{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3daeb24",
   "metadata": {},
   "source": [
    "## Youtube Transcript Search QA Bot\n",
    "This Q&A bot will allow you to search through youtube transcripts using natural language with LanceDB and OpenAI! By going through this notebook, we'll introduce how you can use LanceDB to store and manage your data easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b8f4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet openai datasets \n",
    "!pip install --quiet -U lancedb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e41240e",
   "metadata": {},
   "source": [
    "### Download the data\n",
    "For this dataset we're using the HuggingFace dataset jamescalam/youtube-transcriptions.\n",
    "\n",
    "From the <a href=\"https://huggingface.co/datasets/jamescalam/youtube-transcriptions\">website</a>\n",
    "\n",
    "We'll use the training split with 700 videos and 208619 sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694ceb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset('jamescalam/youtube-transcriptions', split='train')\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0be4da6",
   "metadata": {},
   "source": [
    "### Prepare context\n",
    "Each item in the dataset contains just a short chunk of text. We'll need to merge a bunch of these chunks together on a rolling basis. For this demo, we'll merge 20 rows and step over 4 rows at a time. LanceDB offers chaining support so you can write declarative, readable and parameterized queries. Here we serialize to Pandas as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bbc15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lancedb.context import contextualize\n",
    "\n",
    "df = (contextualize(data.to_pandas())\n",
    "      .groupby(\"title\").text_col(\"text\")\n",
    "      .window(20).stride(4)\n",
    "      .to_df())\n",
    "df.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fe3d190",
   "metadata": {},
   "source": [
    "### Create embedding function\n",
    "To create embeddings out of the text, we'll call the OpenAI embeddings API to get embeddings. Make sure you have an API key setup and that your account has available credits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169134a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Configuring the environment variable OPENAI_API_KEY\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    # OR set the key here as a variable\n",
    "    openai.api_key = \"sk-...\"\n",
    "    \n",
    "assert len(openai.Model.list()[\"data\"]) > 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05377be7",
   "metadata": {},
   "source": [
    "We'll use the ada2 text embeddings model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aef5764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_func(c):    \n",
    "    rs = openai.Embedding.create(input=c, engine=\"text-embedding-ada-002\")\n",
    "    return [record[\"embedding\"] for record in rs[\"data\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7da05ea8",
   "metadata": {},
   "source": [
    "### Create the LanceDB Table\n",
    "\n",
    "OpenAI API often fails or times out. So LanceDB's API provides retry and throttling features behind the scenes to make it easier to call these APIs. In LanceDB the primary abstraction you'll use to work with your data is a Table. A Table is designed to store large numbers of columns and huge quantities of data! For those interested, a LanceDB is columnar-based, and uses Lance, an open data format to store data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e76fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "from lancedb.embeddings import with_embeddings\n",
    "\n",
    "data = with_embeddings(embed_func, df, show_progress=True)\n",
    "data.to_pandas().head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5018aeed",
   "metadata": {},
   "source": [
    "Now we're ready to save the data and create a new LanceDB table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9246741",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /tmp/lancedb\n",
    "\n",
    "db = lancedb.connect(\"/tmp/lancedb\")\n",
    "tbl = db.create_table(\"youtube-chatbot\", data)\n",
    "len(tbl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f28ff93d",
   "metadata": {},
   "source": [
    "The table is backed by a Lance dataset so it's easy to integrate into other tools (e.g., pandas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492762e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl.to_pandas().head(1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc3c6895",
   "metadata": {},
   "source": [
    "### Create and answer the prompt\n",
    "For a given context (bunch of text), we can ask the OpenAI Completion API to answer an arbitrary question using the following prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9b0f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(query, context):\n",
    "    limit = 3750\n",
    "\n",
    "    prompt_start = (\n",
    "        \"Answer the question based on the context below.\\n\\n\"+\n",
    "        \"Context:\\n\"\n",
    "    )\n",
    "    prompt_end = (\n",
    "        f\"\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    )\n",
    "    # append contexts until hitting limit\n",
    "    for i in range(1, len(context)):\n",
    "        if len(\"\\n\\n---\\n\\n\".join(context.text[:i])) >= limit:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(context.text[:i-1]) +\n",
    "                prompt_end\n",
    "            )\n",
    "            break\n",
    "        elif i == len(context)-1:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(context.text) +\n",
    "                prompt_end\n",
    "            )    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3360c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete(prompt):\n",
    "    # query text-davinci-003\n",
    "    res = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=400,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "    return res['choices'][0]['text'].strip()\n",
    "\n",
    "# check that it works\n",
    "query = \"who was the 12th person on the moon and when did they land?\"\n",
    "complete(query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4b12ee5",
   "metadata": {},
   "source": [
    "Let's put it all together now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fac2cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\"Which training method should I use for sentence transformers \"\n",
    "         \"when I only have pairs of related sentences?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a68c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the question\n",
    "emb = embed_func(query)[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f628fb47",
   "metadata": {},
   "source": [
    "Again we'll use LanceDB's chaining query API. This time, we'll perform similarity search to find similar embeddings to our query. We can easily tweak the parameters in the query to produce the best result.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c77d945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LanceDB to get top 3 most relevant context\n",
    "context = tbl.search(emb).limit(3).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605c35a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the answer from completion API\n",
    "prompt = create_prompt(query, context)\n",
    "complete(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9aeedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "top_match = context.iloc[0]\n",
    "YouTubeVideo(top_match[\"url\"].split(\"/\")[-1], start=int(top_match[\"start\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
