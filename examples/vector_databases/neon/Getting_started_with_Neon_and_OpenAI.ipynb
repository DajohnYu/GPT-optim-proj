{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Neon as a vector database for OpenAI embeddings\n",
    "\n",
    "This notebook guides you step by step on using Neon Serverless Postgres as a vector database for OpenAI embeddings.\n",
    "\n",
    "This notebook presents an end-to-end process of:\n",
    "1. Using precomputed embeddings created by OpenAI API.\n",
    "2. Storing the embeddings in a Neon database.\n",
    "3. Converting raw text query to an embedding with OpenAI API.\n",
    "4. Using Neon with the `pgvector` extension to perform the nearest neighbour search in the created collection.\n",
    "\n",
    "### What is Neon Serverless Postgres\n",
    "\n",
    "[Neon Serverless Postgres](https://www.alibabacloud.com/help/en/polardb/latest/what-is-polardb-2) is open-source serverless Postgres built for the cloud. Neon separates compute and storage to offer modern developer features such as autoscaling, database branching, scale-to-zero, and more. Neon supports vector search through the [pg_embedding](https://neon.tech/docs/extensions/pg_embedding) and [pgvector](https://neon.tech/docs/extensions/pgvector) open-source PostgreSQL extensions, both of which allow you to enable Postgres as a vector database.;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Deployment options\n",
    "\n",
    "- Neon is a cloud-hosted Postgres database service. You can create a Free Tier account and set up a project with a default database in a few simple steps. For instructions, see [Sign up](https://neon.tech/docs/get-started-with-neon/signing-up) and [Create your first project](https://neon.tech/docs/get-started-with-neon/setting-up-a-project)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "For the purposes of this exercise we need to prepare the following:\n",
    "\n",
    "1. A Neon Postgres database. Refer to the links provided above to set up an account and a Neon project.\n",
    "2. The connection string for your Neon database. For infomration about obtaining a connection string, see [Connect from any application](https://neon.tech/docs/connect/connect-from-any-app).\n",
    "2. You have installed the `pgvector` extension in Neon by running `CREATE EXTENSION vector;`. For instructions, see [Enable the pgvector exstenion](https://neon.tech/docs/extensions/pgvector#enable-the-pgvector-extension). \n",
    "2. The 'psycopg2' library to interact with Neon. Any other PostgreSQL client library is also supported.\n",
    "3. An [OpenAI API key](https://platform.openai.com/account/api-keys)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup requirements\n",
    "\n",
    "This notebook requires the `openai` and `psycopg2` packages, but there are also some other additional libraries we will use. The following command installs them all:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "! pip install openai psycopg2 pandas wget"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare your OpenAI API key\n",
    "\n",
    "The OpenAI API key is used for vectorization of the documents and queries.\n",
    "\n",
    "If you don't have an OpenAI API key, you can get one from https://platform.openai.com/account/api-keys.\n",
    "\n",
    "Once you have your key, add it to your environment variables as `OPENAI_API_KEY`.\n",
    "\n",
    "For additional information about setting your OpenAI API as an environment variable, please refer to [Best Practices for API Key Safety](https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your OpenAPI key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY environment variable not found\n"
     ]
    }
   ],
   "source": [
    "# Test that your OpenAI API key is set correctly as an environment variable\n",
    "# Note: If you run this notebook locally, you will need to reload your terminal and the notebook for the environment variables to be available.\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is not None:\n",
    "    print(\"OPENAI_API_KEY is ready\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY environment variable not found\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your Neon database\n",
    "\n",
    "Add the connection information defined below to your environment variables. Alternatively, you can just modify the \"psycopg2.connect\" parameters below.\n",
    "\n",
    "Connecting to your Neon database server is easy with the official Python library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'psycopg2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpsycopg2\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# Note. alternatively you can set a temporary env variable like this:\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m# os.environ[\"PGHOST\"] = \"ep-snowy-unit-550577.us-east-2.aws.neon.tech\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m# os.environ[\"PGPORT\"] \"5432\"),\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m# os.environ[\"PGDATABASE\"] \"neondb\"),\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39m# os.environ[\"PGUSER\"] \"user\"),\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m# os.environ[\"PGPASSWORD\"] \"password\"),\u001b[39;00m\n\u001b[0;32m     11\u001b[0m connection \u001b[39m=\u001b[39m psycopg2\u001b[39m.\u001b[39mconnect(\n\u001b[0;32m     12\u001b[0m     host\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mPGHOST\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mep-square-grass-34421519.ap-southeast-1.aws.neon.tech\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m     13\u001b[0m     port\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mPGPORT\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m5432\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     password\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mPGPASSWORD\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mAg8MSyvUPIx9\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'psycopg2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "\n",
    "# Note. alternatively you can set a temporary env variable like this:\n",
    "# os.environ[\"PGHOST\"] = \"ep-snowy-unit-550577.us-east-2.aws.neon.tech\"\n",
    "# os.environ[\"PGPORT\"] \"5432\"),\n",
    "# os.environ[\"PGDATABASE\"] \"neondb\"),\n",
    "# os.environ[\"PGUSER\"] \"user\"),\n",
    "# os.environ[\"PGPASSWORD\"] \"password\"),\n",
    "\n",
    "connection = psycopg2.connect(\n",
    "    host=os.environ.get(\"PGHOST\", \"ep-square-grass-34421519.ap-southeast-1.aws.neon.tech\"),\n",
    "    port=os.environ.get(\"PGPORT\", \"5432\"),\n",
    "    database=os.environ.get(\"PGDATABASE\", \"neondb\"),\n",
    "    user=os.environ.get(\"PGUSER\", \"daniel\"),\n",
    "    password=os.environ.get(\"PGPASSWORD\", \"Ag8MSyvUPIx9\")\n",
    ")\n",
    "\n",
    "# Create a new cursor object\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the connection by running any available method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n"
     ]
    }
   ],
   "source": [
    "# Execute a simple query to test the connection\n",
    "cursor.execute(\"SELECT 1;\")\n",
    "result = cursor.fetchone()\n",
    "\n",
    "# Check the query result\n",
    "if result == (1,):\n",
    "    print(\"Connection successful!\")\n",
    "else:\n",
    "    print(\"Connection failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the pre-computed embeddings archive file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vector_database_wikipedia_articles_embedded.zip'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wget\n",
    "\n",
    "embeddings_url = \"https://cdn.openai.com/API/examples/data/vector_database_wikipedia_articles_embedded.zip\"\n",
    "\n",
    "# The file is ~700 MB so this will take some time\n",
    "wget.download(embeddings_url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the downloaded archive file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file vector_database_wikipedia_articles_embedded.csv exists in the data directory.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import re\n",
    "import tempfile\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "zip_file_path = os.path.join(current_directory, \"vector_database_wikipedia_articles_embedded.zip\")\n",
    "output_directory = os.path.join(current_directory, \"../../data\")\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(output_directory)\n",
    "\n",
    "\n",
    "# check the csv file exist\n",
    "file_name = \"vector_database_wikipedia_articles_embedded.csv\"\n",
    "data_directory = os.path.join(current_directory, \"../../data\")\n",
    "file_path = os.path.join(data_directory, file_name)\n",
    "\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"The file {file_name} exists in the data directory.\")\n",
    "else:\n",
    "    print(f\"The file {file_name} does not exist in the data directory.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index data\n",
    "\n",
    "The vector table will be called **articles** and each object will have both **title** and **content** vectors. \n",
    "\n",
    "We will start by creating a table with an index defined on both the **title** and **content** vector columns. We will then we then populate the table with our precomputed embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_sql = '''\n",
    "CREATE TABLE IF NOT EXISTS public.articles (\n",
    "    id INTEGER NOT NULL,\n",
    "    url TEXT,\n",
    "    title TEXT,\n",
    "    content TEXT,\n",
    "    title_vector vector(1536),\n",
    "    content_vector vector(1536),\n",
    "    vector_id INTEGER\n",
    ");\n",
    "\n",
    "ALTER TABLE public.articles ADD PRIMARY KEY (id);\n",
    "'''\n",
    "\n",
    "# SQL statement for creating indexes\n",
    "create_indexes_sql = '''\n",
    "CREATE INDEX ON public.articles USING ivfflat (content_vector) WITH (lists = 1000);\n",
    "\n",
    "CREATE INDEX ON public.articles USING ivfflat (title_vector) WITH (lists = 1000);\n",
    "'''\n",
    "\n",
    "# Execute the SQL statements\n",
    "cursor.execute(create_table_sql)\n",
    "cursor.execute(create_indexes_sql)\n",
    "\n",
    "# Commit the changes\n",
    "connection.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "In this section we are going to load the data prepared previous to this session, so you don't have to recompute the embeddings of Wikipedia articles with your own credits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "# Path to your local CSV file\n",
    "csv_file_path = '../../data/vector_database_wikipedia_articles_embedded.csv'\n",
    "\n",
    "# Define a generator function to process the file line by line\n",
    "def process_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            yield line\n",
    "\n",
    "# Create a StringIO object to store the modified lines\n",
    "modified_lines = io.StringIO(''.join(list(process_file(csv_file_path))))\n",
    "\n",
    "# Create the COPY command for the copy_expert method\n",
    "copy_command = '''\n",
    "COPY public.articles (id, url, title, content, title_vector, content_vector, vector_id)\n",
    "FROM STDIN WITH (FORMAT CSV, HEADER true, DELIMITER ',');\n",
    "'''\n",
    "\n",
    "# Execute the COPY command using the copy_expert method\n",
    "cursor.copy_expert(copy_command, modified_lines)\n",
    "\n",
    "# Commit the changes\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:25000\n"
     ]
    }
   ],
   "source": [
    "# Check the collection size to make sure all the points have been stored\n",
    "count_sql = \"\"\"select count(*) from public.articles;\"\"\"\n",
    "cursor.execute(count_sql)\n",
    "result = cursor.fetchone()\n",
    "print(f\"Count:{result[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search data\n",
    "\n",
    "Once the data is stored in your Neon database, you can query the collection for the closest vectors. We  provide an additional parameter `vector_name` to switch from title to content based search. Since the precomputed embeddings were created with `text-embedding-ada-002` OpenAI model, we also have to use it during search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_neon(query, collection_name, vector_name=\"title_vector\", top_k=20):\n",
    "\n",
    "    # Creates embedding vector from user query\n",
    "    embedded_query = openai.Embedding.create(\n",
    "        input=query,\n",
    "        model=\"text-embedding-ada-002\",\n",
    "    )[\"data\"][0][\"embedding\"]\n",
    "\n",
    "    # Convert the embedded_query to PostgreSQL compatible format\n",
    "    embedded_query_pg = \"[\" + \",\".join(map(str, embedded_query)) + \"]\"\n",
    "\n",
    "    # Create SQL query\n",
    "    query_sql = f\"\"\"\n",
    "    SELECT id, url, title, l2_distance({vector_name},'{embedded_query_pg}'::VECTOR(1536)) AS similarity\n",
    "    FROM {collection_name}\n",
    "    ORDER BY {vector_name} <-> '{embedded_query_pg}'::VECTOR(1536)\n",
    "    LIMIT {top_k};\n",
    "    \"\"\"\n",
    "    # Execute the query\n",
    "    cursor.execute(query_sql)\n",
    "    results = cursor.fetchall()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Museum of Modern Art (Score: 0.5)\n",
      "2. Western Europe (Score: 0.485)\n",
      "3. Renaissance art (Score: 0.479)\n",
      "4. Pop art (Score: 0.472)\n",
      "5. Northern Europe (Score: 0.461)\n",
      "6. Hellenistic art (Score: 0.457)\n",
      "7. Modernist literature (Score: 0.447)\n",
      "8. Art film (Score: 0.44)\n",
      "9. Central Europe (Score: 0.439)\n",
      "10. European (Score: 0.437)\n",
      "11. Art (Score: 0.437)\n",
      "12. Byzantine art (Score: 0.436)\n",
      "13. Postmodernism (Score: 0.434)\n",
      "14. Eastern Europe (Score: 0.433)\n",
      "15. Europe (Score: 0.433)\n",
      "16. Cubism (Score: 0.432)\n",
      "17. Impressionism (Score: 0.432)\n",
      "18. Bauhaus (Score: 0.431)\n",
      "19. Surrealism (Score: 0.429)\n",
      "20. Expressionism (Score: 0.429)\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "query_results = query_neon(\"modern art in Europe\", \"Articles\")\n",
    "for i, result in enumerate(query_results):\n",
    "    print(f\"{i + 1}. {result[2]} (Score: {round(1 - result[3], 3)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Battle of Bannockburn (Score: 0.489)\n",
      "2. Wars of Scottish Independence (Score: 0.474)\n",
      "3. 1651 (Score: 0.457)\n",
      "4. First War of Scottish Independence (Score: 0.452)\n",
      "5. Robert I of Scotland (Score: 0.445)\n",
      "6. 841 (Score: 0.441)\n",
      "7. 1716 (Score: 0.441)\n",
      "8. 1314 (Score: 0.429)\n",
      "9. 1263 (Score: 0.428)\n",
      "10. William Wallace (Score: 0.426)\n",
      "11. Stirling (Score: 0.419)\n",
      "12. 1306 (Score: 0.419)\n",
      "13. 1746 (Score: 0.418)\n",
      "14. 1040s (Score: 0.414)\n",
      "15. 1106 (Score: 0.412)\n",
      "16. 1304 (Score: 0.411)\n",
      "17. David II of Scotland (Score: 0.408)\n",
      "18. Braveheart (Score: 0.407)\n",
      "19. 1124 (Score: 0.406)\n",
      "20. July 27 (Score: 0.405)\n"
     ]
    }
   ],
   "source": [
    "# This time we'll query using content vector\n",
    "query_results = query_neon(\"Famous battles in Scottish history\", \"Articles\", \"content_vector\")\n",
    "for i, result in enumerate(query_results):\n",
    "    print(f\"{i + 1}. {result[2]} (Score: {round(1 - result[3], 3)})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
