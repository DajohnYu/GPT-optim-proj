{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Neon as a vector database for OpenAI embeddings\n",
    "\n",
    "This notebook guides you through using Neon Serverless Postgres as a vector database for OpenAI embeddings.\n",
    "\n",
    "This notebook will show how to:\n",
    "1. Use embeddings created by OpenAI API.\n",
    "2. Store embeddings in a Neon Postgres database.\n",
    "3. Convert a raw text query to an embedding with OpenAI API.\n",
    "4. Use Neon with the `pgvector` extension to perform vector similarity search.\n",
    "\n",
    "### What is Neon Serverless Postgres?\n",
    "\n",
    "[Neon](https://neon.tech/) is Serverless Postgres built for the cloud. Neon separates compute and storage to offer modern developer features such as autoscaling, database branching, scale-to-zero, and more. You can use Neon Postgres as a vector database by installing [pgvector](https://neon.tech/docs/extensions/pgvector) or [pg_embedding](https://neon.tech/docs/extensions/pg_embedding). These are open-source PostgreSQL extensions that enable Postgres as a vector database, allowing you to perform vector similarity search in Postgres.\n",
    "\n",
    "- [pgvector](https://neon.tech/docs/extensions/pgvector) is an open-source extension that enables vector similarity search in Postgres. It supports `ivfflat` indexes.\n",
    "- [pg_embedding](https://neon.tech/docs/extensions/pg_embedding), developed and maintained by Neon, is an open-source extension that enables graph-based vector similarity search in Postgres using the Hierarchical Navigable Small World (HNSW) algorithm.\n",
    "\n",
    "This guide uses the `pgvector` extension.\n",
    "\n",
    "### Deployment options\n",
    "\n",
    "Neon is a cloud-hosted Postgres database service. Refer to the [Prerequisites](#prerequisites) section for setup instructions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before you begin, ensure that you have the following:\n",
    "\n",
    "1. A Neon Postgres database. You can create a Free Tier account and set up a project with a ready-to-use `neondb` database in a few simple steps. For instructions, see [Sign up](https://neon.tech/docs/get-started-with-neon/signing-up) and [Create your first project](https://neon.tech/docs/get-started-with-neon/setting-up-a-project).\n",
    "2. A connection string for your `neondb` database. You can copy it from the **Connection Details** widget on the Neon **Dashboard**. see [Connect from any application](https://neon.tech/docs/connect/connect-from-any-app).\n",
    "3. The `pgvector` extension. You must install the extension in Neon by running `CREATE EXTENSION vector;`. For instructions, see [Enable the pgvector extension](https://neon.tech/docs/extensions/pgvector#enable-the-pgvector-extension). \n",
    "4. Your [OpenAI API key](https://platform.openai.com/account/api-keys).\n",
    "5. Python and `pip`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup requirements\n",
    "\n",
    "This notebook requires the `openai`, `psycopg2`, `pandas`, and `wget` packages. You can install them with `pip`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai psycopg2 pandas wget"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare your OpenAI API key\n",
    "\n",
    "An OpenAI API key is required to generate vectors for documents and queries.\n",
    "\n",
    "If you do not have an OpenAI API key, obtain one from https://platform.openai.com/account/api-keys.\n",
    "\n",
    "Add the OpenAI API key as an operating system environment variable. Name the variable `OPENAI_API_KEY`.\n",
    "\n",
    "For information about configuring your OpenAI API key as an environment variable, refer to [Best Practices for API Key Safety](https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your OpenAPI key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY is ready\n"
     ]
    }
   ],
   "source": [
    "# Test to ensure that your OpenAI API key is set correctly as an environment variable\n",
    "# Note: If you run this notebook locally, you may need to reload the terminal and the notebook for the environment variables to be available.\n",
    "\n",
    "import os\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is not None:\n",
    "    print(\"OPENAI_API_KEY is ready\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY environment variable not found\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your Neon database\n",
    "\n",
    "Add the database connection details to your environment variables. You can obtain the connection details from your Neon database connection string. If you get stuck, see [Connect from any application](https://neon.tech/docs/connect/connect-from-any-app).\n",
    "\n",
    "Alternatively, you can set `psycopg2.connect` parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "\n",
    "# You can set temporary environment variables like this:\n",
    "# os.environ[\"PGHOST\"] = \"ep-snowy-unit-550577.us-east-2.aws.neon.tech\"\n",
    "# os.environ[\"PGPORT\"] \"5432\"),\n",
    "# os.environ[\"PGDATABASE\"] \"neondb\"),\n",
    "# os.environ[\"PGUSER\"] \"user\"),\n",
    "# os.environ[\"PGPASSWORD\"] \"password\"),\n",
    "\n",
    "# Alternatively, you can set \"psycopg2.connect\" parameters\n",
    "\n",
    "connection = psycopg2.connect(\n",
    "    host=os.environ.get(\"PGHOST\", \"ep-damp-cell-18160816.us-east-2.aws.neon.tech\"),\n",
    "    port=os.environ.get(\"PGPORT\", \"5432\"),\n",
    "    database=os.environ.get(\"PGDATABASE\", \"neondb\"),\n",
    "    user=os.environ.get(\"PGUSER\", \"daniel\"),\n",
    "    password=os.environ.get(\"PGPASSWORD\", \"lsEPxw0o2eHk\")\n",
    ")\n",
    "\n",
    "# Create a new cursor object\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n"
     ]
    }
   ],
   "source": [
    "# Execute a simple query to test the connection\n",
    "cursor.execute(\"SELECT 1;\")\n",
    "result = cursor.fetchone()\n",
    "\n",
    "# Check the query result\n",
    "if result == (1,):\n",
    "    print(\"Connection successful!\")\n",
    "else:\n",
    "    print(\"Connection failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This guide uses pre-computed Wikipedia article embeddings available in the OpenAI Cookbook `examples` directory so that you do not have to compute embeddings with your own OpenAI credits. \n",
    "\n",
    "Import the pre-computed embeddings archive file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vector_database_wikipedia_articles_embedded.zip'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wget\n",
    "\n",
    "embeddings_url = \"https://cdn.openai.com/API/examples/data/vector_database_wikipedia_articles_embedded.zip\"\n",
    "\n",
    "# The file is ~700 MB. Importing it will take some time.\n",
    "wget.download(embeddings_url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the downloaded archive file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file vector_database_wikipedia_articles_embedded.csv exists in the data directory.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import re\n",
    "import tempfile\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "zip_file_path = os.path.join(current_directory, \"vector_database_wikipedia_articles_embedded.zip\")\n",
    "output_directory = os.path.join(current_directory, \"../../data\")\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(output_directory)\n",
    "\n",
    "\n",
    "# Check that the csv file exists\n",
    "file_name = \"vector_database_wikipedia_articles_embedded.csv\"\n",
    "data_directory = os.path.join(current_directory, \"../../data\")\n",
    "file_path = os.path.join(data_directory, file_name)\n",
    "\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"The file {file_name} exists in the data directory.\")\n",
    "else:\n",
    "    print(f\"The file {file_name} does not exist in the data directory.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index your data\n",
    "\n",
    "The vector table created in your database is called **articles**. Each object has **title** and **content** vectors. \n",
    "\n",
    "An index is defined on both the **title** and **content** vector columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_sql = '''\n",
    "CREATE TABLE IF NOT EXISTS public.articles (\n",
    "    id INTEGER NOT NULL,\n",
    "    url TEXT,\n",
    "    title TEXT,\n",
    "    content TEXT,\n",
    "    title_vector vector(1536),\n",
    "    content_vector vector(1536),\n",
    "    vector_id INTEGER\n",
    ");\n",
    "\n",
    "ALTER TABLE public.articles ADD PRIMARY KEY (id);\n",
    "'''\n",
    "\n",
    "# SQL statement for creating indexes\n",
    "create_indexes_sql = '''\n",
    "CREATE INDEX ON public.articles USING ivfflat (content_vector) WITH (lists = 1000);\n",
    "\n",
    "CREATE INDEX ON public.articles USING ivfflat (title_vector) WITH (lists = 1000);\n",
    "'''\n",
    "\n",
    "# Execute the SQL statements\n",
    "cursor.execute(create_table_sql)\n",
    "cursor.execute(create_indexes_sql)\n",
    "\n",
    "# Commit the changes\n",
    "connection.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Load the pre-computed vector data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "# Path to your local CSV file\n",
    "csv_file_path = '../../data/vector_database_wikipedia_articles_embedded.csv'\n",
    "\n",
    "# Define a generator function to process the file line by line\n",
    "def process_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            yield line\n",
    "\n",
    "# Create a StringIO object to store the modified lines\n",
    "modified_lines = io.StringIO(''.join(list(process_file(csv_file_path))))\n",
    "\n",
    "# Create the COPY command for the copy_expert method\n",
    "copy_command = '''\n",
    "COPY public.articles (id, url, title, content, title_vector, content_vector, vector_id)\n",
    "FROM STDIN WITH (FORMAT CSV, HEADER true, DELIMITER ',');\n",
    "'''\n",
    "\n",
    "# Execute the COPY command using the copy_expert method\n",
    "cursor.copy_expert(copy_command, modified_lines)\n",
    "\n",
    "# Commit the changes\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the size of the imported data to ensure the data has been been loaded. There should be 25000 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:25000\n"
     ]
    }
   ],
   "source": [
    "# Check the size of the collection\n",
    "count_sql = \"\"\"select count(*) from public.articles;\"\"\"\n",
    "cursor.execute(count_sql)\n",
    "result = cursor.fetchone()\n",
    "print(f\"Count:{result[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search data\n",
    "\n",
    "After the data is stored in your Neon database, query the collection for nearest neighbors. An additional `vector_name` parameter is provided to switch from \"title\" to \"content\" based similarity search. The pre-computed embeddings were created with `text-embedding-ada-002` OpenAI model, so this model must also be used to vectorize search queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_neon(query, collection_name, vector_name=\"title_vector\", top_k=20):\n",
    "\n",
    "    # Creates embedding vector from user query\n",
    "    embedded_query = openai.Embedding.create(\n",
    "        input=query,\n",
    "        model=\"text-embedding-ada-002\",\n",
    "    )[\"data\"][0][\"embedding\"]\n",
    "\n",
    "    # Convert the embedded_query to PostgreSQL compatible format\n",
    "    embedded_query_pg = \"[\" + \",\".join(map(str, embedded_query)) + \"]\"\n",
    "\n",
    "    # Create SQL query\n",
    "    query_sql = f\"\"\"\n",
    "    SELECT id, url, title, l2_distance({vector_name},'{embedded_query_pg}'::VECTOR(1536)) AS similarity\n",
    "    FROM {collection_name}\n",
    "    ORDER BY {vector_name} <-> '{embedded_query_pg}'::VECTOR(1536)\n",
    "    LIMIT {top_k};\n",
    "    \"\"\"\n",
    "    # Execute the query\n",
    "    cursor.execute(query_sql)\n",
    "    results = cursor.fetchall()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a similarity search using the \"title\" vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Greek mythology (Score: 0.998)\n",
      "2. Roman mythology (Score: 0.7)\n",
      "3. Greek underworld (Score: 0.637)\n",
      "4. Mythology (Score: 0.635)\n",
      "5. Classical mythology (Score: 0.629)\n",
      "6. Japanese mythology (Score: 0.615)\n",
      "7. Norse mythology (Score: 0.569)\n",
      "8. Greek language (Score: 0.566)\n",
      "9. Zeus (Score: 0.535)\n",
      "10. List of mythologies (Score: 0.531)\n",
      "11. Jupiter (mythology) (Score: 0.53)\n",
      "12. Greek (Score: 0.53)\n",
      "13. Gaia (mythology) (Score: 0.526)\n",
      "14. Titan (mythology) (Score: 0.522)\n",
      "15. Mercury (mythology) (Score: 0.521)\n",
      "16. Ancient Greece (Score: 0.52)\n",
      "17. Greek alphabet (Score: 0.52)\n",
      "18. Venus (mythology) (Score: 0.515)\n",
      "19. Pluto (mythology) (Score: 0.515)\n",
      "20. Athena (Score: 0.514)\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "query_results = query_neon(\"Greek mythology\", \"Articles\")\n",
    "for i, result in enumerate(query_results):\n",
    "    print(f\"{i + 1}. {result[2]} (Score: {round(1 - result[3], 3)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a similarity search using the \"content\" vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 222 BC (Score: 0.489)\n",
      "2. Trojan War (Score: 0.458)\n",
      "3. Peloponnesian War (Score: 0.456)\n",
      "4. History of the Peloponnesian War (Score: 0.449)\n",
      "5. 430 BC (Score: 0.441)\n",
      "6. 168 BC (Score: 0.436)\n",
      "7. Ancient Greece (Score: 0.429)\n",
      "8. Classical Athens (Score: 0.428)\n",
      "9. 499 BC (Score: 0.427)\n",
      "10. Leonidas I (Score: 0.426)\n",
      "11. Battle (Score: 0.421)\n",
      "12. Greek War of Independence (Score: 0.421)\n",
      "13. Menelaus (Score: 0.419)\n",
      "14. Thebes, Greece (Score: 0.417)\n",
      "15. Patroclus (Score: 0.417)\n",
      "16. 427 BC (Score: 0.416)\n",
      "17. 429 BC (Score: 0.413)\n",
      "18. August 2 (Score: 0.412)\n",
      "19. Ionia (Score: 0.411)\n",
      "20. 323 (Score: 0.409)\n"
     ]
    }
   ],
   "source": [
    "# Query using the \"content\" vector\n",
    "query_results = query_neon(\"Famous battles in Greek history\", \"Articles\", \"content_vector\")\n",
    "for i, result in enumerate(query_results):\n",
    "    print(f\"{i + 1}. {result[2]} (Score: {round(1 - result[3], 3)})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
