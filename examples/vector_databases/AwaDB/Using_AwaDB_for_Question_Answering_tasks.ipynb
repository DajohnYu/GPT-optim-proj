{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c80dbb1",
   "metadata": {},
   "source": [
    "# Using AwaDB as a Vector database for Question Answering tasks\n",
    "\n",
    "This notebook demonstrates how to utilize AwaDB as a vector database for storing embeddings obtained from OpenAI. It then illustrates how to employ GPT and embedding-based search for question answering tasks.\n",
    "\n",
    "We outline an end-to-end workflow example to illustrate the entire process.\n",
    "\n",
    "1. Text Preprocessing\n",
    "2. Embedding\n",
    "3. Vector Store\n",
    "4. Similarity Search\n",
    "5. Question Answering\n",
    "\n",
    "We need to slice the original document into appropriate text sentences for further embedding, and then utilize different embedding models, such as OpenAI Embedding, to process the text and store it in the database. After the above operations, the subsequent queries will be combined with the similarity finding results in the database to give a better answer.\n",
    "\n",
    "## Install libraries\n",
    "The requirements for this sample are `openai` and `awadb` packages \n",
    "\n",
    "You can use `pip install awadb` and `pip install openai` to install them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9904f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "try:\n",
    "    import openai\n",
    "    import awadb\n",
    "except ImportError as exc:\n",
    "    raise ImportError(\n",
    "        \"Could not import libraries. \"\n",
    "        \"Please install it with `pip install awadb` or `pip install openai`\"\n",
    "    ) from exc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1811c33",
   "metadata": {},
   "source": [
    "You also need to set your openai api key as an environment variable before. You can find more information about this by referring [Best Practices for API Key Safety\n",
    "](https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "671422b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wget\n",
    "\n",
    "assert os.environ[\"OPENAI_API_KEY\"] != None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f0a06b",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "We then need to load the dataset we are using in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc442968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists in the local file system.\n"
     ]
    }
   ],
   "source": [
    "embeddings_path = \"https://raw.githubusercontent.com/awa-ai/awadb/main/tests/state_of_the_union.txt\"\n",
    "file_path = \"state_of_the_union.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    wget.download(embeddings_path, file_path)\n",
    "    print(\"\\nFile downloaded successfully.\")\n",
    "else:\n",
    "    print(\"File already exists in the local file system.\")\n",
    "    \n",
    "# Load the data file\n",
    "from langchain.document_loaders import TextLoader\n",
    "loader = TextLoader(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9a5289",
   "metadata": {},
   "source": [
    "### Split the text\n",
    "Then we are going to preprocessing the text. Briefly, we split the text data into chunks of max size 200, with an overlap of size 10 between neighboring chunks.\n",
    "\n",
    "The choice of the two hyperparameters here is related to the average sentence length of your document. A basic logic is the need to ensure that each segmented phrase contains a complete semantic meaning and does not contain more than one semantic meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d26f92a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 215, which is longer than the specified 200\n",
      "Created a chunk of size 232, which is longer than the specified 200\n",
      "Created a chunk of size 242, which is longer than the specified 200\n",
      "Created a chunk of size 219, which is longer than the specified 200\n",
      "Created a chunk of size 304, which is longer than the specified 200\n",
      "Created a chunk of size 205, which is longer than the specified 200\n",
      "Created a chunk of size 332, which is longer than the specified 200\n",
      "Created a chunk of size 215, which is longer than the specified 200\n",
      "Created a chunk of size 203, which is longer than the specified 200\n",
      "Created a chunk of size 281, which is longer than the specified 200\n",
      "Created a chunk of size 201, which is longer than the specified 200\n",
      "Created a chunk of size 250, which is longer than the specified 200\n",
      "Created a chunk of size 325, which is longer than the specified 200\n",
      "Created a chunk of size 242, which is longer than the specified 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents:1\n",
      "split_docs size: 255\n"
     ]
    }
   ],
   "source": [
    "# Transform to document\n",
    "data = loader.load()\n",
    "print(f'documents:{len(data)}')\n",
    "\n",
    "# Initialize tex spilitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "\n",
    "# Split the document\n",
    "split_docs = text_splitter.split_documents(data)\n",
    "print(\"split_docs size:\",len(split_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "741ce493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set\n",
    "\n",
    "# Save the embedded texts by Awadb\n",
    "texts = [text.page_content for text in split_docs]\n",
    "\n",
    "awadb_client = awadb.Client()\n",
    "awadb_client.Create(\"testdb1\")\n",
    "\n",
    "# Add the splitted texts into database\n",
    "awadb_client.AddTexts(\"embedding_text\", \"testdb1\", texts=texts)\n",
    "\n",
    "not_include_fields: Set[str] = {\"text_embedding\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ff2153",
   "metadata": {},
   "source": [
    "### Set the question\n",
    "\n",
    "Use `awadb_client.Search` for similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5410506c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the question\n",
    "query = \"What measures does the speaker ask Congress to pass to reduce gun violence?\"\n",
    "# Similarity search results\n",
    "similar_docs = awadb_client.Search(query=query, topn=3, not_include_fields=not_include_fields)\n",
    "\n",
    "#print(similar_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f41e1ac",
   "metadata": {},
   "source": [
    "## Create Prompt\n",
    "We then will create prompts based on our question and the results from the similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "821dbc83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a person who answers questions for people based on specified information\n",
      "Here is some information given to you:\n",
      "Ban assault weapons and high-capacity magazines. \n",
      "\n",
      "Repeal the liability shield that makes gun manufacturers the only industry in America that canâ€™t be sued.\n",
      "I ask Democrats and Republicans alike: Pass my budget and keep our neighborhoods safe.\n",
      "And I ask Congress to pass proven measures to reduce gun violence. Pass universal background checks. Why should anyone on a terrorist list be able to purchase a weapon?\n",
      "Here is the question: What measures does the speaker ask Congress to pass to reduce gun violence?\n",
      "Please provide an answer only related to the question and do not include any information more than that.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create prompt\n",
    "system_prompt = \"You are a person who answers questions for people based on specified information\\n\"\n",
    "\n",
    "similar_prompt = \"\"\n",
    "for i in range(3):\n",
    "    similar_prompt += similar_docs[0]['ResultItems'][i]['embedding_text'] + \"\\n\"\n",
    "\n",
    "#similar_prompt = similar_docs[0].page_content + \"\\n\" + similar_docs[1].page_content + \"\\n\" + similar_docs[2].page_content + \"\\n\"\n",
    "question_prompt = f\"Here is the question: {query}\\nPlease provide an answer only related to the question and do not include any information more than that.\\n\"\n",
    "prompt = system_prompt + \"Here is some information given to you:\\n\" + similar_prompt + question_prompt\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8fd7b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The speaker asks Congress to pass measures to reduce gun violence, including universal background checks and preventing individuals on a terrorist list from purchasing weapons.\n"
     ]
    }
   ],
   "source": [
    "# Create response from gpt-3.5\n",
    "response = openai.ChatCompletion.create(\n",
    "  model = \"gpt-3.5-turbo\",\n",
    "  temperature =  0.7,\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"\"},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ],\n",
    "  max_tokens = 40\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'].replace(' .', '.').strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
