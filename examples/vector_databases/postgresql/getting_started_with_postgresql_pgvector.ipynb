{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostgreSQL as Vector Database: Getting Started With pgvector\n",
    "\n",
    "PostgreSQL is an open source relational database known for its extensibility. Pgvector is one of the extensions that provides PostgreSQL with all the essential capabilities needed for a vector database. With pgvector, you can efficiently store vectors/embeddings in PostgreSQL, perform similarity searches across vectorized data, optimize data access with IVFFlat and HNSW indexes, and much more.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "TBD\n",
    "\n",
    "* Docker\n",
    "\n",
    "## Install Required Modules\n",
    "\n",
    "The notebook uses the following libraries:\n",
    "- `openai` - provides access to the OpenAI Embedding API.\n",
    "- `psycopg2` - PostgreSQL database driver for Python.\n",
    "- `wget` - allows downloading files and datasets.\n",
    "\n",
    "Install the libraries with pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai psycopg2 wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start PostgreSQL With pgvector\n",
    "\n",
    "The fastest way to start with PostgreSQL as a vector database is by creating a database container with pre-installed pgvector extension. Run the command below to start PostgreSQL in Docker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker compose up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable the pgvector extension by connecting to the database instance from within the container with the psql tool and running the `CREATE EXTENSION vector` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE EXTENSION\n"
     ]
    }
   ],
   "source": [
    "! docker exec -it postgres-pgvector psql -U postgres -c 'CREATE EXTENSION vector'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide OpenAI API Key\n",
    "\n",
    "Provide your OpenAI API key as the `OPENAI_API_KEY` environment variable or run the code snippet below. If the variable is not set, then you'll be prompted for your key and it will be used during this session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key set.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from getpass import getpass\n",
    "\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if (openai_key == None):\n",
    "    openai_key = getpass('Provide your OpenAI API key: ')\n",
    "\n",
    "if (not openai_key):\n",
    "    raise Exception('No OpenAI API key provided. Please set the OPENAI_API_KEY environment variable or provide it when prompted.')\n",
    "\n",
    "openai.api_key = openai_key\n",
    "\n",
    "print('OpenAI API key set.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sample Dataset\n",
    "\n",
    "The notebook uses a [movies dataset](https://huggingface.co/datasets/denismagda/movies/blob/main/README.md) from the Hugging Face with over 45,000 movies and 26 million ratings from over 270,000 users. The dataset comes with pre-generated embeddings for the movies' overviews. The embeddings were generated with the OpenAI `text-embedding-ada-002` model.\n",
    "\n",
    "Download the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the schema file...\n",
      "Downloading the data file...\n",
      "Finished downloading the files.\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "\n",
    "schema_file = \"https://huggingface.co/datasets/denismagda/movies/raw/main/movie_schema.sql\"\n",
    "data_file = \"https://huggingface.co/datasets/denismagda/movies/resolve/main/movie_data_with_openai_embeddings.sql\"\n",
    "\n",
    "print('Downloading the schema file...')\n",
    "wget.download(schema_file)\n",
    "\n",
    "# This file is 900MB, so it might take a minute to download it\n",
    "print('Downloading the data file...')\n",
    "wget.download(data_file)\n",
    "\n",
    "print('Finished downloading the files.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the schema and data into the PostgreSQL instance using the psycopg2 driver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to PostgreSQL...\n",
      "Creating the schema...\n",
      "Loading the data. It might take a minute...\n",
      "45426 movies loaded.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "print('Connecting to PostgreSQL...')\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=password\")\n",
    "    \n",
    "cursor = conn.cursor()\n",
    "\n",
    "print('Creating the schema...')\n",
    "schema_file = open('movie_schema.sql', 'r')\n",
    "cursor.execute(schema_file.read())\n",
    "conn.commit()\n",
    "\n",
    "print('Loading the data. It might take a minute...')\n",
    "data_file = open('movie_data_with_openai_embeddings.sql', 'r')\n",
    "cursor.execute(data_file.read())\n",
    "conn.commit()\n",
    "\n",
    "cursor.execute('SELECT COUNT(*) FROM movie')\n",
    "result = cursor.fetchone()\n",
    "\n",
    "print(f'{result[0]} movies loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Vector Similarity Search\n",
    "\n",
    "The movie dataset stores a vectorized representation of a movie overview in the `overview_vector` column. Each vector is a 1536-dimensional embedding generated with the OpenAI `text-embedding-ada-002` model.\n",
    "\n",
    "The Postgres pgvector extension supports L2 and cosine distance calculation between the embeddings. \n",
    "\n",
    "Run the snippet below to find the most relevant movies for the user's prompt using the cosine distance operator (`<=>`):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Better Living', 'A comedy about families, the elements that bind them together, and about hope in the face of hardship.')\n",
      "('Shared Rooms', 'A new romantic comedy feature film that brings together three interrelated tales of gay men seeking family, love and sex during the holiday season.')\n",
      "('The Ref', 'A cat burglar is forced to take a bickering, dysfunctional family hostage on Christmas Eve.')\n"
     ]
    }
   ],
   "source": [
    "prompt = 'A family comedy for the Christmas holidays.'\n",
    "\n",
    "response = openai.embeddings.create(\n",
    "        input=prompt,\n",
    "        model='text-embedding-ada-002')\n",
    "\n",
    "# Converting the embedding to the pgvector format by adding brackets\n",
    "prompt_vector = '[' + ','.join(map(str, response.data[0].embedding)) + ']'\n",
    "\n",
    "match_threshold = 0.7\n",
    "match_cnt = 3\n",
    "\n",
    "cursor.execute(\n",
    "    'SELECT title, overview '\n",
    "    'FROM movie WHERE 1 - (overview_vector <=> %(prompt_vector)s) >= %(match_threshold)s '\n",
    "    'ORDER BY overview_vector <=> %(prompt_vector)s LIMIT %(match_cnt)s',\n",
    "    {'prompt_vector': prompt_vector, 'match_threshold': match_threshold, 'match_cnt': match_cnt}\n",
    "    )\n",
    "\n",
    "result = cursor.fetchall()\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
