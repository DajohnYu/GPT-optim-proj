{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostgreSQL as Vector Database: Getting Started With pgvector\n",
    "\n",
    "PostgreSQL is an open source relational database known for its extensibility. Pgvector is one of the extensions that provides PostgreSQL with all the essential capabilities needed for a vector database. With pgvector, you can efficiently store vectors/embeddings in PostgreSQL, perform similarity searches across vectorized data, optimize data access with IVFFlat and HNSW indexes, and much more.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "TBD\n",
    "\n",
    "* Docker\n",
    "\n",
    "## Install Required Modules\n",
    "\n",
    "The notebook uses the following libraries:\n",
    "- `openai` - provides access to the OpenAI Embedding API.\n",
    "- `psycopg2` - PostgreSQL database driver for Python.\n",
    "- `wget` - allows downloading files and datasets.\n",
    "\n",
    "Install the libraries with pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai psycopg2 wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start PostgreSQL With pgvector\n",
    "\n",
    "The fastest way to start with PostgreSQL as a vector database is by creating a database container with pre-installed pgvector extension. Run the command below to start PostgreSQL in Docker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker compose up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable the pgvector extension by connecting to the database instance from within the container with the psql tool and running the `CREATE EXTENSION vector` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker exec -it postgres-pgvector psql -U postgres -c 'CREATE EXTENSION vector'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide OpenAI API Key\n",
    "\n",
    "Provide your OpenAI API key as the `OPENAI_API_KEY` environment variable or run the code snippet below. If the variable is not set, then you'll be prompted for your key and it will be used during this session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from getpass import getpass\n",
    "\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if (openai_key == None):\n",
    "    openai_key = getpass('Provide your OpenAI API key: ')\n",
    "\n",
    "if (not openai_key):\n",
    "    raise Exception('No OpenAI API key provided. Please set the OPENAI_API_KEY environment variable or provide it when prompted.')\n",
    "\n",
    "openai.api_key = openai_key\n",
    "\n",
    "print('OpenAI API key set.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sample Dataset\n",
    "\n",
    "The notebook uses a [movies dataset](https://huggingface.co/datasets/denismagda/movies/blob/main/README.md) from the Hugging Face with over 45,000 movies and 26 million ratings from over 270,000 users. The dataset comes with pre-generated embeddings for the movies' overviews. The embeddings were generated with the OpenAI `text-embedding-ada-002` model.\n",
    "\n",
    "First, download the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "\n",
    "schema_file = \"https://huggingface.co/datasets/denismagda/movies/raw/main/movie_schema.sql\"\n",
    "data_file = \"https://huggingface.co/datasets/denismagda/movies/resolve/main/movie_data_with_openai_embeddings.sql\"\n",
    "\n",
    "print('Downloading the schema file...')\n",
    "wget.download(schema_file)\n",
    "\n",
    "# This file is 900MB, so it might take a minute to download it\n",
    "print('Downloading the data file...')\n",
    "wget.download(data_file)\n",
    "\n",
    "print('Finished downloading the files.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, open a database connection using the psycopg2 driver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "print('Connecting to PostgreSQL...')\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=password\")\n",
    "    \n",
    "cursor = conn.cursor()\n",
    "\n",
    "print('Successfully connected to PostgreSQL.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, load the schema and data into Postgres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Creating the schema...')\n",
    "schema_file = open('movie_schema.sql', 'r')\n",
    "cursor.execute(schema_file.read())\n",
    "conn.commit()\n",
    "\n",
    "print('Loading the data. It might take a minute...')\n",
    "data_file = open('movie_data_with_openai_embeddings.sql', 'r')\n",
    "cursor.execute(data_file.read())\n",
    "conn.commit()\n",
    "\n",
    "cursor.execute('SELECT COUNT(*) FROM movie')\n",
    "result = cursor.fetchone()\n",
    "\n",
    "print(f'{result[0]} movies loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Vector Similarity Search\n",
    "\n",
    "The dataset already stores a vectorized representation of a movie overview in the `overview_vector` column. Each vector is a 1536-dimensional embedding generated with the OpenAI `text-embedding-ada-002` model.\n",
    "\n",
    "First, define several functions that generate vectors for user prompts and configure the matching threshold and count parameters for the similarity search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the prompt to the pgvector embedding\n",
    "def get_embedding(prompt):\n",
    "    response = openai.embeddings.create(\n",
    "        input=prompt,\n",
    "        model='text-embedding-ada-002')\n",
    "\n",
    "    embedding = response.data[0].embedding\n",
    "\n",
    "    # Converting the embedding to the pgvector and returning it\n",
    "    return '[' + ','.join(map(str, embedding)) + ']'\n",
    "\n",
    "# Getting the matching threshold for the similarity search\n",
    "def get_matching_threshold():\n",
    "    return 0.7\n",
    "\n",
    "# Getting the number of matching movies to return\n",
    "def get_matching_count():\n",
    "    return 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, find the most relevant movies for a provided user prompt by calculating the cosine distance (`<=>`) between the prompt's and movies' embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = 'A movie about a space adventure.'\n",
    "\n",
    "prompt_vector = get_embedding(user_prompt)\n",
    "\n",
    "cursor.execute(\n",
    "    'SELECT title, overview '\n",
    "    'FROM movie WHERE 1 - (overview_vector <=> %(prompt_vector)s) >= %(match_threshold)s '\n",
    "    'ORDER BY overview_vector <=> %(prompt_vector)s LIMIT %(match_cnt)s',\n",
    "    {'prompt_vector': prompt_vector, 'match_threshold': get_matching_threshold(), 'match_cnt': get_matching_count()}\n",
    "    )\n",
    "\n",
    "result = cursor.fetchall()\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Filter Data Before Similarity Search\n",
    "\n",
    "As a general purpose relational database, PostgreSQL allows you to pre-filter data before a vector search is started. You can pre-filter by specifying a condition on non-vector columns in the `WHERE` clause of a query statement. \n",
    "\n",
    "For instance, imagine the user selecting the `Science Fiction` category and asking to suggest movies with rating `7` or higher. Then, the user prompts for `A movie about a space adventure.`. The final SQL query can look as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = 'A movie about a space adventure.'\n",
    "\n",
    "prompt_vector = get_embedding(user_prompt)\n",
    "\n",
    "cursor.execute(\n",
    "    'SELECT title, vote_average, genres '\n",
    "    'FROM movie WHERE vote_average >= 7 '\n",
    "    'AND EXISTS (SELECT 1 FROM jsonb_array_elements(genres) as genres_obj WHERE genres_obj ->> \\'name\\' = \\'Science Fiction\\') '\n",
    "    'AND 1 - (overview_vector <=> %(prompt_vector)s) >= %(match_threshold)s '\n",
    "    'ORDER BY overview_vector <=> %(prompt_vector)s LIMIT %(match_cnt)s',\n",
    "    {'prompt_vector': prompt_vector, 'match_threshold': get_matching_threshold(), 'match_cnt': get_matching_count()}\n",
    "    )\n",
    "\n",
    "result = cursor.fetchall()\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on a selected execution plan, PostgreSQL can pre-filter data with one of the following columns:\n",
    "\n",
    "* The `vote_average` column stores a rank from `1` through `10`. \n",
    "* The `genres` column is an array of JSON objects stored in the JSONB format. A movie can be categorized by several genres with a sample value looking as follows - `[{'id': 12, 'name': 'Adventure'}, {'id': 18, 'name': 'Drama'}, {'id': 878, 'name': 'Science Fiction'}])`\n",
    "\n",
    "Run the `EXPLAIN` statement if you'd like to see currenlty selected execution plan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = 'A movie about a space adventure.'\n",
    "\n",
    "prompt_vector = get_embedding(user_prompt)\n",
    "\n",
    "cursor.execute(\n",
    "    'EXPLAIN (costs off) SELECT title, vote_average, genres '\n",
    "    'FROM movie WHERE vote_average >= 7 '\n",
    "    'AND EXISTS (SELECT 1 FROM jsonb_array_elements(genres) as genres_obj WHERE genres_obj ->> \\'name\\' = \\'Science Fiction\\') '\n",
    "    'AND 1 - (overview_vector <=> %(prompt_vector)s) >= %(match_threshold)s '\n",
    "    'ORDER BY overview_vector <=> %(prompt_vector)s LIMIT %(match_cnt)s',\n",
    "    {'prompt_vector': prompt_vector, 'match_threshold': get_matching_threshold(), 'match_cnt': get_matching_count()}\n",
    "    )\n",
    "\n",
    "result = cursor.fetchall()\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated plan should look as follows:\n",
    "```sql\n",
    "('Limit',)\n",
    "('  ->  Sort',)\n",
    "(\"        Sort Key: ((movie.overview_vector <=> '[0.015902195,-0.03861236,...]'::vector))\",)\n",
    "('        ->  Seq Scan on movie',)\n",
    "(\"              Filter: ((vote_average >= '7'::numeric) AND (('1'::double precision - (overview_vector <=> '[0.015902195,-0.03861236,...]'::vector)) >= '0.7'::double precision) AND (SubPlan 1))\",)\n",
    "('              SubPlan 1',)\n",
    "('                ->  Function Scan on jsonb_array_elements genres_obj',)\n",
    "(\"                      Filter: ((value ->> 'name'::text) = 'Science Fiction'::text)\",)\n",
    "```\n",
    "\n",
    "The plan shows that the data is first filtered by the `vote_average` column following by the similarity search on the `overview_vector` column and scan on the `genres` column. Note, PostgreSQL can generate another plan if you create an index for any of the columns or other conditions are changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Vector Search With HNSW Index\n",
    "\n",
    "As of now, there `vector_overview` column is not indexed. It means that the database performs the exact nearest neighbor search by comparing a user prompt's vector to all the embeddings to all movies' overviews. You can confirm that by checking the execution plan that will show the `Seq Scan` (full table scan) on the `movie` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = 'A movie about a space adventure.'\n",
    "\n",
    "prompt_vector = get_embedding(user_prompt)\n",
    "\n",
    "cursor.execute(\n",
    "    'EXPLAIN (costs off) SELECT title, overview '\n",
    "    'FROM movie WHERE 1 - (overview_vector <=> %(prompt_vector)s) >= %(match_threshold)s '\n",
    "    'ORDER BY overview_vector <=> %(prompt_vector)s LIMIT %(match_cnt)s',\n",
    "    {'prompt_vector': prompt_vector, 'match_threshold': get_matching_threshold(), 'match_cnt': get_matching_count()}\n",
    "    )\n",
    "\n",
    "result = cursor.fetchall()\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postgres pgvector supports the IVFFlat and HNSW indexes that are two most widespread index types across vector databases.\n",
    "\n",
    "Let's create an HNSW index on the embeddings stored in the `overview_vector` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Building the index. It might take a minute...')\n",
    "\n",
    "# Build the index\n",
    "conn.autocommit = True\n",
    "cursor.execute(\n",
    "    'CREATE INDEX movie_overview_hnsw_idx ON movie '\n",
    "    'USING hnsw (overview_vector vector_cosine_ops) '\n",
    "    'WITH (m = 4, ef_construction = 10)')\n",
    "\n",
    "# Update the statistics for the query planner\n",
    "# to ensure that the index is used for the vector similarity search\n",
    "cursor.execute(\n",
    "    'VACUUM ANALYZE movie')\n",
    "conn.autocommit = False\n",
    "\n",
    "print('HNSW Index created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the execution plan one more time for the earlier query returning the most relevant movies for the user prompt to make sure that Postgres now expedites the similarity search with the just-created index. You should see the `Index Scan` on the `movie` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = 'A movie about a space adventure.'\n",
    "\n",
    "prompt_vector = get_embedding(user_prompt)\n",
    "\n",
    "cursor.execute(\n",
    "    'EXPLAIN (costs off) SELECT title, overview '\n",
    "    'FROM movie WHERE 1 - (overview_vector <=> %(prompt_vector)s) >= %(match_threshold)s '\n",
    "    'ORDER BY overview_vector <=> %(prompt_vector)s LIMIT %(match_cnt)s',\n",
    "    {'prompt_vector': prompt_vector, 'match_threshold': get_matching_threshold(), 'match_cnt': get_matching_count()}\n",
    "    )\n",
    "\n",
    "result = cursor.fetchall()\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn More\n",
    "\n",
    "Deepen and broaden your knowledge about Postgres as a database for generative AI applications by studying the following resources (your vector YouTube series, CrunchyData HNSW and other articles, your PostgresML video)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
