{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDlIS3wQHA9R"
   },
   "source": [
    "# How to Use the Assistants API to Build a Math Chatbot with a Code Interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGjdMMB_HPuy"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Welcome to this tutorial on utilizing the OpenAI Assistants API to build an interactive Math Chatbot with a Code Interpreter feature.\n",
    "\n",
    "The OpenAI Assistants API enables developers to create sophisticated AI-powered assistants within applications. It offers tools such as **Code Interpreter**, **Retrieval**, and **Function Calling**. The API supports models like GPT-3.5 or GPT-4 and can be integrated into various applications for use cases including mentoring, customer support, and more.\n",
    "\n",
    "In this tutorial, we will explore how to use the Assistants API with the **Code Interpreter** to build a math mentoring chatbot. This chatbot will engage users conversationally and automatically interpret and execute code snippets for math problems, making it a versatile learning and problem-solving tool in mathematics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXhfxSwPHU2p"
   },
   "source": [
    "## Setting Up the Environment\n",
    "\n",
    "First, install the necessary Python packages. Run the following command to install OpenAI and Gradio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zja8vsBMHX0u",
    "outputId": "96d308c4-0fe3-43f5-eee4-9f35467ce921"
   },
   "outputs": [],
   "source": [
    "!pip install openai gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yq55ZuapHkm7"
   },
   "source": [
    "Then, provide your OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WtwZpaOIHYlq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'your_api_key_here'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Auth6yB6I52o"
   },
   "source": [
    "## Creating an Assistant\n",
    "\n",
    "We will create an Assistant to manage interactions with the OpenAI Assistants API. An Assistant is an entity that can be configured to respond to user messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "lgvrJ6GpIEYD"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.Client()\n",
    "\n",
    "def create_assistant():\n",
    "  return client.beta.assistants.create(\n",
    "    name=\"Math Mentor\",\n",
    "    instructions=\"You are a supportive and engaging math mentor for school children, utilizing a code interpreter for accurate problem-solving. Simplify complex concepts with age-appropriate language and examples, ensuring content alignment with educational standards while maintaining child safety and privacy.\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    model=\"gpt-3.5-turbo-1106\" # Can find out all models at https://openai.com/pricing\n",
    "  )\n",
    "\n",
    "\n",
    "assistant = create_assistant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZluGkqpKtwD"
   },
   "source": [
    "Large language models (LLMs) like GPT-4 have impressive capabilities across a broad range of tasks, such as predicting the next word. However, they have limitations, such as lack of precision in computation and handling complex calculations. Using a code interpreter or additional tools can be particularly beneficial in these cases. To demonstrate the use of the Code Interpreter, we are creating an Assistant as a Math Mentor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpTz4P6oRfIE"
   },
   "source": [
    "### Creating a Thread\n",
    "A Thread represents an ongoing conversation with a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "LGjC7o_KRoiI"
   },
   "outputs": [],
   "source": [
    "client = openai.Client()\n",
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMT2S4KDVWQi"
   },
   "source": [
    "## Sending a User Message\n",
    "\n",
    "To send a user message, create a message containing user queries and possibly files.\n",
    "\n",
    "Then, create a Run. The Assistant reads the Thread and decides whether to call tools, e.g., Code Interpreter, or use the model to answer.\n",
    "\n",
    "Periodically retrieve the Run to check its status and see if it has moved to `completed` or `failed`.\n",
    "\n",
    "Once it is `completed`, you can `yield` the `'assistant'` message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "LugoWzfsKkmk"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def ask_assistant(assistant, thread_id, question):\n",
    "  client.beta.threads.messages.create(\n",
    "      thread_id=thread_id,\n",
    "      role=\"user\",\n",
    "      content=question\n",
    "  )\n",
    "\n",
    "  run = client.beta.threads.runs.create(\n",
    "      thread_id=thread_id,\n",
    "      assistant_id=assistant.id\n",
    "  )\n",
    "\n",
    "  print(\"retrieving data...\")\n",
    "  while True:\n",
    "    # Retrieve the current status of the Run\n",
    "    run_status = client.beta.threads.runs.retrieve(\n",
    "      thread_id=thread_id,\n",
    "      run_id=run.id\n",
    "    )\n",
    "\n",
    "    # Check if the Run is completed\n",
    "    print(f\"run status: {run_status.status}\")\n",
    "    if run_status.status == 'completed':\n",
    "        print(\"Run is completed\")\n",
    "        break\n",
    "    elif run_status.status == 'failed':\n",
    "        yield f\"Error occurred!\"\n",
    "        return  # Exit the function after yielding the error message\n",
    "\n",
    "    # If not completed, wait for some time before next check\n",
    "    time.sleep(1)  # Waits for 1 second before the next check\n",
    "\n",
    "  messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    "  )\n",
    "  print(messages)\n",
    "\n",
    "  for message in messages.data:\n",
    "    # Check if the message belongs to the current run, and it's assistant message\n",
    "    if message.run_id == run.id and message.role == 'assistant':\n",
    "        for content in message.content:\n",
    "            yield content.text.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbX0X6jlRFCl"
   },
   "source": [
    "Test this method and print out the `yield`ed messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w2Iksl5DbfXc",
    "outputId": "0c6ba0de-4932-49c6-d7fb-e1334b47bab8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieving data...\n",
      "run status: queued\n",
      "run status: in_progress\n",
      "run status: in_progress\n",
      "run status: in_progress\n",
      "run status: in_progress\n",
      "run status: in_progress\n",
      "run status: in_progress\n",
      "run status: in_progress\n",
      "run status: in_progress\n",
      "run status: completed\n",
      "Run is completed\n",
      "SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_JvU65Egnn89RpFi7s9n23vnk', assistant_id='asst_4PUSw6z2aWKoXUG0KVWPuGLP', content=[MessageContentText(text=Text(annotations=[], value='The solution to the equation 3x + 11 = 14 is x = 1.'), type='text')], created_at=1699599855, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_SiPo84eL1cyVsiYnscAJ0S36', thread_id='thread_7ICt9Lzwf23CRGFZqRRDYWoo'), ThreadMessage(id='msg_hG5V7MoIZv2jGMGrSSl3FtGU', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='I need to solve the equation 3x + 11 = 14. Can you help me?'), type='text')], created_at=1699599845, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_7ICt9Lzwf23CRGFZqRRDYWoo'), ThreadMessage(id='msg_OyXOBEOWp0vTcElApMykogds', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='I need to solve the equation 3x + 11 = 14. Can you help me?'), type='text')], created_at=1699599533, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_7ICt9Lzwf23CRGFZqRRDYWoo')], object='list', first_id='msg_JvU65Egnn89RpFi7s9n23vnk', last_id='msg_OyXOBEOWp0vTcElApMykogds', has_more=False)\n",
      "The solution to the equation 3x + 11 = 14 is x = 1.\n"
     ]
    }
   ],
   "source": [
    "for message in ask_assistant(assistant, thread.id, \"I need to solve the equation 3x + 11 = 14. Can you help me?\"):\n",
    "  print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqEmFftMW0d5"
   },
   "source": [
    "## Integrating Gradio for a Web Interface\n",
    "\n",
    "Gradio is a Python library that simplifies creating UIs for machine learning models, ideal for quickly deploying models as web applications.\n",
    "\n",
    "We will use `ChatInterface` to create a Chat Web UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "liJOsCOUNSFm"
   },
   "outputs": [],
   "source": [
    "def chat_with_math_mentor(user_input, history):\n",
    "  # Chat with AI with defined assistant and thread\n",
    "  yield from ask_assistant(assistant, thread.id, user_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "id": "pQ0xQQysYI3w",
    "outputId": "9d306d18-620d-4ced-cf26-58e2ae23ee3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "Running on public URL: https://6f1a6b282e600408fa.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://6f1a6b282e600408fa.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "chat = gr.ChatInterface(\n",
    "    chat_with_math_mentor,\n",
    "    chatbot=gr.Chatbot(height=300),\n",
    "    textbox=gr.Textbox(placeholder=\"I can help you with math questions\", container=False, scale=7),\n",
    "    title=\"Math Mentor\",\n",
    "    description=\"Ask Math Mentor any math question\",\n",
    "    theme=\"soft\",\n",
    "    examples=[\"I need to solve the equation 3x + 11 = 14. Can you help me?\", \"3 ** 4\", \"What's linear regression?\"],\n",
    "  ).queue()\n",
    "\n",
    "chat.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fb93bf",
   "metadata": {},
   "source": [
    "## Conclusion and Further Learning\n",
    "\n",
    "Congratulations on completing this tutorial! You now have a solid understanding of how to use the OpenAI Assistants API with the Code Interpreter to create an intelligent math chatbot.\n",
    "\n",
    "For further learning, explore these resources:\n",
    "- [OpenAI API Documentation](https://platform.openai.com/docs/assistants/overview)\n",
    "- [Gradio Documentation](https://gradio.app/docs/)\n",
    "\n",
    "Please check out the runnable Notebook on [Kaggle](https://www.kaggle.com/code/jakelinai/use-openai-assistants-api-with-code-interpreter)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
