{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e67f200",
   "metadata": {},
   "source": [
    "# How to generate function arguments with the Chat Completions API\n",
    "\n",
    "This notebook covers how to use the Chat Completions API to generate function arguments\n",
    "\n",
    "`functions` is an optional parameter in the Chat Completion API which can be used to provide function specifications. The purpose of this is to enable models to generate function arguments which adhere to function input schemas. Note that the API will not actually execute any function calls. It is up to developers to execute function calls using model outputs.\n",
    "\n",
    "If the `functions` parameter is provided then by default the model will decide when it is appropriate to use one of the functions. The API can be forced to use a specific function by setting the `function_call` parameter to `{\"name\": \"<insert-function-name>\"}`. The API can also be forced to not use any function by setting the `function_call` parameter to `\"none\"`. If a function is used, the output will contain `\"finish_reason\": \"function_message\"` in the response, as well as a `function_call` object that has the name of the function and the generated function arguments.\n",
    "\n",
    "Functions are specified with the following fields:\n",
    "\n",
    "- **Name:** The name of the function.\n",
    "- **Description:** A description of what the function does. This will help the model decide when to use it.\n",
    "- **Parameters:** The parameters object contains all of the input fields the function requires. These inputs can be of the following types: String, Number, Boolean, Object, Null, AnyOf. Refer to the [API reference docs](https://platform.openai.com/docs/api-reference/chat) for details.\n",
    "- **Required:** Which of the parameters are required to make a query. The rest will be treated as optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80e71f33",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/joe/.virtualenvs/openai-cookbook/lib/python3.9/site-packages (0.27.8)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/joe/.virtualenvs/openai-cookbook/lib/python3.9/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/joe/.virtualenvs/openai-cookbook/lib/python3.9/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /Users/joe/.virtualenvs/openai-cookbook/lib/python3.9/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/joe/.virtualenvs/openai-cookbook/lib/python3.9/site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/joe/.virtualenvs/openai-cookbook/lib/python3.9/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/joe/.virtualenvs/openai-cookbook/lib/python3.9/site-packages (from requests>=2.20->openai) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/joe/.virtualenvs/openai-cookbook/lib/python3.9/site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/joe/.virtualenvs/openai-cookbook/lib/python3.9/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/joe/.virtualenvs/openai-cookbook/lib/python3.9/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/joe/.virtualenvs/openai-cookbook/lib/python3.9/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/joe/.virtualenvs/openai-cookbook/lib/python3.9/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/joe/.virtualenvs/openai-cookbook/lib/python3.9/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/joe/.virtualenvs/openai-cookbook/lib/python3.9/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: requests in /Users/joe/.virtualenvs/openai-cookbook/lib/python3.9/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/joe/.virtualenvs/openai-cookbook/lib/python3.9/site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/joe/.virtualenvs/openai-cookbook/lib/python3.9/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/joe/.virtualenvs/openai-cookbook/lib/python3.9/site-packages (from requests) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/joe/.virtualenvs/openai-cookbook/lib/python3.9/site-packages (from requests) (2023.5.7)\n",
      "Requirement already satisfied: termcolor in /Users/joe/.virtualenvs/openai-cookbook/lib/python3.9/site-packages (2.3.0)\n",
      "Requirement already satisfied: tenacity in /Users/joe/.virtualenvs/openai-cookbook/lib/python3.9/site-packages (8.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install requests\n",
    "!pip install termcolor\n",
    "!pip install tenacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dab872c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import requests\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from termcolor import colored\n",
    "\n",
    "GPT_MODEL = \"gpt-3.5-turbo-0613\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ee6a93",
   "metadata": {},
   "source": [
    "## Utilities\n",
    "\n",
    "First let's define a few utilities for making calls to the Chat Completions API and for maintaining and keeping track of the conversation state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "745ceec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, functions=None, function_call=None, model=GPT_MODEL):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
    "    }\n",
    "    json_data = {\"model\": model, \"messages\": messages}\n",
    "    if functions is not None:\n",
    "        json_data.update({\"functions\": functions})\n",
    "    if function_call is not None:\n",
    "        json_data.update({\"function_call\": function_call})\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=json_data,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4d1c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conversation:\n",
    "    def __init__(self):\n",
    "        self.conversation_history = []\n",
    "\n",
    "    def add_message(self, role, content):\n",
    "        message = {\"role\": role, \"content\": content}\n",
    "        self.conversation_history.append(message)\n",
    "\n",
    "    def display_conversation(self, detailed=False):\n",
    "        role_to_color = {\n",
    "            \"system\": \"red\",\n",
    "            \"user\": \"green\",\n",
    "            \"assistant\": \"blue\",\n",
    "            \"function\": \"magenta\",\n",
    "        }\n",
    "        for message in self.conversation_history:\n",
    "            print(\n",
    "                colored(\n",
    "                    f\"{message['role']}: {message['content']}\\n\\n\",\n",
    "                    role_to_color[message[\"role\"]],\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d4e02b",
   "metadata": {},
   "source": [
    "## Basic concepts\n",
    "\n",
    "Next we'll create a specification for a function called ```get_current_weather```. Later we'll pass this function specification to the API in order to generate function arguments that adhere to the specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2e25069",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"format\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\", \"format\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_n_day_weather_forecast\",\n",
    "        \"description\": \"Get an N-day weather forecast\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"format\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                },\n",
    "                \"num_days\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"The number of days to forecast\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\", \"format\", \"num_days\"]\n",
    "        },\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84da169e",
   "metadata": {},
   "source": [
    "If we prompt the model about the current weather, it will respond with some clarifying questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "854b6e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': 'Sure, could you please provide me with the location?'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = Conversation()\n",
    "conversation.add_message(\"system\", \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\")\n",
    "conversation.add_message(\"user\", \"What's the weather like today\")\n",
    "chat_response = chat_completion_request(\n",
    "    conversation.conversation_history, functions=functions\n",
    ")\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "conversation.add_message(assistant_message[\"role\"], assistant_message[\"content\"])\n",
    "assistant_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f50a35",
   "metadata": {},
   "source": [
    "Once we provide the missing information, it will generate the appropriate function arguments for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db30364f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': None,\n",
       " 'function_call': {'name': 'get_current_weather',\n",
       "  'arguments': '{\\n  \"location\": \"Glasgow, Scotland\",\\n  \"format\": \"celsius\"\\n}'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.add_message(\"user\", \"I'm in Glasgow, Scotland.\")\n",
    "chat_response = chat_completion_request(\n",
    "    conversation.conversation_history, functions=functions\n",
    ")\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "conversation.add_message(assistant_message[\"role\"], assistant_message[\"content\"])\n",
    "assistant_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae365c5",
   "metadata": {},
   "source": [
    "By prompting it differently, we can get it to target the other function we've told it about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80c3716d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': 'Sure, I can help you with that. Please provide me with the number of days you would like to forecast.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = Conversation()\n",
    "conversation.add_message(\"system\", \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\")\n",
    "conversation.add_message(\"user\", \"what is the weather going to be like in Glasgow, Scotland over the next x days\")\n",
    "chat_response = chat_completion_request(\n",
    "    conversation.conversation_history, functions=functions\n",
    ")\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "conversation.add_message(assistant_message[\"role\"], assistant_message[\"content\"])\n",
    "assistant_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27550756",
   "metadata": {},
   "source": [
    "Once again, the model is asking us for clarification because it doesn't have enough information yet. In this case it already knows the location for the forecast, but it needs to know how many days are required in the forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f4e1bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 0,\n",
       " 'message': {'role': 'assistant',\n",
       "  'content': None,\n",
       "  'function_call': {'name': 'get_n_day_weather_forecast',\n",
       "   'arguments': '{\\n  \"location\": \"Glasgow, Scotland\",\\n  \"format\": \"celsius\",\\n  \"num_days\": 5\\n}'}},\n",
       " 'finish_reason': 'function_call'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.add_message(\"user\", \"5 days\")\n",
    "chat_response = chat_completion_request(\n",
    "    conversation.conversation_history, functions=functions\n",
    ")\n",
    "chat_response.json()[\"choices\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf236e1",
   "metadata": {},
   "source": [
    "We can force the model to use a specific function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9e0991b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': None,\n",
       " 'function_call': {'name': 'get_n_day_weather_forecast',\n",
       "  'arguments': '{\\n  \"location\": \"Toronto, Canada\",\\n  \"format\": \"celsius\",\\n  \"num_days\": 1\\n}'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by forcing the model to use a specific function, it is forced to make assumptions about how to use it\n",
    "conversation = Conversation()\n",
    "conversation.add_message(\"system\", \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\")\n",
    "conversation.add_message(\"user\", \"Give me a weather report for Toronto, Canada.\")\n",
    "chat_response = chat_completion_request(\n",
    "    conversation.conversation_history, functions=functions, function_call={\"name\": \"get_n_day_weather_forecast\"}\n",
    ")\n",
    "chat_response.json()[\"choices\"][0][\"message\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe872a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': None,\n",
       " 'function_call': {'name': 'get_current_weather',\n",
       "  'arguments': '{\\n  \"location\": \"Toronto, Canada\",\\n  \"format\": \"celsius\"\\n}'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we don't force the model to use get_n_day_weather_forecast it may not\n",
    "conversation = Conversation()\n",
    "conversation.add_message(\"system\", \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\")\n",
    "conversation.add_message(\"user\", \"Give me a weather report for Toronto, Canada.\")\n",
    "chat_response = chat_completion_request(\n",
    "    conversation.conversation_history, functions=functions, \n",
    ")\n",
    "chat_response.json()[\"choices\"][0][\"message\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ae80cf",
   "metadata": {},
   "source": [
    "We can also force the model to not use a function at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f20f6a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '{\\n  \"location\": \"Toronto, Canada\",\\n  \"format\": \"celsius\"\\n}'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we force the model to not use a function, we prevent it from outputting a proper function call\n",
    "conversation = Conversation()\n",
    "conversation.add_message(\"system\", \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\")\n",
    "conversation.add_message(\"user\", \"Give me the current weather (use Celcius) for Toronto, Canada.\")\n",
    "chat_response = chat_completion_request(\n",
    "    conversation.conversation_history, functions=functions, function_call=\"none\"\n",
    ")\n",
    "chat_response.json()[\"choices\"][0][\"message\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be73fbc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
