{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI API + [Weights & Biases](https://wandb.ai/site) Integration\n",
    "\n",
    "Learn more about LLMOps at https://wandb.me/prompts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üí° **Beta Integration**: This is a new feature, and we're actively working on making this better. Please reach out if you have any feedback ‚Äî contact@wandb.com"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI‚Äôs API gives practitioners access to GPT-4, an incredibly powerful natural language model that can be applied to virtually any task that involves understanding or generating natural language.\n",
    "\n",
    "## Log OpenAI API calls in 1 line of code\n",
    "With just 1 line of code you can now automatically log inputs and outputs from the OpenAI Python SDK to Weights & Biases! \n",
    "\n",
    "![](./open_ai_autolog.png)\n",
    "\n",
    "To get started, pip install the `wandb` library, then follow the steps below:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import autolog and initialise it\n",
    "First, import `autolog` from `wandb.integration.openai` and initialise it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from wandb.integration.openai import autolog\n",
    "\n",
    "autolog({\"project\":\"gpt5\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can optionally pass a dictionary with argument that `wandb.init()` accepts to `autolog`. This includes a project name, team name, entity, and more. For more information about [`wandb.init`](https://docs.wandb.ai/ref/python/init), see the API Reference Guide."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Call the OpenAI API\n",
    "Each call you make to the OpenAI API will now be logged to Weights & Biases automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"XXX\"\n",
    "\n",
    "chat_request_kwargs = dict(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"},\n",
    "    ],\n",
    ")\n",
    "response = openai.ChatCompletion.create(**chat_request_kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. View your OpenAI API inputs and responses\n",
    "\n",
    "Click on the Weights & Biases [run](https://docs.wandb.ai/guides/runs) link generated by `autolog` in **step 1**. This will redirect you to your project workspace in the W&B App.\n",
    "\n",
    "Select a run you created to view the trace table, trace timeline and the model architecture of the OpenAI LLM used."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Disable autolog\n",
    "We recommend that you call `disable()` to close all W&B processes when you are finished using the OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autolog.disable()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your inputs and completions will be logged to Weights & Biases, ready for analysis or to be shared with colleagues."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log OpenAI fine-tunes to W&B\n",
    "\n",
    "If you use OpenAI's API to [fine-tune GPT-3](https://beta.openai.com/docs/guides/fine-tuning), you can now use the W&B integration to track experiments, models, and datasets in your central dashboard.\n",
    "\n",
    "![](./open_ai_api.png)\n",
    "\n",
    "All it takes is one line: `openai wandb sync`\n",
    "\n",
    "## ‚ú® Check out interactive examples\n",
    "\n",
    "* [Demo Colab](http://wandb.me/openai-colab)\n",
    "* [Report - GPT-3 Exploration and Fine-Tuning Tips](http://wandb.me/openai-report)\n",
    "\n",
    "## üéâ Sync your fine-tunes with one line!\n",
    "\n",
    "Make sure you are using latest version of openai and wandb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade openai wandb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then sync your results from the command line or from your script."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one line command\n",
    "!openai wandb sync\n",
    "\n",
    "# passing optional parameters\n",
    "!openai wandb sync --help"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.wandb_logger import WandbLogger\n",
    "\n",
    "# one line command\n",
    "WandbLogger.sync()\n",
    "\n",
    "# passing optional parameters\n",
    "WandbLogger.sync(\n",
    "    id=None,\n",
    "    n_fine_tunes=None,\n",
    "    project=\"GPT-3\",\n",
    "    entity=None,\n",
    "    force=False,\n",
    "    **kwargs_wandb_init\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scan for new completed fine-tunes and automatically add them to your dashboard.\n",
    "\n",
    "![](./open_ai_auto_scan.png)\n",
    "\n",
    "In addition your training and validation files are logged and versioned, as well as details of your fine-tune results. This let you interactively explore your training and validation data.\n",
    "\n",
    "![](./open_ai_validation_files.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Optional arguments\n",
    "\n",
    "| Argument                 | Description                                                                                                               |\n",
    "| ------------------------ | ------------------------------------------------------------------------------------------------------------------------- |\n",
    "| -i ID, --id ID           | The id of the fine-tune (optional)                                                                                        |\n",
    "| -n N, --n\\_fine\\_tunes N | Number of most recent fine-tunes to log when an id is not provided. By default, every fine-tune is synced.                |\n",
    "| --project PROJECT        | Name of the project where you're sending runs. By default, it is \"GPT-3\".                                                 |\n",
    "| --entity ENTITY          | Username or team name where you're sending runs. By default, your default entity is used, which is usually your username. |\n",
    "| --force                  | Forces logging and overwrite existing wandb run of the same fine-tune.                                                    |\n",
    "| \\*\\*kwargs\\_wandb\\_init  | In python, any additional argument is directly passed to [`wandb.init()`](https://docs.wandb.ai/ref/python/init)                    |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Inspect sample predictions\n",
    "\n",
    "Use [Tables](https://docs.wandb.ai/guides/data-vis) to better visualize sample predictions and compare models.\n",
    "\n",
    "![](./open_ai_inspect_sample.png)\n",
    "\n",
    "Create a new run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=\"GPT-3\", job_type=\"eval\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve a model id for inference.\n",
    "\n",
    "You can use automatically logged artifacts to retrieve your latest model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_job = run.use_artifact(\"ENTITY/PROJECT/fine_tune_details:latest\")\n",
    "fine_tuned_model = artifact_job.metadata[\"fine_tuned_model\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also retrieve your validation file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_valid = run.use_artifact(\"ENTITY/PROJECT/FILENAME:latest\")\n",
    "valid_file = artifact_valid.get_path(\"FILENAME\").download()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform some inferences using OpenAI API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform inference and record results\n",
    "my_prompts = [\"PROMPT_1\", \"PROMPT_2\"]\n",
    "results = []\n",
    "for prompt in my_prompts:\n",
    "    res = openai.Completion.create(model=fine_tuned_model,\n",
    "                                   prompt=prompt,\n",
    "                                   ...)\n",
    "    results.append(res[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log your results with a Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = wandb.Table(columns=['prompt', 'completion'],\n",
    "                    data=list(zip(my_prompts, results)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìï Resources\n",
    "\n",
    "* [OpenAI Fine-tuning Documentation](https://beta.openai.com/docs/guides/fine-tuning) is very thorough and contains many useful tips\n",
    "* [Demo Colab](http://wandb.me/openai-colab)\n",
    "* [Report - GPT-3 Exploration & Fine-tuning Tips](http://wandb.me/openai-report)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
