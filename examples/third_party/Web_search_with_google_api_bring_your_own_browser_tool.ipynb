{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Building a Bring Your Own Browser (BYOB) Tool for Web Browsing and Summarization\n",
    "\n",
    "**Disclaimer: This cookbook is for educational purposes only. Ensure that you comply with all applicable laws and service terms when using web search and scraping technologies. This cookbook will restrict the search to openai.com domain to retrieve the public information to illustrate the concepts.**\n",
    "\n",
    "Large Language Models (LLMs) like GPT-4 have a knowledge cutoff date, which means they lack information about events that occurred after that point. In scenarios where the most recent data is essential, it's necessary to provide LLMs with access to current web information to ensure accurate and relevant responses.\n",
    "\n",
    "In this guide, we will build a Bring Your Own Browser (BYOB) tool using Python to overcome this limitation. Our goal is to create a system that helps us compile a list of the most recent product launches by OpenAI. By integrating web search capabilities with an LLM, we'll enable the model to generate responses based on the latest information available online.\n",
    "\n",
    "While you can use any publicly available search APIs, we'll utilize Google's Custom Search API to perform web searches. The retrieved information from the search results will be processed and passed to the LLM to generate the final response through Retrieval-Augmented Generation (RAG).\n",
    "\n",
    "**Bring Your Own Browser (BYOB)** tools allow users to perform web browsing tasks programmatically. In this notebook, we'll create a BYOB tool that:\n",
    "\n",
    "**#1 Set Up a Search Engine:** Use a public search API, like Google's Custom Search API, to perform web searches and obtain a list of relevant search results.  \n",
    "\n",
    "**#2 Build a Search Dictionary:** Collect the title, URL, and a summary of each web page from the search results to create a structured dictionary of information.  \n",
    "\n",
    "**#3. Generate a RAG Response:** Implement Retrieval-Augmented Generation (RAG) by passing the gathered information to the LLM, which then generates a final response to the user's query.\n",
    "\n"
   ],
   "id": "7f59879cabc55a5e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Setting up a BYOB tool\n",
    "Before we begin, ensure you have the following: **Python 3.12 or later** installed on your machine. You will also need a Google Custom Search API key and Custom Search Engine ID (CSE ID). Necessary Python packages installed: `requests`, `beautifulsoup4`, `openai`. And ensure the OPENAI_API_KEY is set up as an environment variable.\n",
    "\n",
    "#### Step 1: Set Up a Search Engine to Provide Web Search Results\n",
    "You can use any publicly available web search APIs to perform this task. We will configure a custom search engine using Google's Custom Search API. This engine will fetch a list of relevant web pages based on the user's query, focusing on obtaining the most recent and pertinent results.  \n",
    "\n",
    "**a. Obtain API Credentials:** Acquire a Google API key and a Custom Search Engine ID (CSE ID) from the Google Developers Console. You can navigate to this [Programmable Search Engine Link](https://developers.google.com/custom-search/v1/overview) to set up an API key as well as Search Engine ID. \n",
    "\n",
    "**b. Configure Search Function:** The `search` function below sets up the search based on search term, the API and CSE ID keys, as well as number of search results to return. We'll introduce a parameter `site_filter` to restrict the output to only `openai.com`\n",
    "  "
   ],
   "id": "1a766088c001c30b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T16:47:32.104038Z",
     "start_time": "2024-09-13T16:47:32.006801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests  # For making HTTP requests to APIs and websites\n",
    "\n",
    "def search(search_item, api_key, cse_id, search_depth=10, site_filter=None):\n",
    "    service_url = 'https://www.googleapis.com/customsearch/v1'\n",
    "\n",
    "    params = {\n",
    "        'q': search_item,\n",
    "        'key': api_key,\n",
    "        'cx': cse_id,\n",
    "        'num': search_depth\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(service_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        results = response.json()\n",
    "\n",
    "        # Check if 'items' exists in the results\n",
    "        if 'items' in results:\n",
    "            if site_filter is not None:\n",
    "                \n",
    "                # Filter results to include only those with site_filter in the link\n",
    "                filtered_results = [result for result in results['items'] if site_filter in result['link']]\n",
    "\n",
    "                if filtered_results:\n",
    "                    return filtered_results\n",
    "                else:\n",
    "                    print(f\"No results with {site_filter} found.\")\n",
    "                    return []\n",
    "            else:\n",
    "                if 'items' in results:\n",
    "                    return results['items']\n",
    "                else:\n",
    "                    print(\"No search results found.\")\n",
    "                    return []\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred during the search: {e}\")\n",
    "        return []\n"
   ],
   "id": "7df836efe1589633",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**c. Identify the search terms for search engine:** Typically the natural language prompt does not produce the desired results on the search engine. An effective approach is to use LLM to produce the right search term before invoking the search function.   \n",
    "\n",
    "In this example, we have the `search_query` as the user's desire to list OpenAI product launches in the reverse chronological order. In order to retrieve meaningful results, we first invoke the search engine to produce relevant search terms. "
   ],
   "id": "dcee6754a2e6cd24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T16:47:34.931879Z",
     "start_time": "2024-09-13T16:47:33.487055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "search_query = \"List the latest OpenAI product launches in chronological order from latest to oldest in the past 2 years\"\n",
    "\n",
    "search_term = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Provide a google search term based on search query provided below in 3-4 words\"},\n",
    "        {\"role\": \"user\", \"content\": search_query}]\n",
    ").choices[0].message.content\n",
    "\n",
    "print(search_term)"
   ],
   "id": "3752702114df8160",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest OpenAI product launches\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**d. Invoke the search function:** Given the search result, we will invoke the search function to retrieve the results. The results only have the link of the web page and a snippet at this point. ",
   "id": "62b7194aedbc3a21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T16:47:37.401035Z",
     "start_time": "2024-09-13T16:47:36.493607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv('.env')\n",
    "\n",
    "api_key = os.getenv('API_KEY')\n",
    "cse_id = os.getenv('CSE_ID')\n",
    "\n",
    "search_items = search(search_item=search_term, api_key=api_key, cse_id=cse_id, search_depth=10, site_filter=\"https://openai.com\")\n"
   ],
   "id": "891e924b15957206",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T16:47:38.483644Z",
     "start_time": "2024-09-13T16:47:38.480621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for item in search_items:\n",
    "    print(f\"Link: {item['link']}\")\n",
    "    print(f\"Snippet: {item['snippet']}\\n\")"
   ],
   "id": "ceedee1eb3ffec85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link: https://openai.com/news/\n",
      "Snippet: Overview ; Product. Sep 12, 2024. Introducing OpenAI o1 ; Product. Jul 25, 2024. SearchGPT is a prototype of new AI search features ; Research. Jul 18, 2024. GPT- ...\n",
      "\n",
      "Link: https://openai.com/index/new-models-and-developer-products-announced-at-devday/\n",
      "Snippet: Nov 6, 2023 ... GPT-4 Turbo with 128K context · We released the first version of GPT-4 in March and made GPT-4 generally available to all developers in July.\n",
      "\n",
      "Link: https://openai.com/news/product/\n",
      "Snippet: Discover the latest product advancements from OpenAI and the ways they're being used by individuals and businesses.\n",
      "\n",
      "Link: https://openai.com/\n",
      "Snippet: A new series of AI models designed to spend more time thinking before they respond. Learn more · (opens in a new window) ...\n",
      "\n",
      "Link: https://openai.com/index/sora/\n",
      "Snippet: Feb 15, 2024 ... We plan to include C2PA metadata(opens in a new window) in the future if we deploy the model in an OpenAI product. In addition to us developing ...\n",
      "\n",
      "Link: https://openai.com/api/\n",
      "Snippet: The most powerful platform for building AI products ... Build and scale AI experiences powered by industry-leading models and tools. Start building (opens in a ...\n",
      "\n",
      "Link: https://openai.com/index/introducing-gpts/\n",
      "Snippet: Nov 6, 2023 ... We plan to offer GPTs to more users soon. Learn more about our OpenAI DevDay announcements for new models and developer products.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 2: Build a Search Dictionary with Titles, URLs, and Summaries of Web Pages\n",
    "After obtaining the search results, we'll extract and organize the relevant information, so it can be passed to the LLM for final output. \n",
    "\n",
    "**a. Scrape Web Page Content:** For each URL in the search results, retrieve the web page to extract textual content while filtering out non-relevant data like scripts and advertisements as demonstrated in function `retrieve_content`. \n",
    "\n",
    "**b. Summarize Content:** Use an LLM to generate concise summaries of the scraped content, focusing on information pertinent to the user's query. Model can be provided the original search text, so it can focus on summarizing the content for the search intent as outlined in function `summarize_content`. \n",
    "  \n",
    "**c. Create a Structured Dictionary:** Organize the data into a dictionary or a DataFrame containing the title, link, and summary for each web page. This structure can be passed on to the LLM to generate the summary with the appropriate citations.    \n"
   ],
   "id": "c2f754f92866307e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T16:47:58.327492Z",
     "start_time": "2024-09-13T16:47:58.321058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "TRUNCATE_SCRAPED_TEXT = 50000  # Adjust based on your model's context window\n",
    "SEARCH_DEPTH = 5\n",
    "\n",
    "def retrieve_content(url, max_tokens=TRUNCATE_SCRAPED_TEXT):\n",
    "        try:\n",
    "            headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            for script_or_style in soup(['script', 'style']):\n",
    "                script_or_style.decompose()\n",
    "\n",
    "            text = soup.get_text(separator=' ', strip=True)\n",
    "            characters = max_tokens * 4  # Approximate conversion\n",
    "            text = text[:characters]\n",
    "            return text\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to retrieve {url}: {e}\")\n",
    "            return None\n",
    "        \n",
    "def summarize_content(content, search_term, character_limit=500):\n",
    "        prompt = (\n",
    "            f\"You are an AI assistant tasked with summarizing content relevant to '{search_term}'. \"\n",
    "            f\"Please provide a concise summary in {character_limit} characters or less.\"\n",
    "        )\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": prompt},\n",
    "                    {\"role\": \"user\", \"content\": content}]\n",
    "            )\n",
    "            summary = response.choices[0].message.content\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during summarization: {e}\")\n",
    "            return None\n",
    "\n",
    "def get_search_results(search_items, character_limit=500):\n",
    "    # Generate a summary of search results for the given search term\n",
    "    results_list = []\n",
    "    for idx, item in enumerate(search_items, start=1):\n",
    "        url = item.get('link')\n",
    "        \n",
    "        snippet = item.get('snippet', '')\n",
    "        web_content = retrieve_content(url, TRUNCATE_SCRAPED_TEXT)\n",
    "        \n",
    "        if web_content is None:\n",
    "            print(f\"Error: skipped URL: {url}\")\n",
    "        else:\n",
    "            summary = summarize_content(web_content, search_term, character_limit)\n",
    "            result_dict = {\n",
    "                'order': idx,\n",
    "                'link': url,\n",
    "                'title': snippet,\n",
    "                'Summary': summary\n",
    "            }\n",
    "            results_list.append(result_dict)\n",
    "    return results_list"
   ],
   "id": "f4981ca230333116",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T16:48:16.789588Z",
     "start_time": "2024-09-13T16:48:01.686242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = get_search_results(search_items)\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Search order: {result['order']}\")\n",
    "    print(f\"Link: {result['link']}\")\n",
    "    print(f\"Snippet: {result['title']}\")\n",
    "    print(f\"Summary: {result['Summary']}\")\n",
    "    print('-' * 80)"
   ],
   "id": "6b9afc6c933a6a67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search order: 1\n",
      "Link: https://openai.com/news/\n",
      "Snippet: Overview ; Product. Sep 12, 2024. Introducing OpenAI o1 ; Product. Jul 25, 2024. SearchGPT is a prototype of new AI search features ; Research. Jul 18, 2024. GPT- ...\n",
      "Summary: OpenAI has launched several products in 2024, including \"OpenAI o1\" and \"GPT-4o mini.\" \"SearchGPT,\" a prototype for AI-enhanced search, aims to improve user experiences. Additionally, \"OpenAI for Nonprofits\" and \"ChatGPT Edu\" were introduced to cater to specific user needs. Enhancements to data analysis in ChatGPT and updates to the fine-tuning API were also rolled out. These initiatives reflect OpenAI's commitment to expanding accessible AI tools for diverse applications and communities.\n",
      "--------------------------------------------------------------------------------\n",
      "Search order: 2\n",
      "Link: https://openai.com/index/new-models-and-developer-products-announced-at-devday/\n",
      "Snippet: Nov 6, 2023 ... GPT-4 Turbo with 128K context · We released the first version of GPT-4 in March and made GPT-4 generally available to all developers in July.\n",
      "Summary: At OpenAI's DevDay on November 6, 2023, several new products and features were launched, including GPT-4 Turbo with a 128K context window, new Assistants API, and DALL·E 3 API. GPT-4 Turbo offers enhanced capabilities at lower costs, while the Assistants API allows developers to build AI apps with persistent threads and function calling. OpenAI also introduced multimodal capabilities, including vision and text-to-speech features, alongside reduced prices for API usage. Additionally, Whisper v3 and a new Copyright Shield for legal support were announced.\n",
      "--------------------------------------------------------------------------------\n",
      "Search order: 3\n",
      "Link: https://openai.com/news/product/\n",
      "Snippet: Discover the latest product advancements from OpenAI and the ways they're being used by individuals and businesses.\n",
      "Summary: OpenAI has announced several recent product launches, including OpenAI o1 on September 12, 2024, aimed at enhancing user interactions through improved features. Additionally, on July 25, 2024, the prototype SearchGPT was introduced, bringing AI-powered search capabilities. Earlier, on May 30, 2024, OpenAI for Education was launched to support educational initiatives. These advancements build on existing AI technologies like GPT-4 and DALL·E 3, continuing OpenAI's commitment to innovation in artificial intelligence.\n",
      "--------------------------------------------------------------------------------\n",
      "Search order: 4\n",
      "Link: https://openai.com/\n",
      "Snippet: A new series of AI models designed to spend more time thinking before they respond. Learn more · (opens in a new window) ...\n",
      "Summary: OpenAI has recently launched several notable products and updates. Key highlights include the introduction of OpenAI o1, designed to enhance AI reasoning capabilities, and the debut of Sora, which generates realistic videos from text prompts. Additionally, OpenAI has improved its API with structured outputs and compliance tools for ChatGPT Enterprise. Partnerships, such as with Apple, aim to integrate ChatGPT into various applications. Furthermore, advancements in model safety and functionality, including new features for ChatGPT that allow it to see, hear, and speak, have been announced.\n",
      "--------------------------------------------------------------------------------\n",
      "Search order: 5\n",
      "Link: https://openai.com/index/sora/\n",
      "Snippet: Feb 15, 2024 ... We plan to include C2PA metadata(opens in a new window) in the future if we deploy the model in an OpenAI product. In addition to us developing ...\n",
      "Summary: OpenAI has launched \"Sora,\" a groundbreaking text-to-video AI model capable of generating up to a minute-long videos based on detailed prompts. Sora understands complex scenes, simulating physical interactions and characters with impressive fidelity. Currently available to select users for testing, Sora aims to enhance creative processes in visual arts and filmmaking. OpenAI is ensuring safety measures, including adversarial testing and content detection. By leveraging past research, Sora represents a significant advancement toward understanding real-world dynamics in AI.\n",
      "--------------------------------------------------------------------------------\n",
      "Search order: 6\n",
      "Link: https://openai.com/api/\n",
      "Snippet: The most powerful platform for building AI products ... Build and scale AI experiences powered by industry-leading models and tools. Start building (opens in a ...\n",
      "Summary: OpenAI recently launched several new products and enhancements to its API platform. Key offerings include GPT-4o, a flagship model for complex tasks with a 128k context length, and the more affordable GPT-4o mini for lightweight tasks. OpenAI introduced new models, o1-preview and o1-mini, focused on improved reasoning capabilities. The API now features tools for knowledge retrieval, code execution, and real-time output. Customization options through fine-tuning and a range of enterprise-grade security features, such as HIPAA compliance, have also been implemented.\n",
      "--------------------------------------------------------------------------------\n",
      "Search order: 7\n",
      "Link: https://openai.com/index/introducing-gpts/\n",
      "Snippet: Nov 6, 2023 ... We plan to offer GPTs to more users soon. Learn more about our OpenAI DevDay announcements for new models and developer products.\n",
      "Summary: OpenAI has launched custom versions of ChatGPT, known as GPTs, allowing users to create tailored AI models for specific tasks without coding knowledge. These GPTs can assist with various activities like education, work, or personal projects and can be shared publicly. A GPT Store is set to launch soon, enabling users to discover and utilize community-created GPTs while maintaining privacy controls. Additionally, enterprise solutions will allow businesses to create internal GPTs focused on their needs. Improvements to ChatGPT Plus enhance user experience by simplifying access to features.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 3: Generate a RAG Response to the User Query\n",
    "With the search data organized in a JSON data structure, we will pass this information to the LLM with the original user query to generate the final response. Now LLM response includes information beyond its original knowledge cutoff, providing current insights."
   ],
   "id": "3f81cf3fd1a942c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T16:48:33.413932Z",
     "start_time": "2024-09-13T16:48:21.729557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json \n",
    "\n",
    "final_prompt = (\n",
    "    f\"The user will provide a dictionary of search results in JSON format for search query {search_term} Based on on the search results provided by the user, provide a detailed response to this query: **'{search_query}'**. Make sure to cite all the sources at the end of your answer.\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": final_prompt},\n",
    "        {\"role\": \"user\", \"content\": json.dumps(results)}],\n",
    "    temperature=0\n",
    "\n",
    ")\n",
    "summary = response.choices[0].message.content\n",
    "\n",
    "print(summary)"
   ],
   "id": "2894a01ce6c44d36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the search results provided, here is a chronological list of the latest OpenAI product launches from the past two years, ordered from the latest to the oldest:\n",
      "\n",
      "1. **September 12, 2024**: **OpenAI o1**\n",
      "   - Aimed at enhancing user interactions through improved features.\n",
      "   - Source: [OpenAI News](https://openai.com/news/)\n",
      "\n",
      "2. **July 25, 2024**: **SearchGPT**\n",
      "   - A prototype for AI-enhanced search capabilities.\n",
      "   - Source: [OpenAI News](https://openai.com/news/)\n",
      "\n",
      "3. **July 18, 2024**: **GPT-4o mini**\n",
      "   - A more affordable version of GPT-4o for lightweight tasks.\n",
      "   - Source: [OpenAI API](https://openai.com/api/)\n",
      "\n",
      "4. **May 30, 2024**: **OpenAI for Education**\n",
      "   - Launched to support educational initiatives.\n",
      "   - Source: [OpenAI News](https://openai.com/news/product/)\n",
      "\n",
      "5. **February 15, 2024**: **Sora**\n",
      "   - A text-to-video AI model capable of generating realistic videos from text prompts.\n",
      "   - Source: [OpenAI Sora](https://openai.com/index/sora/)\n",
      "\n",
      "6. **November 6, 2023**: **GPT-4 Turbo with 128K context**\n",
      "   - Enhanced capabilities at lower costs, introduced at OpenAI's DevDay.\n",
      "   - Source: [OpenAI DevDay](https://openai.com/index/new-models-and-developer-products-announced-at-devday/)\n",
      "\n",
      "7. **November 6, 2023**: **Assistants API**\n",
      "   - Allows developers to build AI apps with persistent threads and function calling.\n",
      "   - Source: [OpenAI DevDay](https://openai.com/index/new-models-and-developer-products-announced-at-devday/)\n",
      "\n",
      "8. **November 6, 2023**: **DALL·E 3 API**\n",
      "   - Introduced multimodal capabilities, including vision and text-to-speech features.\n",
      "   - Source: [OpenAI DevDay](https://openai.com/index/new-models-and-developer-products-announced-at-devday/)\n",
      "\n",
      "9. **November 6, 2023**: **Whisper v3**\n",
      "   - Announced alongside other products at OpenAI's DevDay.\n",
      "   - Source: [OpenAI DevDay](https://openai.com/index/new-models-and-developer-products-announced-at-devday/)\n",
      "\n",
      "10. **November 6, 2023**: **Custom GPTs**\n",
      "    - Allows users to create tailored AI models for specific tasks without coding knowledge.\n",
      "    - Source: [OpenAI DevDay](https://openai.com/index/introducing-gpts/)\n",
      "\n",
      "11. **March 2023**: **GPT-4**\n",
      "    - The first version of GPT-4 was released.\n",
      "    - Source: [OpenAI DevDay](https://openai.com/index/new-models-and-developer-products-announced-at-devday/)\n",
      "\n",
      "12. **July 2023**: **GPT-4 General Availability**\n",
      "    - Made generally available to all developers.\n",
      "    - Source: [OpenAI DevDay](https://openai.com/index/new-models-and-developer-products-announced-at-devday/)\n",
      "\n",
      "These product launches reflect OpenAI's ongoing efforts to innovate and expand the capabilities of artificial intelligence across various domains, from education and enterprise solutions to creative tools and developer APIs.\n",
      "\n",
      "### Sources:\n",
      "- [OpenAI News](https://openai.com/news/)\n",
      "- [OpenAI DevDay](https://openai.com/index/new-models-and-developer-products-announced-at-devday/)\n",
      "- [OpenAI API](https://openai.com/api/)\n",
      "- [OpenAI Sora](https://openai.com/index/sora/)\n",
      "- [OpenAI Product](https://openai.com/news/product/)\n",
      "- [OpenAI Introducing GPTs](https://openai.com/index/introducing-gpts/)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Conclusion\n",
    " \n",
    "Large Language Models (LLMs) have a knowledge cutoff and may not be aware of recent events. To provide them with the latest information, you can build a Bring Your Own Browser (BYOB) tool using Python. This tool retrieves current web data and feeds it to the LLM, enabling up-to-date responses.\n",
    "\n",
    "The process involves three main steps:\n",
    "\n",
    "**#1 Set Up a Search Engine:** Use a public search API, like Google's Custom Search API, to perform web searches and obtain a list of relevant search results.  \n",
    "\n",
    "**#2 Build a Search Dictionary:** Collect the title, URL, and a summary of each web page from the search results to create a structured dictionary of information.  \n",
    "\n",
    "**#3. Generate a RAG Response:** Implement Retrieval-Augmented Generation (RAG) by passing the gathered information to the LLM, which then generates a final response to the user's query.\n",
    "\n",
    "By following these steps, you enhance the LLMs ability to provide up-to-date answers in your application that include the most recent developments, such as the latest product launches by OpenAI."
   ],
   "id": "8b6beba8859f1bc7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
