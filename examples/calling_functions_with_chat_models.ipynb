{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e67f200",
   "metadata": {},
   "source": [
    "# How to call functions with chat models\n",
    "\n",
    "This notebook covers how to use the Chat Completions API in combination with external functions to extend the capabilities of GPT models.\n",
    "\n",
    "`functions` is an optional parameter in the Chat Completion API which can be used to provide function specifications. The purpose of this is to enable models to generate function arguments which adhere to the provided specifications. Note that the API will not actually execute any function calls. It is up to developers to execute function calls using model outputs.\n",
    "\n",
    "If the `functions` parameter is provided then by default the model will decide when it is appropriate to use one of the functions. The API can be forced to use a specific function by setting the `function_call` parameter to `{\"name\": \"<insert-function-name>\"}`. The API can also be forced to not use any function by setting the `function_call` parameter to `\"none\"`. If a function is used, the output will contain `\"finish_reason\": \"function_message\"` in the response, as well as a `function_call` object that has the name of the function and the generated function arguments.\n",
    "\n",
    "### Overview\n",
    "\n",
    "- **How to generate function arguments:** Specify a set of functions and make calls to the API with specific instructions to generate function arguments.\n",
    "- **How to call functions with model generated arguments:** Close the loop by actually executing specified functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c85e26",
   "metadata": {},
   "source": [
    "## How to generate function arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e71f33",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install scipy\n",
    "!pip install tenacity\n",
    "!pip install tiktoken\n",
    "!pip install termcolor \n",
    "!pip install openai\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab872c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import arxiv\n",
    "# import ast\n",
    "# import concurrent\n",
    "# from csv import writer\n",
    "# from IPython.display import display, Markdown, Latex\n",
    "# import json\n",
    "# import openai\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# from PyPDF2 import PdfReader\n",
    "# import requests\n",
    "# from scipy import spatial\n",
    "# from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "# import tiktoken\n",
    "# from tqdm import tqdm\n",
    "# from termcolor import colored\n",
    "\n",
    "import json\n",
    "import openai\n",
    "import requests\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from termcolor import colored\n",
    "\n",
    "GPT_MODEL = \"gpt-3.5-turbo-0613\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ee6a93",
   "metadata": {},
   "source": [
    "## Utilities\n",
    "\n",
    "First let's define a few utilities for making calls to the Chat Completions API and for maintaining and keeping track of the conversation state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745ceec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, functions=None, function_call=None, model=GPT_MODEL):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
    "    }\n",
    "    json_data = {\"model\": model, \"messages\": messages}\n",
    "    if functions is not None:\n",
    "        json_data.update({\"functions\": functions})\n",
    "    if function_call is not None:\n",
    "        json_data.update({\"function_call\": function_call})\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=json_data,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d1c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conversation:\n",
    "    def __init__(self):\n",
    "        self.conversation_history = []\n",
    "\n",
    "    def add_message(self, role, content):\n",
    "        message = {\"role\": role, \"content\": content}\n",
    "        self.conversation_history.append(message)\n",
    "\n",
    "    def display_conversation(self, detailed=False):\n",
    "        role_to_color = {\n",
    "            \"system\": \"red\",\n",
    "            \"user\": \"green\",\n",
    "            \"assistant\": \"blue\",\n",
    "            \"function\": \"magenta\",\n",
    "        }\n",
    "        for message in self.conversation_history:\n",
    "            print(\n",
    "                colored(\n",
    "                    f\"{message['role']}: {message['content']}\\n\\n\",\n",
    "                    role_to_color[message[\"role\"]],\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d4e02b",
   "metadata": {},
   "source": [
    "## Basic concepts\n",
    "\n",
    "Let's create some function specifications to interface with a hypothetical weather API. Later we'll pass these function specification to the Chat Completions API in order to generate function arguments that adhere to the specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e25069",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"format\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\", \"format\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_n_day_weather_forecast\",\n",
    "        \"description\": \"Get an N-day weather forecast\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"format\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                },\n",
    "                \"num_days\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"The number of days to forecast\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\", \"format\", \"num_days\"]\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc39899",
   "metadata": {},
   "source": [
    "If we prompt the model about the current weather, it will respond with some clarifying questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518d6827",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = Conversation()\n",
    "conversation.add_message(\"system\", \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\")\n",
    "conversation.add_message(\"user\", \"What's the weather like today\")\n",
    "chat_response = chat_completion_request(\n",
    "    conversation.conversation_history, functions=functions\n",
    ")\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "conversation.add_message(assistant_message[\"role\"], assistant_message[\"content\"])\n",
    "assistant_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c999375",
   "metadata": {},
   "source": [
    "Once we provide the missing information, it will generate the appropriate function arguments for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c42a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.add_message(\"user\", \"I'm in Glasgow, Scotland.\")\n",
    "chat_response = chat_completion_request(\n",
    "    conversation.conversation_history, functions=functions\n",
    ")\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "conversation.add_message(assistant_message[\"role\"], assistant_message[\"content\"])\n",
    "assistant_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14d4762",
   "metadata": {},
   "source": [
    "By prompting it differently, we can get it to target the other function we've told it about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa232e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = Conversation()\n",
    "conversation.add_message(\"system\", \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\")\n",
    "conversation.add_message(\"user\", \"what is the weather going to be like in Glasgow, Scotland over the next x days\")\n",
    "chat_response = chat_completion_request(\n",
    "    conversation.conversation_history, functions=functions\n",
    ")\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "conversation.add_message(assistant_message[\"role\"], assistant_message[\"content\"])\n",
    "assistant_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6172ddac",
   "metadata": {},
   "source": [
    "Once again, the model is asking us for clarification because it doesn't have enough information yet. In this case it already knows the location for the forecast, but it needs to know how many days are required in the forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d8a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.add_message(\"user\", \"5 days\")\n",
    "chat_response = chat_completion_request(\n",
    "    conversation.conversation_history, functions=functions\n",
    ")\n",
    "chat_response.json()[\"choices\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412f79ba",
   "metadata": {},
   "source": [
    "We can force the model to use a specific function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559371b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by forcing the model to use a specific function, it is forced to make assumptions about how to use it\n",
    "conversation = Conversation()\n",
    "conversation.add_message(\"system\", \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\")\n",
    "conversation.add_message(\"user\", \"Give me a weather report for Toronto, Canada.\")\n",
    "chat_response = chat_completion_request(\n",
    "    conversation.conversation_history, functions=functions, function_call={\"name\": \"get_n_day_weather_forecast\"}\n",
    ")\n",
    "chat_response.json()[\"choices\"][0][\"message\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ab0f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we don't force the model to use get_n_day_weather_forecast it may not\n",
    "conversation = Conversation()\n",
    "conversation.add_message(\"system\", \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\")\n",
    "conversation.add_message(\"user\", \"Give me a weather report for Toronto, Canada.\")\n",
    "chat_response = chat_completion_request(\n",
    "    conversation.conversation_history, functions=functions, \n",
    ")\n",
    "chat_response.json()[\"choices\"][0][\"message\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd70e48",
   "metadata": {},
   "source": [
    "We can also force the model to not use a function at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfe54e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we force the model to not use a function, we prevent it from outputting a proper function call\n",
    "conversation = Conversation()\n",
    "conversation.add_message(\"system\", \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\")\n",
    "conversation.add_message(\"user\", \"Give me the current weather (use Celcius) for Toronto, Canada.\")\n",
    "chat_response = chat_completion_request(\n",
    "    conversation.conversation_history, functions=functions, function_call=\"none\"\n",
    ")\n",
    "chat_response.json()[\"choices\"][0][\"message\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92723beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4482aee",
   "metadata": {},
   "source": [
    "## How to call functions with model generated arguments\n",
    "\n",
    "In our next example, we'll demonstrate how to execute functions whose inputs are model-generated, and use this to implement an agent that can answer questions for us about a database. For simplicity we'll use the [Chinook sample database](https://www.sqlitetutorial.net/sqlite-sample-database/).\n",
    "\n",
    "*Note:* SQL generation use cases are high-risk in a production environment - models can be unreliable when generating consistent SQL syntax. A more reliable way to solve this problem may be to build a query generation API that takes the desired columns as input from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7654fef",
   "metadata": {},
   "source": [
    "### Pull SQL Database Info\n",
    "\n",
    "First let's define some helpful utility functions to extract data from a SQLite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f6b60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"data/Chinook.db\")\n",
    "print(\"Opened database successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abec0214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_names(conn):\n",
    "    \"\"\"Return a list of table names.\"\"\"\n",
    "    table_names = []\n",
    "    tables = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    for table in tables.fetchall():\n",
    "        table_names.append(table[0])\n",
    "    return table_names\n",
    "\n",
    "\n",
    "def get_column_names(conn, table_name):\n",
    "    \"\"\"Return a list of column names.\"\"\"\n",
    "    column_names = []\n",
    "    columns = conn.execute(f\"PRAGMA table_info('{table_name}');\").fetchall()\n",
    "    for col in columns:\n",
    "        column_names.append(col[1])\n",
    "    return column_names\n",
    "\n",
    "\n",
    "def get_database_info(conn):\n",
    "    \"\"\"Return a list of dicts containing the table name and columns for each table in the database.\"\"\"\n",
    "    table_dicts = []\n",
    "    for table_name in get_table_names(conn):\n",
    "        columns_names = get_column_names(conn, table_name)\n",
    "        table_dicts.append({\"table_name\": table_name, \"column_names\": columns_names})\n",
    "    return table_dicts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e6e5ea",
   "metadata": {},
   "source": [
    "Now can use these utility functions to extract a representation of the database schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0104cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_schema_dict = get_database_info(conn)\n",
    "database_schema_string = \"\\n\".join(\n",
    "    [\n",
    "        f\"Table: {table['table_name']}\\nColumns: {', '.join(table['column_names'])}\"\n",
    "        for table in database_schema_dict\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae73c9ee",
   "metadata": {},
   "source": [
    "As before, we'll define a function specification for the function we'd like the API to generate arguments for. Notice that we are inserting the database schema into the function specification. This will be important for the model to know about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0258813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"ask_database\",\n",
    "        \"description\": \"Use this function to answer user questions about music. Output should be a fully formed SQL query.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": f\"\"\"\n",
    "                            SQL query extracting info to answer the user's question.\n",
    "                            SQL should be written using this database schema:\n",
    "                            {database_schema_string}\n",
    "                            The query should be returned in plain text, not in JSON.\n",
    "                            \"\"\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "        },\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da08c121",
   "metadata": {},
   "source": [
    "### SQL execution\n",
    "\n",
    "Now let's implement the function that the agent will use to query the database. We also need to implement utilities to integrate the calls to the Chat Completions API with the function it is calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65585e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_database(conn, query):\n",
    "    \"\"\"Function to query SQLite database with provided SQL query.\"\"\"\n",
    "    try:\n",
    "        results = conn.execute(query).fetchall()\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"SQL error: {e}\")\n",
    "\n",
    "\n",
    "def chat_completion_with_function_execution(messages, functions=None):\n",
    "    \"\"\"This function makes a ChatCompletion API call and if a function call is requested, executes the function\"\"\"\n",
    "    try:\n",
    "        response = chat_completion_request(messages, functions)\n",
    "        full_message = response.json()[\"choices\"][0]\n",
    "        if full_message[\"finish_reason\"] == \"function_call\":\n",
    "            print(f\"Function generation requested, calling function\")\n",
    "            return call_function(messages, full_message)\n",
    "        else:\n",
    "            print(f\"Function not required, responding to user\")\n",
    "            return response.json()\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return response\n",
    "\n",
    "\n",
    "def call_function(messages, full_message):\n",
    "    \"\"\"Executes function calls using model generated function arguments.\"\"\"\n",
    "\n",
    "    # We'll add our one function here - this can be extended with any additional functions\n",
    "    if full_message[\"message\"][\"function_call\"][\"name\"] == \"ask_database\":\n",
    "        query = eval(full_message[\"message\"][\"function_call\"][\"arguments\"])\n",
    "        print(f\"Prepped query is {query}\")\n",
    "        try:\n",
    "            results = ask_database(conn, query[\"query\"])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "            # This following block tries to fix any issues in query generation with a subsequent call\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": f\"\"\"Query: {query['query']}\n",
    "The previous query received the error {e}. \n",
    "Please return a fixed SQL query in plain text.\n",
    "Your response should consist of ONLY the SQL query with the separator sql_start at the beginning and sql_end at the end\"\"\",\n",
    "                }\n",
    "            )\n",
    "            response = chat_completion_request(messages, model=\"gpt-4-next\")\n",
    "\n",
    "            # Retrying with the fixed SQL query. If it fails a second time we exit.\n",
    "            try:\n",
    "                cleaned_query = response.json()[\"choices\"][0][\"message\"][\n",
    "                    \"content\"\n",
    "                ].split(\"sql_start\")[1]\n",
    "                cleaned_query = cleaned_query.split(\"sql_end\")[0]\n",
    "                print(cleaned_query)\n",
    "                results = ask_database(conn, cleaned_query)\n",
    "                print(results)\n",
    "                print(\"Got on second try\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"Second failure, exiting\")\n",
    "\n",
    "                print(f\"Function execution failed\")\n",
    "                print(f\"Error message: {e}\")\n",
    "\n",
    "        messages.append(\n",
    "            {\"role\": \"function\", \"name\": \"ask_database\", \"content\": str(results)}\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            response = chat_completion_request(messages)\n",
    "            return response.json()\n",
    "        except Exception as e:\n",
    "            print(type(e))\n",
    "            print(e)\n",
    "            raise Exception(\"Function chat request failed\")\n",
    "    else:\n",
    "        raise Exception(\"Function does not exist and cannot be called\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c55083",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_system_message = \"\"\"You are ChinookGPT, a helpful assistant who gets answers to user questions from the Chinook Music Database.\n",
    "Provide as many details as possible to your users\n",
    "Begin!\"\"\"\n",
    "\n",
    "sql_conversation = Conversation()\n",
    "sql_conversation.add_message(\"system\", agent_system_message)\n",
    "sql_conversation.add_message(\n",
    "    \"user\", \"Hi, who are the top 5 artists by number of tracks\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e5338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response = chat_completion_with_function_execution(\n",
    "    sql_conversation.conversation_history, functions=functions\n",
    ")\n",
    "try:\n",
    "    assistant_message = chat_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    print(assistant_message)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(chat_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28471ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_conversation.add_message(\"assistant\", assistant_message)\n",
    "sql_conversation.display_conversation(detailed=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710481dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_conversation.add_message(\n",
    "    \"user\", \"What is the name of the album with the most tracks\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f954e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response = chat_completion_with_function_execution(\n",
    "    sql_conversation.conversation_history, functions=functions\n",
    ")\n",
    "assistant_message = chat_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "assistant_message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2518ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_conversation.add_message(\"assistant\", assistant_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13984dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_conversation.display_conversation(detailed=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
