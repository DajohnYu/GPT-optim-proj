{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning for RAG\n",
    "\n",
    "\n",
    "\n",
    "Here, we'll take you through the process, complete with code examples, to help you fine-tune your OpenAI model for usage with RAG like a pro.\n",
    "\n",
    "\n",
    "\n",
    "To begin, we've selected a dataset where we've a guarantee that the retrieval is perfect. We've selected a subset of the [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) dataset, which is a collection of questions and answers about Wikipedia articles. We've also included samples where the answer is not present in the context, to demonstrate how RAG handles this case.\n",
    "\n",
    "## Table of Contents\n",
    "1. Setting up the Environment\n",
    "2. Data Preparation\n",
    "3. Running the Model\n",
    "4. Evaluation\n",
    "5. Fine-Tuning\n",
    "6. Comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up\n",
    "\n",
    "### Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas openai tqdm tenacity pandarallel scikit-learn tiktoken python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import openai\n",
    "import tiktoken\n",
    "from tenacity import retry, wait_exponential\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "\n",
    "For the purpose of demonstration, we'll make small slices from the train and validation splits of the [SQuADv2](https://rajpurkar.github.io/SQuAD-explorer/) dataset. This dataset has questions and contexts where the answer is not present in the context, to help us evaluate how LLM handles this case.\n",
    "\n",
    "### Download the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p local_cache\n",
    "# !wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json -O local_cache/train.json\n",
    "# !wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json -O local_cache/dev.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_dataframe_with_titles(json_data):\n",
    "    qas = []\n",
    "    context = []\n",
    "    is_impossible = []\n",
    "    answers = []\n",
    "    titles = []\n",
    "\n",
    "    for article in json_data['data']:\n",
    "        title = article['title']\n",
    "        for paragraph in article['paragraphs']:\n",
    "            for qa in paragraph['qas']:\n",
    "                qas.append(qa['question'].strip())\n",
    "                context.append(paragraph['context'])\n",
    "                is_impossible.append(qa['is_impossible'])\n",
    "                \n",
    "                ans_list = []\n",
    "                for ans in qa['answers']:\n",
    "                    ans_list.append(ans['text'])\n",
    "                answers.append(ans_list)\n",
    "                titles.append(title)\n",
    "\n",
    "    df = pd.DataFrame({'title': titles, 'question': qas, 'context': context, 'is_impossible': is_impossible, 'answers': answers})\n",
    "    return df\n",
    "\n",
    "def get_diverse_sample(df, sample_size=100, random_state=42):\n",
    "    sample_df = df.groupby(['title', 'is_impossible']).apply(lambda x: x.sample(min(len(x), max(1, sample_size // 50)), random_state=random_state)).reset_index(drop=True)\n",
    "    \n",
    "    if len(sample_df) < sample_size:\n",
    "        remaining_sample_size = sample_size - len(sample_df)\n",
    "        remaining_df = df.drop(sample_df.index).sample(remaining_sample_size, random_state=random_state)\n",
    "        sample_df = pd.concat([sample_df, remaining_df]).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "    return sample_df.sample(min(sample_size, len(sample_df)), random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "train_df = json_to_dataframe_with_titles(json.load(open('local_cache/train.json')))\n",
    "val_df = json_to_dataframe_with_titles(json.load(open('local_cache/dev.json')))\n",
    "\n",
    "df = get_diverse_sample(val_df, sample_size=100, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the OpenAI Model for Question Answering\n",
    "\n",
    "### Prompt, API Call, and Answer\n",
    "Create functions to get prompt messages and make API calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get prompt messages\n",
    "def get_prompt(row):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"Answer the following Question based on the Context only. Only answer from the Context. If you don't know the answer, say 'I don't know'.\n",
    "    Question: {row.question}\\n\\n\n",
    "    Context: {row.context}\\n\\n\n",
    "    Answer:\\n\"\"\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "\n",
    "# Function with tenacity for retries\n",
    "@retry(wait=wait_exponential(multiplier=1, min=2, max=6))\n",
    "def api_call(messages, model):\n",
    "    return openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        stop=[\"\\n\\n\"],\n",
    "        max_tokens=100,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "\n",
    "# Main function to answer question\n",
    "def answer_question(row, prompt_func=get_prompt, model=\"gpt-3.5-turbo-0613\"):\n",
    "    messages = prompt_func(row)\n",
    "    response = api_call(messages, model)\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:53<00:00,  1.73s/it]\n"
     ]
    }
   ],
   "source": [
    "# Use progress_apply with tqdm for progress bar\n",
    "df[\"generated_answer\"] = df.progress_apply(answer_question, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"local_cache/100_val.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "To evaluate the model's performance, compare the predicted answer to the actual answers -- if any of the actual answers are present in the predicted answer, then it's a match. We've also created error categories to help you understand where the model is struggling.\n",
    "\n",
    "1. Expected and Right: The model responsded the correct answer. It may have also included other answers that were not in the context.\n",
    "2. Expected but \"IDK\": The model responded with \"I don't know\" (IDK) while the answer was present in the context. *This is a model error* and better than giving the wrong answer. We exclude this from the overall error rate.\n",
    "3. Expected but Wrong: The model responded with an incorrect answer. *This is a model ERROR.*\n",
    "4. Hallucination: The model responded with an answer, when \"I don't know\" was expected. **This is a model error.** \n",
    "5. Did not expect and IDK: The model responded with \"I don't know\" (IDK) and the answer was not present in the context. *This is a model WIN.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'generated_answer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'generated_answer'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 46\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m freq_series\n\u001b[1;32m     45\u001b[0m evaluator \u001b[39m=\u001b[39m ConfusionMatrixEvaluator(df, answers_column\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgenerated_answer\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m evaluator\u001b[39m.\u001b[39;49mevaluate_answers()\n\u001b[1;32m     47\u001b[0m error_categories \u001b[39m=\u001b[39m evaluator\u001b[39m.\u001b[39mgenerate_matrices(use_percentages\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     48\u001b[0m error_categories\n",
      "Cell \u001b[0;32mIn[61], line 34\u001b[0m, in \u001b[0;36mConfusionMatrixEvaluator.evaluate_answers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate_answers\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 34\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdf\u001b[39m.\u001b[39;49mapply(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluate_single_row, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages/pandas/core/frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9412\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9414\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9415\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9416\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9421\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9422\u001b[0m )\n\u001b[0;32m-> 9423\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages/pandas/core/apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    676\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages/pandas/core/apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 798\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    800\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages/pandas/core/apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    812\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    813\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    815\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    816\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    817\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[61], line 16\u001b[0m, in \u001b[0;36mConfusionMatrixEvaluator._evaluate_single_row\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_evaluate_single_row\u001b[39m(\u001b[39mself\u001b[39m, row):\n\u001b[1;32m     15\u001b[0m     is_impossible \u001b[39m=\u001b[39m row[\u001b[39m\"\u001b[39m\u001b[39mis_impossible\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> 16\u001b[0m     generated_answer \u001b[39m=\u001b[39m row[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49manswers_column]\u001b[39m.\u001b[39mlower()\n\u001b[1;32m     17\u001b[0m     actual_answers \u001b[39m=\u001b[39m [ans\u001b[39m.\u001b[39mlower() \u001b[39mfor\u001b[39;00m ans \u001b[39min\u001b[39;00m row[\u001b[39m\"\u001b[39m\u001b[39manswers\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[1;32m     19\u001b[0m     y_pred \u001b[39m=\u001b[39m (\n\u001b[1;32m     20\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExpected and Right\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_impossible\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mDid not Expect and IDK\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages/pandas/core/series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m   1006\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m   1009\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m   1010\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1012\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages/pandas/core/series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1115\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1116\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1118\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'generated_answer'"
     ]
    }
   ],
   "source": [
    "class ConfusionMatrixEvaluator:\n",
    "    def __init__(self, df, answers_column=\"generated_answer\"):\n",
    "        self.df = df\n",
    "        self.y_pred = []\n",
    "        self.labels = [\n",
    "            \"Expected and Right\",\n",
    "            \"Expected but IDK\",\n",
    "            \"Expected but Wrong\",\n",
    "            \"Hallucination\",\n",
    "            \"Did not Expect and IDK\",\n",
    "        ]\n",
    "        self.answers_column = answers_column\n",
    "\n",
    "    def _evaluate_single_row(self, row):\n",
    "        is_impossible = row[\"is_impossible\"]\n",
    "        generated_answer = row[self.answers_column].lower()\n",
    "        actual_answers = [ans.lower() for ans in row[\"answers\"]]\n",
    "\n",
    "        y_pred = (\n",
    "            \"Expected and Right\"\n",
    "            if not is_impossible\n",
    "            and any(ans in generated_answer for ans in actual_answers)\n",
    "            else \"Expected but IDK\"\n",
    "            if not is_impossible and generated_answer == \"i don't know\"\n",
    "            else \"Expected but Wrong\"\n",
    "            if not is_impossible and generated_answer not in actual_answers\n",
    "            else \"Hallucination\"\n",
    "            if is_impossible and generated_answer != \"i don't know\"\n",
    "            else \"Did not Expect and IDK\"\n",
    "        )\n",
    "        return y_pred\n",
    "\n",
    "    def evaluate_answers(self):\n",
    "        self.y_pred = self.df.apply(self._evaluate_single_row, axis=1)\n",
    "\n",
    "    def generate_matrices(self, use_percentages=False):\n",
    "        # Using value_counts to create a Series of frequencies, then reindexing to include missing labels with count 0\n",
    "        freq_series = self.y_pred.value_counts().reindex(self.labels, fill_value=0)\n",
    "        if use_percentages:\n",
    "            total = freq_series.sum()\n",
    "            freq_series = (freq_series / total * 100).apply(\"{0:.2f}%\".format)\n",
    "        return freq_series\n",
    "\n",
    "\n",
    "evaluator = ConfusionMatrixEvaluator(df, answers_column=\"generated_answer\")\n",
    "evaluator.evaluate_answers()\n",
    "error_categories = evaluator.generate_matrices(use_percentages=True)\n",
    "error_categories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning\n",
    "\n",
    "### Prepare the Fine-Tuning Data\n",
    "\n",
    "We need to prepare the data for fine-tuning. We'll use a few samples from train split of same dataset as before, but we'll add the answer to the context. This will help the model learn to retrieve the answer from the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_diverse_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     jsonl_output \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mprogress_apply(create_jsonl_entry, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     18\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(jsonl_output)\n\u001b[0;32m---> 20\u001b[0m train_sample \u001b[39m=\u001b[39m get_diverse_sample(train_df, sample_size\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mlocal_cache/100_train.jsonl\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     23\u001b[0m     f\u001b[39m.\u001b[39mwrite(dataframe_to_jsonl(train_sample))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_diverse_sample' is not defined"
     ]
    }
   ],
   "source": [
    "def dataframe_to_jsonl(df):\n",
    "    def create_jsonl_entry(row):\n",
    "        answer = row[\"answers\"][0] if row[\"answers\"] else \"I don't know\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"Answer the following Question based on the Context only. Only answer from the Context. If you don't know the answer, say 'I don't know'.\n",
    "            Question: {row.question}\\n\\n\n",
    "            Context: {row.context}\\n\\n\n",
    "            Answer:\\n\"\"\",\n",
    "            },\n",
    "            {\"role\": \"assistant\", \"content\": answer},\n",
    "        ]\n",
    "        return json.dumps({\"messages\": messages})\n",
    "\n",
    "    jsonl_output = df.progress_apply(create_jsonl_entry, axis=1)\n",
    "    return \"\\n\".join(jsonl_output)\n",
    "\n",
    "train_sample = get_diverse_sample(train_df, sample_size=100, random_state=42)\n",
    "\n",
    "with open(\"local_cache/100_train.jsonl\", \"w\") as f:\n",
    "    f.write(dataframe_to_jsonl(train_sample))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Verify the Fine-Tuning Data\n",
    "\n",
    "The script below will verify that the data is in the format that OpenAI expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 100\n",
      "First example:\n",
      "{'role': 'system', 'content': 'You are a helpful assistant.'}\n",
      "{'role': 'user', 'content': \"Answer the following Question based on the Context only. Only answer from the Context. If you don't know the answer, say 'I don't know'.\\n            Question: What is a cirque?\\n\\n\\n            Context: Glaciers form where the accumulation of snow and ice exceeds ablation. The area in which a glacier forms is called a cirque (corrie or cwm) - a typically armchair-shaped geological feature (such as a depression between mountains enclosed by arêtes) - which collects and compresses through gravity the snow which falls into it. This snow collects and is compacted by the weight of the snow falling above it forming névé. Further crushing of the individual snowflakes and squeezing the air from the snow turns it into 'glacial ice'. This glacial ice will fill the cirque until it 'overflows' through a geological weakness or vacancy, such as the gap between two mountains. When the mass of snow and ice is sufficiently thick, it begins to move due to a combination of surface slope, gravity and pressure. On steeper slopes, this can occur with as little as 15 m (50 ft) of snow-ice.\\n\\n\\n            Answer:\\n\"}\n",
      "{'role': 'assistant', 'content': 'The area in which a glacier forms'}\n",
      "No errors found\n",
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 114, 689\n",
      "mean / median: 236.88, 217.0\n",
      "p5 / p95: 166.7, 321.3\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 1, 13\n",
      "mean / median: 3.81, 4.0\n",
      "p5 / p95: 1.0, 5.0\n",
      "\n",
      "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n",
      "Dataset has ~23688 tokens that will be charged for during training\n",
      "By default, you'll train for 3 epochs on this dataset\n",
      "By default, you'll be charged for ~71064 tokens\n",
      "See pricing page to estimate total costs\n"
     ]
    }
   ],
   "source": [
    "# Specify the data path and open the JSONL file\n",
    "\n",
    "data_path = \"local_cache/100_train.jsonl\"\n",
    "\n",
    "# Load dataset\n",
    "with open(data_path) as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# We can inspect the data quickly by checking the number of examples and the first item\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)\n",
    "\n",
    "# Now that we have a sense of the data, we need to go through all the different examples and check to make sure the formatting is correct and matches the Chat completions message structure\n",
    "\n",
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "\n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "\n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "\n",
    "        if any(k not in (\"role\", \"content\", \"name\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "\n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "\n",
    "        content = message.get(\"content\", None)\n",
    "        if not content or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "\n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")\n",
    "\n",
    "# Beyond the structure of the message, we also need to ensure that the length does not exceed the 4096 token limit.\n",
    "\n",
    "# Token counting functions\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
    "\n",
    "# Last, we can look at the results of the different formatting operations before proceeding with creating a fine-tuning job:\n",
    "\n",
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")\n",
    "\n",
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_EPOCHS = 1\n",
    "MAX_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n",
    "print(\"See pricing page to estimate total costs\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push the Fine-Tuning data to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_object = openai.File.create(\n",
    "    file=open(\"local_cache/100_train.jsonl\", \"r\"),\n",
    "    purpose=\"fine-tune\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<File file id=file-iuSjUY6kK84A1cOB9QffTxfD at 0x2b3099db0> JSON: {\n",
       "  \"object\": \"file\",\n",
       "  \"id\": \"file-iuSjUY6kK84A1cOB9QffTxfD\",\n",
       "  \"purpose\": \"fine-tune\",\n",
       "  \"filename\": \"file\",\n",
       "  \"bytes\": 120415,\n",
       "  \"created_at\": 1694012894,\n",
       "  \"status\": \"processed\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while file_object.status!='processed':\n",
    "    time.sleep(5)\n",
    "    file_object.refresh()\n",
    "file_object"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Fine Tuning Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_job = openai.FineTuningJob.create(\n",
    "    training_file=file_object[\"id\"], model=\"gpt-3.5-turbo\", suffix=\"100train20230906\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  succeeded\n"
     ]
    }
   ],
   "source": [
    "while ft_job.status!='succeeded':\n",
    "    time.sleep(15)\n",
    "    ft_job.refresh()\n",
    "    print(\"Status: \", ft_job.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ft:gpt-3.5-turbo-0613:qdrant:100train20230906:7vp2AzMY'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = openai.FineTuningJob.retrieve(ft_job[\"id\"]).fine_tuned_model\n",
    "model_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try out the Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"I don't know\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "    model=model_id,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Hi, how can I help you today?\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Can you answer the following question based on the given context? If not, say, I don't know:\\n\\nQuestion: What is the capital of France?\\n\\nContext: The capital of Mars is Gaia. Answer:\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "\n",
    "### Get Answers from the Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:16<00:00,  3.17s/it]\n"
     ]
    }
   ],
   "source": [
    "df[\"ft_generated_answer\"] = df.progress_apply(answer_question, model=model_id, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Expected and Right        30.00%\n",
       "Expected but IDK          21.00%\n",
       "Expected but Wrong         2.00%\n",
       "Hallucination              5.00%\n",
       "Did not Expect and IDK    42.00%\n",
       "Name: count, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the evaluator\n",
    "finetuned_model_evaluator = ConfusionMatrixEvaluator(\n",
    "    df, answers_column=\"ft_generated_answer\"\n",
    ")\n",
    "\n",
    "# Run the evaluation\n",
    "finetuned_model_evaluator.evaluate_answers()\n",
    "finetuned_model_error_categories = finetuned_model_evaluator.generate_matrices(\n",
    "    use_percentages=True\n",
    ")\n",
    "finetuned_model_error_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save the results to a JSON file\n",
    "df.to_json(\"local_cache/100_val_ft.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing required libraries for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def evaluate_matrix(df, answers_column):\n",
    "    \"\"\"\n",
    "    Evaluate the confusion matrix for a given DataFrame and answer column.\n",
    "    \"\"\"\n",
    "    evaluator = ConfusionMatrixEvaluator(df, answers_column=answers_column)\n",
    "    evaluator.evaluate_answers()\n",
    "    matrix = evaluator.generate_matrices(use_percentages=True)\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def plot_overall_error(matrix1, matrix2, label1, label2):\n",
    "    \"\"\"\n",
    "    Plot a bar chart showing only the overall error between two confusion matrices.\n",
    "    \"\"\"\n",
    "    # Calculate overall error\n",
    "    error_categories = [\"Expected but Wrong\", \"Hallucination\"]\n",
    "    matrix1_error = sum(\n",
    "        [float(matrix1.loc[cat].replace(\"%\", \"\")) for cat in error_categories]\n",
    "    )\n",
    "    matrix2_error = sum(\n",
    "        [float(matrix2.loc[cat].replace(\"%\", \"\")) for cat in error_categories]\n",
    "    )\n",
    "\n",
    "    labels = [\"Overall Error\"]\n",
    "    matrix1_values = [matrix1_error]\n",
    "    matrix2_values = [matrix2_error]\n",
    "\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(x - width / 2, matrix1_values, width, label=label1)\n",
    "    ax.bar(x + width / 2, matrix2_values, width, label=label2)\n",
    "\n",
    "    ax.set_ylabel(\"Error (%) - Lower is Better\")\n",
    "    ax.set_title(\"Comparison between {} and {}\".format(label1, label2))\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "matrix_plain = evaluate_matrix(df, \"generated_answer\")\n",
    "matrix_ft = evaluate_matrix(df, \"ft_generated_answer\")\n",
    "# Plot only the overall error\n",
    "plot_overall_error(matrix_plain, matrix_ft, \"gpt-3.5-turbo-0613\", \"Fine Tuned\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Shot Learning with Qdrant to Improve RAG\n",
    "\n",
    "So far, we've been using the OpenAI model to answer questions where the answer is present in the context. But what if we want to answer questions where the answer is not present in the context? This is where few-shot learning comes in. Few-shot learning is a type of transfer learning that allows us to answer questions where the answer is not present in the context. We can do this by providing a few examples of the answer we're looking for, and the model will learn to answer questions where the answer is not present in the context."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shot Prompting\n",
    "\n",
    "We'll select a few examples from the dataset, including cases where the answer is not present in the context. We'll then use these examples to create a prompt that we can use to fine-tune the model.\n",
    "\n",
    "We'll measure the baseline on our previous 1K dataset, and then we'll fine-tune the model on the new dataset. We'll then measure the performance of the fine-tuned model on the same 1K dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>is_impossible</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>False</td>\n",
       "      <td>[in the late 1990s]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>False</td>\n",
       "      <td>[singing and dancing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>False</td>\n",
       "      <td>[2003]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>False</td>\n",
       "      <td>[Houston, Texas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>False</td>\n",
       "      <td>[late 1990s]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     title                                           question  \\\n",
       "0  Beyoncé           When did Beyonce start becoming popular?   \n",
       "1  Beyoncé  What areas did Beyonce compete in when she was...   \n",
       "2  Beyoncé  When did Beyonce leave Destiny's Child and bec...   \n",
       "3  Beyoncé       In what city and state did Beyonce  grow up?   \n",
       "4  Beyoncé         In which decade did Beyonce become famous?   \n",
       "\n",
       "                                             context  is_impossible  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...          False   \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...          False   \n",
       "2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...          False   \n",
       "3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...          False   \n",
       "4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...          False   \n",
       "\n",
       "                 answers  \n",
       "0    [in the late 1990s]  \n",
       "1  [singing and dancing]  \n",
       "2                 [2003]  \n",
       "3       [Houston, Texas]  \n",
       "4           [late 1990s]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from qdrant_client.http.models import PointStruct\n",
    "from qdrant_client.http.models import Distance, VectorParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client = QdrantClient(\n",
    "    url=os.getenv(\"QDRANT_URL\"), api_key=os.getenv(\"QDRANT_API_KEY\"), timeout=6000, prefer_grpc=True\n",
    ")\n",
    "\n",
    "# collection_name = \"squadv2-cookbook\"\n",
    "\n",
    "\n",
    "# # Create the collection\n",
    "# qdrant_client.recreate_collection(\n",
    "#     collection_name=collection_name,\n",
    "#     vectors_config=VectorParams(size=384, distance=Distance.COSINE),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fastembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastembed.embedding import DefaultEmbedding\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "embedding_model = DefaultEmbedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding the Questions\n",
    "\n",
    "We embed the entire training set questions. We'll use the question to question similarity to find the most similar questions to the question we're looking for. This is a workflow which is used in RAG to leverage the OpenAI model ability of incontext learning with more examples. This is what we call Few Shot Learning here.\n",
    "\n",
    "### ❗️ Important Note: This step can take upto 3 hours to complete. Please be patient. If you see Out of Memory errors or Kernel Crashes, please reduce the batch size to 32, restart the kernel and run the notebook again. This code needs to be run only ONCE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994a3daab89c4e64b78caf39bcfee553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/130319 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf2827c330b434fa58295794d94356e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130319 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def generate_points_from_dataframe(df: pd.DataFrame) -> List[PointStruct]:\n",
    "#     batch_size = 512\n",
    "#     questions = df[\"question\"].tolist()\n",
    "#     total_batches = len(questions) // batch_size + 1\n",
    "    \n",
    "#     pbar = tqdm(total=len(questions), desc=\"Generating embeddings\")\n",
    "    \n",
    "#     # Generate embeddings in batches to improve performance\n",
    "#     embeddings = []\n",
    "#     for i in range(total_batches):\n",
    "#         start_idx = i * batch_size\n",
    "#         end_idx = min((i + 1) * batch_size, len(questions))\n",
    "#         batch = questions[start_idx:end_idx]\n",
    "        \n",
    "#         batch_embeddings = embedding_model.embed(batch, batch_size=batch_size)\n",
    "#         embeddings.extend(batch_embeddings)\n",
    "#         pbar.update(len(batch))\n",
    "        \n",
    "#     pbar.close()\n",
    "    \n",
    "#     # Convert embeddings to list of lists\n",
    "#     embeddings_list = [embedding.tolist() for embedding in embeddings]\n",
    "    \n",
    "#     # Create a temporary DataFrame to hold the embeddings and existing DataFrame columns\n",
    "#     temp_df = df.copy()\n",
    "#     temp_df[\"embeddings\"] = embeddings_list\n",
    "#     temp_df[\"id\"] = temp_df.index\n",
    "    \n",
    "#     # Generate PointStruct objects using DataFrame apply method\n",
    "#     points = temp_df.progress_apply(\n",
    "#         lambda row: PointStruct(\n",
    "#             id=row[\"id\"],\n",
    "#             vector=row[\"embeddings\"],\n",
    "#             payload={\n",
    "#                 \"question\": row[\"question\"],\n",
    "#                 \"title\": row[\"title\"],\n",
    "#                 \"context\": row[\"context\"],\n",
    "#                 \"is_impossible\": row[\"is_impossible\"],\n",
    "#                 \"answers\": row[\"answers\"],\n",
    "#             },\n",
    "#         ),\n",
    "#         axis=1,\n",
    "#     ).tolist()\n",
    "\n",
    "#     return points\n",
    "\n",
    "# points = generate_points_from_dataframe(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the Embeddings to Qdrant\n",
    "\n",
    "Note that configuring Qdrant is outside the scope of this notebook. Please refer to the [Qdrant](https://qdrant.tech) for more information. We used a timeout of 600 seconds for the upload, and grpc compression to speed up the upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operation_id=0 status=<UpdateStatus.COMPLETED: 'completed'>\n"
     ]
    }
   ],
   "source": [
    "# operation_info = qdrant_client.upsert(\n",
    "#     collection_name=collection_name, wait=True, points=points\n",
    "# )\n",
    "# print(operation_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = get_diverse_sample(train_df, sample_size=100, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Qdrant to Improve RAG Prompt\n",
    "\n",
    "Now that we've uploaded the embeddings to Qdrant, we can use Qdrant to find the most similar questions to the question we're looking for. We'll use the top 5 most similar questions to create a prompt that we can use to fine-tune the model. We'll then measure the performance of the fine-tuned model on the same validation set, but with few shot prompting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff39612710a749fdae166745b2bd2d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_few_shot_prompt(row):\n",
    "\n",
    "    query, row_context = row[\"question\"], row[\"context\"]\n",
    "\n",
    "    embeddings = list(embedding_model.embed([query]))\n",
    "    query_embedding = embeddings[0].tolist()\n",
    "\n",
    "    num_of_qa_to_retrieve = 5\n",
    "\n",
    "    # Pick the most similar question from the collection\n",
    "    q1 = qdrant_client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding,\n",
    "        with_payload=True,\n",
    "        limit=num_of_qa_to_retrieve,\n",
    "        query_filter=models.Filter(\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"is_impossible\",\n",
    "                    match=models.MatchValue(\n",
    "                        value=False,\n",
    "                    ),\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Pick the next best question which has same title but impossible answer/I don't know answer\n",
    "    q2 = qdrant_client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding,\n",
    "        query_filter=models.Filter(\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"is_impossible\",\n",
    "                    match=models.MatchValue(\n",
    "                        value=True,\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "        with_payload=True,\n",
    "        limit=num_of_qa_to_retrieve,\n",
    "    )\n",
    "\n",
    "\n",
    "    instruction = \"\"\"Answer the following Question based on the Context only. Only answer from the Context. If you don't know the answer, say 'I don't know'.\\n\\n\"\"\"\n",
    "    # If there is a next best question, add it to the prompt\n",
    "    \n",
    "    def q_to_prompt(q):\n",
    "        question, context = q.payload[\"question\"], q.payload[\"context\"]\n",
    "        answer = q.payload[\"answers\"][0] if len(q.payload[\"answers\"]) > 0 else \"I don't know\"\n",
    "        return [\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"\"\"Question: {question}\\n\\nContext: {context}\\n\\nAnswer:\"\"\"\n",
    "            },\n",
    "            {\"role\": \"assistant\", \"content\": answer},\n",
    "        ]\n",
    "\n",
    "    rag_prompt = []\n",
    "    # If the next best question is not the same as the question, add it to the prompt\n",
    "    if len(q2) >= 1:\n",
    "        rag_prompt += q_to_prompt(q2[1])\n",
    "    if len(q1) >= 1:\n",
    "        rag_prompt += q_to_prompt(q1[1])\n",
    "        rag_prompt += q_to_prompt(q1[2])\n",
    "    if len(q2) >= 1:\n",
    "        rag_prompt += q_to_prompt(q2[2])\n",
    "    \n",
    "    \n",
    "\n",
    "    rag_prompt += [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"Question: {query}\\n\\nContext: {row_context}\\n\\nAnswer:\"\"\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    rag_prompt = [{\"role\": \"system\", \"content\": instruction}] + rag_prompt\n",
    "    return rag_prompt\n",
    "\n",
    "train_sample[\"few_shot_prompt_1K\"] = train_sample.progress_apply(get_few_shot_prompt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [{'role': 'system', 'content': 'Answer the fol...\n",
       "1    [{'role': 'system', 'content': 'Answer the fol...\n",
       "2    [{'role': 'system', 'content': 'Answer the fol...\n",
       "3    [{'role': 'system', 'content': 'Answer the fol...\n",
       "4    [{'role': 'system', 'content': 'Answer the fol...\n",
       "Name: few_shot_prompt_1K, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample[\"few_shot_prompt_1K\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"Answer the following Question based on the Context only. Only answer from the Context. If you don't know the answer, say 'I don't know'.\\n\\n\"},\n",
       " {'role': 'user',\n",
       "  'content': 'Question: What is the Italian Quarter?\\n\\nContext: Small Armenian trading and religious communities have existed outside of Armenia for centuries. For example, a community has existed for over a millennium in the Holy Land, and one of the four quarters of the walled Old City of Jerusalem has been called the Armenian Quarter. An Armenian Catholic monastic community of 35 founded in 1717 exists on an island near Venice, Italy. There are also remnants of formerly populous communities in India, Myanmar, Thailand, Belgium, Portugal, Italy, Poland, Austria, Hungary, Bulgaria, Romania, Serbia, Ethiopia, Sudan and Egypt.[citation needed]\\n\\nAnswer:'},\n",
       " {'role': 'assistant', 'content': \"I don't know\"},\n",
       " {'role': 'user',\n",
       "  'content': \"Question: What shape is a cirque, generally?\\n\\nContext: Glaciers form where the accumulation of snow and ice exceeds ablation. The area in which a glacier forms is called a cirque (corrie or cwm) - a typically armchair-shaped geological feature (such as a depression between mountains enclosed by arêtes) - which collects and compresses through gravity the snow which falls into it. This snow collects and is compacted by the weight of the snow falling above it forming névé. Further crushing of the individual snowflakes and squeezing the air from the snow turns it into 'glacial ice'. This glacial ice will fill the cirque until it 'overflows' through a geological weakness or vacancy, such as the gap between two mountains. When the mass of snow and ice is sufficiently thick, it begins to move due to a combination of surface slope, gravity and pressure. On steeper slopes, this can occur with as little as 15 m (50 ft) of snow-ice.\\n\\nAnswer:\"},\n",
       " {'role': 'assistant', 'content': 'armchair-shaped'},\n",
       " {'role': 'user',\n",
       "  'content': 'Question: On which side is a cirque opened?\\n\\nContext: At the start of a classic valley glacier is a bowl-shaped cirque, which has escarped walls on three sides but is open on the side that descends into the valley. Cirques are where ice begins to accumulate in a glacier. Two glacial cirques may form back to back and erode their backwalls until only a narrow ridge, called an arête is left. This structure may result in a mountain pass. If multiple cirques encircle a single mountain, they create pointed pyramidal peaks; particularly steep examples are called horns.\\n\\nAnswer:'},\n",
       " {'role': 'assistant', 'content': 'the side that descends into the valley'},\n",
       " {'role': 'user',\n",
       "  'content': 'Question: What are two indications of a larger cerebrum?\\n\\nContext: In intelligent mammals, such as primates, the cerebrum is larger relative to the rest of the brain. Intelligence itself is not easy to define, but indications of intelligence include the ability to learn, matched with behavioral flexibility. Rats, for example, are considered to be highly intelligent, as they can learn and perform new tasks, an ability that may be important when they first colonize a fresh habitat. In some mammals, food gathering appears to be related to intelligence: a deer feeding on plants has a brain smaller than a cat, which must think to outwit its prey.\\n\\nAnswer:'},\n",
       " {'role': 'assistant', 'content': \"I don't know\"},\n",
       " {'role': 'user',\n",
       "  'content': \"Question: What is a cirque?\\n\\nContext: Glaciers form where the accumulation of snow and ice exceeds ablation. The area in which a glacier forms is called a cirque (corrie or cwm) - a typically armchair-shaped geological feature (such as a depression between mountains enclosed by arêtes) - which collects and compresses through gravity the snow which falls into it. This snow collects and is compacted by the weight of the snow falling above it forming névé. Further crushing of the individual snowflakes and squeezing the air from the snow turns it into 'glacial ice'. This glacial ice will fill the cirque until it 'overflows' through a geological weakness or vacancy, such as the gap between two mountains. When the mass of snow and ice is sufficiently thick, it begins to move due to a combination of surface slope, gravity and pressure. On steeper slopes, this can occur with as little as 15 m (50 ft) of snow-ice.\\n\\nAnswer:\"}]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample[\"few_shot_prompt_1K\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Model Fine-Tuning\n",
    "\n",
    "### Upload the Fine-Tuning Data to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf7fea68e3d45e4ade09e63f7abe907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare the OpenAI File format i.e. JSONL from train_sample\n",
    "def dataframe_to_jsonl(df):\n",
    "    def create_jsonl_entry(row):\n",
    "        messages = row[\"few_shot_prompt_1K\"]\n",
    "        return json.dumps({\"messages\": messages})\n",
    "\n",
    "    jsonl_output = df.progress_apply(create_jsonl_entry, axis=1)\n",
    "    return \"\\n\".join(jsonl_output)\n",
    "\n",
    "with open(\"local_cache/100_train_few_shot.jsonl\", \"w\") as f:\n",
    "    f.write(dataframe_to_jsonl(train_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create OpenAI File\n",
    "file_object = openai.File.create(\n",
    "    file=open(\"local_cache/100_train_few_shot.jsonl\", \"r\"),\n",
    "    purpose=\"fine-tune\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💡 Wait: The file object status needs to change to \"processed\" before we can start our fine tuning job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "uploaded\n",
      "processed\n"
     ]
    }
   ],
   "source": [
    "while file_object.status!='processed':\n",
    "    time.sleep(20)\n",
    "    file_object.refresh()\n",
    "    print(file_object.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuning job\n",
    "ft_job = openai.FineTuningJob.create(\n",
    "    training_file=file_object[\"id\"], model=\"gpt-3.5-turbo\", suffix=\"trnfewshot20230907\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💡 Wait: We've to wait till the fine-tuning job is complete i.e. status changes to \"succeeded\" before we can use the fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status:  created\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  running\n",
      "Status:  succeeded\n"
     ]
    }
   ],
   "source": [
    "while ft_job.status!='succeeded':\n",
    "    ft_job.refresh()\n",
    "    print(\"Status: \", ft_job.status)\n",
    "    time.sleep(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ft:gpt-3.5-turbo-0613:qdrant:trnfewshot20230907:7w54vei9'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = openai.FineTuningJob.retrieve(ft_job[\"id\"]).fine_tuned_model\n",
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4333f061f0e54cb5a8a30133308896a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"ft_generated_answer_few_shot\"] = df.progress_apply(answer_question, model=model_id, prompt_func=get_few_shot_prompt, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ft_generated_answer_few_shot': 'illegal boycotts',\n",
       " 'question': 'What is a type of disobedience against the federal government?',\n",
       " 'context': 'Some forms of civil disobedience, such as illegal boycotts, refusals to pay taxes, draft dodging, distributed denial-of-service attacks, and sit-ins, make it more difficult for a system to function. In this way, they might be considered coercive. Brownlee notes that \"although civil disobedients are constrained in their use of coercion by their conscientious aim to engage in moral dialogue, nevertheless they may find it necessary to employ limited coercion in order to get their issue onto the table.\" The Plowshares organization temporarily closed GCSB Waihopai by padlocking the gates and using sickles to deflate one of the large domes covering two satellite dishes.',\n",
       " 'is_impossible': False}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"ft_generated_answer_few_shot\", \"question\", \"context\", \"is_impossible\"]].iloc[5].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Expected and Right        46.00%\n",
       "Expected but IDK           0.00%\n",
       "Expected but Wrong         7.00%\n",
       "Hallucination             44.00%\n",
       "Did not Expect and IDK     3.00%\n",
       "Name: count, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate this using the Evaluator\n",
    "\n",
    "# Initialize the evaluator\n",
    "evaluator = ConfusionMatrixEvaluator(\n",
    "    df, answers_column=\"ft_generated_answer_few_shot\"\n",
    ")\n",
    "evaluator.evaluate_answers()\n",
    "error_categories = evaluator.generate_matrices(use_percentages=True)\n",
    "error_categories"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
