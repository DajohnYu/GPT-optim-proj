{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e67f200",
   "metadata": {},
   "source": [
    "# How to call functions with chat models\n",
    "\n",
    "This notebook covers how to use the Chat Completions API in combination with external functions to extend the capabilities of GPT models.\n",
    "\n",
    "`functions` is an optional parameter in the Chat Completion API which can be used to provide function specifications. The purpose of this is to enable models to generate function arguments which adhere to the provided specifications. Note that the API will not actually execute any function calls. It is up to developers to execute function calls using model outputs.\n",
    "\n",
    "If the `functions` parameter is provided then by default the model will decide when it is appropriate to use one of the functions. The API can be forced to use a specific function by setting the `function_call` parameter to `{\"name\": \"<insert-function-name>\"}`. The API can also be forced to not use any function by setting the `function_call` parameter to `\"none\"`. If a function is used, the output will contain `\"finish_reason\": \"function_message\"` in the response, as well as a `function_call` object that has the name of the function and the generated function arguments.\n",
    "\n",
    "### Overview\n",
    "\n",
    "- **How to generate function arguments:** Specify a set of functions and make calls to the API with specific instructions to generate function arguments.\n",
    "- **How to call functions with model generated arguments:** Close the loop by actually executing specified functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c85e26",
   "metadata": {},
   "source": [
    "## How to generate function arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e71f33",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install scipy\n",
    "!pip install tenacity\n",
    "!pip install tiktoken\n",
    "!pip install termcolor \n",
    "!pip install openai\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dab872c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import requests\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from termcolor import colored\n",
    "\n",
    "GPT_MODEL = \"gpt-3.5-turbo-0613\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ee6a93",
   "metadata": {},
   "source": [
    "## Utilities\n",
    "\n",
    "First let's define a few utilities for making calls to the Chat Completions API and for maintaining and keeping track of the conversation state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "745ceec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, functions=None, function_call=None, model=GPT_MODEL):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
    "    }\n",
    "    json_data = {\"model\": model, \"messages\": messages}\n",
    "    if functions is not None:\n",
    "        json_data.update({\"functions\": functions})\n",
    "    if function_call is not None:\n",
    "        json_data.update({\"function_call\": function_call})\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=json_data,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4d1c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conversation:\n",
    "    def __init__(self):\n",
    "        self.conversation_history = []\n",
    "\n",
    "    def add_message(self, role, content):\n",
    "        message = {\"role\": role, \"content\": content}\n",
    "        self.conversation_history.append(message)\n",
    "\n",
    "    def display_conversation(self, detailed=False):\n",
    "        role_to_color = {\n",
    "            \"system\": \"red\",\n",
    "            \"user\": \"green\",\n",
    "            \"assistant\": \"blue\",\n",
    "            \"function\": \"magenta\",\n",
    "        }\n",
    "        for message in self.conversation_history:\n",
    "            print(\n",
    "                colored(\n",
    "                    f\"{message['role']}: {message['content']}\\n\\n\",\n",
    "                    role_to_color[message[\"role\"]],\n",
    "                )\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d4e02b",
   "metadata": {},
   "source": [
    "## Basic concepts\n",
    "\n",
    "Let's create some function specifications to interface with a hypothetical weather API. Later we'll pass these function specification to the Chat Completions API in order to generate function arguments that adhere to the specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2e25069",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"format\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\", \"format\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_n_day_weather_forecast\",\n",
    "        \"description\": \"Get an N-day weather forecast\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"format\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                },\n",
    "                \"num_days\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"The number of days to forecast\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\", \"format\", \"num_days\"]\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc39899",
   "metadata": {},
   "source": [
    "If we prompt the model about the current weather, it will respond with some clarifying questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "518d6827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': 'I can help you with that. Could you please provide me with your location?'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = Conversation()\n",
    "conversation.add_message(\"system\", \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\")\n",
    "conversation.add_message(\"user\", \"What's the weather like today\")\n",
    "chat_response = chat_completion_request(\n",
    "    conversation.conversation_history, functions=functions\n",
    ")\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "conversation.add_message(assistant_message[\"role\"], assistant_message[\"content\"])\n",
    "assistant_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c999375",
   "metadata": {},
   "source": [
    "Once we provide the missing information, it will generate the appropriate function arguments for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23c42a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': None,\n",
       " 'function_call': {'name': 'get_current_weather',\n",
       "  'arguments': '{\\n  \"location\": \"Glasgow, Scotland\",\\n  \"format\": \"celsius\"\\n}'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.add_message(\"user\", \"I'm in Glasgow, Scotland.\")\n",
    "chat_response = chat_completion_request(\n",
    "    conversation.conversation_history, functions=functions\n",
    ")\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "conversation.add_message(assistant_message[\"role\"], assistant_message[\"content\"])\n",
    "assistant_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14d4762",
   "metadata": {},
   "source": [
    "By prompting it differently, we can get it to target the other function we've told it about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa232e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': 'Sure, I can help you with that. Please provide the number of days you would like to get the weather forecast for.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = Conversation()\n",
    "conversation.add_message(\"system\", \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\")\n",
    "conversation.add_message(\"user\", \"what is the weather going to be like in Glasgow, Scotland over the next x days\")\n",
    "chat_response = chat_completion_request(\n",
    "    conversation.conversation_history, functions=functions\n",
    ")\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "conversation.add_message(assistant_message[\"role\"], assistant_message[\"content\"])\n",
    "assistant_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6172ddac",
   "metadata": {},
   "source": [
    "Once again, the model is asking us for clarification because it doesn't have enough information yet. In this case it already knows the location for the forecast, but it needs to know how many days are required in the forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7d8a543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 0,\n",
       " 'message': {'role': 'assistant',\n",
       "  'content': None,\n",
       "  'function_call': {'name': 'get_n_day_weather_forecast',\n",
       "   'arguments': '{\\n  \"location\": \"Glasgow, Scotland\",\\n  \"format\": \"celsius\",\\n  \"num_days\": 5\\n}'}},\n",
       " 'finish_reason': 'function_call'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.add_message(\"user\", \"5 days\")\n",
    "chat_response = chat_completion_request(\n",
    "    conversation.conversation_history, functions=functions\n",
    ")\n",
    "chat_response.json()[\"choices\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412f79ba",
   "metadata": {},
   "source": [
    "We can force the model to use a specific function, for example get_n_day_weather_forecast. By doing so, we force the model to make assumptions about how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "559371b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': None,\n",
       " 'function_call': {'name': 'get_n_day_weather_forecast',\n",
       "  'arguments': '{\\n  \"location\": \"Toronto, Canada\",\\n  \"format\": \"celsius\",\\n  \"num_days\": 1\\n}'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in this cell we force the model to use get_n_day_weather_forecast\n",
    "conversation = Conversation()\n",
    "conversation.add_message(\"system\", \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\")\n",
    "conversation.add_message(\"user\", \"Give me a weather report for Toronto, Canada.\")\n",
    "chat_response = chat_completion_request(\n",
    "    conversation.conversation_history, functions=functions, function_call={\"name\": \"get_n_day_weather_forecast\"}\n",
    ")\n",
    "chat_response.json()[\"choices\"][0][\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7ab0f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': None,\n",
       " 'function_call': {'name': 'get_current_weather',\n",
       "  'arguments': '{\\n\"location\": \"Toronto, Canada\",\\n\"format\": \"celsius\"\\n}'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we don't force the model to use get_n_day_weather_forecast it may not\n",
    "conversation = Conversation()\n",
    "conversation.add_message(\"system\", \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\")\n",
    "conversation.add_message(\"user\", \"Give me a weather report for Toronto, Canada.\")\n",
    "chat_response = chat_completion_request(\n",
    "    conversation.conversation_history, functions=functions, \n",
    ")\n",
    "chat_response.json()[\"choices\"][0][\"message\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd70e48",
   "metadata": {},
   "source": [
    "We can also force the model to not use a function at all. By doing so we prevent it from producing a proper function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acfe54e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': 'Sure! I will retrieve the current weather in Toronto, Canada for you.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = Conversation()\n",
    "conversation.add_message(\"system\", \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\")\n",
    "conversation.add_message(\"user\", \"Give me the current weather (use Celcius) for Toronto, Canada.\")\n",
    "chat_response = chat_completion_request(\n",
    "    conversation.conversation_history, functions=functions, function_call=\"none\"\n",
    ")\n",
    "chat_response.json()[\"choices\"][0][\"message\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4482aee",
   "metadata": {},
   "source": [
    "## How to call functions with model generated arguments\n",
    "\n",
    "In our next example, we'll demonstrate how to execute functions whose inputs are model-generated, and use this to implement an agent that can answer questions for us about a database. For simplicity we'll use the [Chinook sample database](https://www.sqlitetutorial.net/sqlite-sample-database/).\n",
    "\n",
    "*Note:* SQL generation use cases are high-risk in a production environment - models can be unreliable when generating consistent SQL syntax. A more reliable way to solve this problem may be to build a query generation API that takes the desired columns as input from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7654fef",
   "metadata": {},
   "source": [
    "### Pull SQL Database Info\n",
    "\n",
    "First let's define some helpful utility functions to extract data from a SQLite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30f6b60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened database successfully\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"data/Chinook.db\")\n",
    "print(\"Opened database successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abec0214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_names(conn):\n",
    "    \"\"\"Return a list of table names.\"\"\"\n",
    "    table_names = []\n",
    "    tables = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    for table in tables.fetchall():\n",
    "        table_names.append(table[0])\n",
    "    return table_names\n",
    "\n",
    "\n",
    "def get_column_names(conn, table_name):\n",
    "    \"\"\"Return a list of column names.\"\"\"\n",
    "    column_names = []\n",
    "    columns = conn.execute(f\"PRAGMA table_info('{table_name}');\").fetchall()\n",
    "    for col in columns:\n",
    "        column_names.append(col[1])\n",
    "    return column_names\n",
    "\n",
    "\n",
    "def get_database_info(conn):\n",
    "    \"\"\"Return a list of dicts containing the table name and columns for each table in the database.\"\"\"\n",
    "    table_dicts = []\n",
    "    for table_name in get_table_names(conn):\n",
    "        columns_names = get_column_names(conn, table_name)\n",
    "        table_dicts.append({\"table_name\": table_name, \"column_names\": columns_names})\n",
    "    return table_dicts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e6e5ea",
   "metadata": {},
   "source": [
    "Now can use these utility functions to extract a representation of the database schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c0104cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_schema_dict = get_database_info(conn)\n",
    "database_schema_string = \"\\n\".join(\n",
    "    [\n",
    "        f\"Table: {table['table_name']}\\nColumns: {', '.join(table['column_names'])}\"\n",
    "        for table in database_schema_dict\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae73c9ee",
   "metadata": {},
   "source": [
    "As before, we'll define a function specification for the function we'd like the API to generate arguments for. Notice that we are inserting the database schema into the function specification. This will be important for the model to know about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0258813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"ask_database\",\n",
    "        \"description\": \"Use this function to answer user questions about music. Output should be a fully formed SQL query.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": f\"\"\"\n",
    "                            SQL query extracting info to answer the user's question.\n",
    "                            SQL should be written using this database schema:\n",
    "                            {database_schema_string}\n",
    "                            The query should be returned in plain text, not in JSON.\n",
    "                            \"\"\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da08c121",
   "metadata": {},
   "source": [
    "### SQL execution\n",
    "\n",
    "Now let's implement the function that the agent will use to query the database. We also need to implement utilities to integrate the calls to the Chat Completions API with the function it is calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65585e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_completion_with_function_execution(messages, functions=None):\n",
    "    \"\"\"This function makes a ChatCompletion API call and if a function call is requested, executes the function\"\"\"\n",
    "    try:\n",
    "        response = chat_completion_request(messages, functions)\n",
    "        full_message = response.json()[\"choices\"][0]\n",
    "        if full_message[\"finish_reason\"] == \"function_call\":\n",
    "            print(f\"Function generation requested, calling function\")\n",
    "            return call_function(messages, full_message)\n",
    "        else:\n",
    "            print(f\"Function not required, responding to user\")\n",
    "            return response.json()\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return response\n",
    "\n",
    "\n",
    "def call_function(messages, full_message):\n",
    "    \"\"\"Executes function calls using model generated function arguments.\"\"\"\n",
    "\n",
    "    # We'll add our one function here - this can be extended with any additional functions\n",
    "    if full_message[\"message\"][\"function_call\"][\"name\"] == \"ask_database\":\n",
    "        query = eval(full_message[\"message\"][\"function_call\"][\"arguments\"])\n",
    "        print(f\"Generated SQL query is: {query}\")\n",
    "        try:\n",
    "            results = ask_database(conn, query[\"query\"])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "            # This following block tries to fix any issues in query generation with a subsequent call\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": f\"\"\"Query: {query['query']}\n",
    "The previous query received the error {e}. \n",
    "Please return a fixed SQL query in plain text.\n",
    "Your response should consist of ONLY the SQL query with the separator sql_start at the beginning and sql_end at the end\"\"\",\n",
    "                }\n",
    "            )\n",
    "            response = chat_completion_request(messages, model=\"gpt-4-next\")\n",
    "\n",
    "            # Retrying with the fixed SQL query. If it fails a second time we exit.\n",
    "            try:\n",
    "                cleaned_query = response.json()[\"choices\"][0][\"message\"][\n",
    "                    \"content\"\n",
    "                ].split(\"sql_start\")[1]\n",
    "                cleaned_query = cleaned_query.split(\"sql_end\")[0]\n",
    "                print(cleaned_query)\n",
    "                results = ask_database(conn, cleaned_query)\n",
    "                print(results)\n",
    "                print(\"Got on second try\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"Second failure, exiting\")\n",
    "\n",
    "                print(f\"Function execution failed\")\n",
    "                print(f\"Error message: {e}\")\n",
    "\n",
    "        messages.append(\n",
    "            {\"role\": \"function\", \"name\": \"ask_database\", \"content\": str(results)}\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            response = chat_completion_request(messages)\n",
    "            return response.json()\n",
    "        except Exception as e:\n",
    "            print(type(e))\n",
    "            print(e)\n",
    "            raise Exception(\"Function chat request failed\")\n",
    "    else:\n",
    "        raise Exception(\"Function does not exist and cannot be called\")\n",
    "\n",
    "\n",
    "def ask_database(conn, query):\n",
    "    \"\"\"Function to query SQLite database with provided SQL query.\"\"\"\n",
    "    try:\n",
    "        results = conn.execute(query).fetchall()\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"SQL error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38c55083",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_system_message = \"\"\"Answer user questions by generating SQL queries against the Chinook Music Database.\"\"\"\n",
    "\n",
    "sql_conversation = Conversation()\n",
    "sql_conversation.add_message(\"system\", agent_system_message)\n",
    "sql_conversation.add_message(\n",
    "    \"user\", \"Hi, who are the top 5 artists by number of tracks?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2e5338e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function generation requested, calling function\n",
      "Prepped query is {'query': 'SELECT Artist.Name, COUNT(*) as TrackCount FROM Artist JOIN Album ON Artist.ArtistId = Album.ArtistId JOIN Track ON Album.AlbumId = Track.AlbumId GROUP BY Artist.Name ORDER BY TrackCount DESC LIMIT 5'}\n",
      "The top 5 artists with the highest number of tracks in the Chinook Music Database are:\n",
      "\n",
      "1. Iron Maiden - 213 tracks\n",
      "2. U2 - 135 tracks\n",
      "3. Led Zeppelin - 114 tracks\n",
      "4. Metallica - 112 tracks\n",
      "5. Lost - 92 tracks\n",
      "\n",
      "Please note that these rankings are based on the number of tracks available in the database and may not necessarily reflect an artist's overall discography.\n"
     ]
    }
   ],
   "source": [
    "chat_response = chat_completion_with_function_execution(\n",
    "    sql_conversation.conversation_history, functions=functions\n",
    ")\n",
    "try:\n",
    "    assistant_message = chat_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    print(assistant_message)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(chat_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28471ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: You are ChinookGPT, a helpful assistant who gets answers to user questions from the Chinook Music Database.\n",
      "Provide as many details as possible to your users\n",
      "Begin!\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32muser: Hi, who are the top 5 artists by number of tracks\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35mfunction: [('Iron Maiden', 213), ('U2', 135), ('Led Zeppelin', 114), ('Metallica', 112), ('Lost', 92)]\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34massistant: The top 5 artists with the highest number of tracks in the Chinook Music Database are:\n",
      "\n",
      "1. Iron Maiden - 213 tracks\n",
      "2. U2 - 135 tracks\n",
      "3. Led Zeppelin - 114 tracks\n",
      "4. Metallica - 112 tracks\n",
      "5. Lost - 92 tracks\n",
      "\n",
      "Please note that these rankings are based on the number of tracks available in the database and may not necessarily reflect an artist's overall discography.\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sql_conversation.add_message(\"assistant\", assistant_message)\n",
    "sql_conversation.display_conversation(detailed=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "710481dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_conversation.add_message(\n",
    "    \"user\", \"What is the name of the album with the most tracks\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40f954e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function generation requested, calling function\n",
      "Prepped query is {'query': 'SELECT AlbumId, Title, COUNT(TrackId) AS TrackCount FROM Album GROUP BY AlbumId ORDER BY TrackCount DESC LIMIT 1'}\n",
      "SQL error: no such column: TrackId\n",
      "\n",
      "SELECT Album.Title, COUNT(Track.TrackId) AS TrackCount \n",
      "FROM Album \n",
      "JOIN Track ON Album.AlbumId = Track.AlbumId \n",
      "GROUP BY Album.AlbumId \n",
      "ORDER BY TrackCount DESC \n",
      "LIMIT 1\n",
      "\n",
      "[('Greatest Hits', 57)]\n",
      "Got on second try\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sql_start\\nSELECT Title, COUNT(TrackId) AS TrackCount \\nFROM Album \\nGROUP BY Title \\nORDER BY TrackCount DESC \\nLIMIT 1\\nsql_end'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response = chat_completion_with_function_execution(\n",
    "    sql_conversation.conversation_history, functions=functions\n",
    ")\n",
    "assistant_message = chat_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "assistant_message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df2518ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_conversation.add_message(\"assistant\", assistant_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13984dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: You are ChinookGPT, a helpful assistant who gets answers to user questions from the Chinook Music Database.\n",
      "Provide as many details as possible to your users\n",
      "Begin!\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32muser: Hi, who are the top 5 artists by number of tracks\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35mfunction: [('Iron Maiden', 213), ('U2', 135), ('Led Zeppelin', 114), ('Metallica', 112), ('Lost', 92)]\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34massistant: The top 5 artists with the highest number of tracks in the Chinook Music Database are:\n",
      "\n",
      "1. Iron Maiden - 213 tracks\n",
      "2. U2 - 135 tracks\n",
      "3. Led Zeppelin - 114 tracks\n",
      "4. Metallica - 112 tracks\n",
      "5. Lost - 92 tracks\n",
      "\n",
      "Please note that these rankings are based on the number of tracks available in the database and may not necessarily reflect an artist's overall discography.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32muser: What is the name of the album with the most tracks\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31msystem: Query: SELECT AlbumId, Title, COUNT(TrackId) AS TrackCount FROM Album GROUP BY AlbumId ORDER BY TrackCount DESC LIMIT 1\n",
      "The previous query received the error SQL error: no such column: TrackId. \n",
      "Please return a fixed SQL query in plain text.\n",
      "Your response should consist of ONLY the SQL query with the separator sql_start at the beginning and sql_end at the end\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35mfunction: [('Greatest Hits', 57)]\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34massistant: sql_start\n",
      "SELECT Title, COUNT(TrackId) AS TrackCount \n",
      "FROM Album \n",
      "GROUP BY Title \n",
      "ORDER BY TrackCount DESC \n",
      "LIMIT 1\n",
      "sql_end\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sql_conversation.display_conversation(detailed=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
