{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6806af9-68ae-4714-851c-9a967aee0e23",
   "metadata": {},
   "source": [
    "OpenAI recently released **Distillation** which allows to leverage the outputs of a (large) model to fine-tune another (smaller) model. This can significantly reduce the price and the latency for specific tasks as you move to a smaller model. In this cookbook we'll look at a dataset, distill the output of gpt-4o to gpt-4o-mini and show how we can get significantly better results than on a generic, non-distilled, 4o-mini.\n",
    "\n",
    "We'll also leverage **Structured Outputs** for a classification problem using a list of enum. We'll see how fine-tuned model can benefit from structured output and how it impact the performance. We'll show that **Structured Ouputs** works with all of those models, including the distilled one.\n",
    "\n",
    "We'll first analyze the dataset, get the output of both 4o and 4o mini, highlighting the difference in performance of both models, then proceed to the distillation and analyze the performance of this distilled model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd8fd2f-dfdf-47c2-9627-02acbe3fb7a2",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Let's install and load dependencies.\n",
    "Make sure your OpenAI API key is defined in your environment as \"OPENAI_API_KEY\" and it'll be loaded by the client directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e16ed9ef-0220-4f23-a8eb-40813eacf210",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai tiktoken numpy pandas --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b643798-3b2b-43e4-bfb5-ebcf74066253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import tiktoken\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246364b6-2fed-4b54-b540-09569a197a6b",
   "metadata": {},
   "source": [
    "## Loading and understanding the dataset\n",
    "\n",
    "For this cookbook, we'll load the data from the following Kaggle challenge: [https://www.kaggle.com/datasets/zynicide/wine-reviews](https://www.kaggle.com/datasets/zynicide/wine-reviews).\n",
    "\n",
    "This dataset has a large number of rows and you're free to run this cookbook on the whole data, but as a biaised french wine-lover, I'll narrow down the dataset to only French wine to focus on less rows and grape varieties.\n",
    "\n",
    "We're looking at a classification problem where we'd like to guess the grape variety based on all other criterias available, including description, subregion and province that we'll include in the prompt. It gives a lot of information to the model, you're free to also remove some information that can help significantly the model such as the region in which it was produced to see if it does a good job at finding the grape.\n",
    "\n",
    "Let's filter the grape varieties that have less than 5 occurences in reviews.\n",
    "\n",
    "Let's proceed with a subset of 500 random rows from this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "759d1705-2213-443a-9fc3-050bc00177e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52178</th>\n",
       "      <td>52178</td>\n",
       "      <td>France</td>\n",
       "      <td>This is a structured wine, with solid tannins ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>Bordeaux Supérieur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Château Barreyre 2011  Bordeaux Supérieur</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "      <td>Château Barreyre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34287</th>\n",
       "      <td>34287</td>\n",
       "      <td>France</td>\n",
       "      <td>White peach and spice notes billow aromaticall...</td>\n",
       "      <td>Brut</td>\n",
       "      <td>86</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>Crémant d'Alsace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Hubert Meyer NV Brut Sparkling (Crémant d'Alsace)</td>\n",
       "      <td>Sparkling Blend</td>\n",
       "      <td>Hubert Meyer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95227</th>\n",
       "      <td>95227</td>\n",
       "      <td>France</td>\n",
       "      <td>This wine is fairly soft and muted, with delic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Languedoc-Roussillon</td>\n",
       "      <td>Pays d'Oc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lauren Buzzeo</td>\n",
       "      <td>@laurbuzz</td>\n",
       "      <td>Les Jamelles 2016 Viognier (Pays d'Oc)</td>\n",
       "      <td>Viognier</td>\n",
       "      <td>Les Jamelles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84797</th>\n",
       "      <td>84797</td>\n",
       "      <td>France</td>\n",
       "      <td>Made by the same team as Château Pichon Longue...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>Haut-Médoc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Château Bernadotte 2011  Haut-Médoc</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "      <td>Château Bernadotte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78982</th>\n",
       "      <td>78982</td>\n",
       "      <td>France</td>\n",
       "      <td>Fresh and fruity, it has ripe blackberries, so...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>Côtes de Bourg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Bailli de Bourg 2011  Côtes de Bourg</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "      <td>Bailli de Bourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57100</th>\n",
       "      <td>57100</td>\n",
       "      <td>France</td>\n",
       "      <td>This is the rare Côtes du Rhône that needs cel...</td>\n",
       "      <td>Cuvée Maclura</td>\n",
       "      <td>90</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Rhône Valley</td>\n",
       "      <td>Côtes du Rhône</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Joe Czerwinski</td>\n",
       "      <td>@JoeCz</td>\n",
       "      <td>Château Pégau 2013 Cuvée Maclura Red (Côtes du...</td>\n",
       "      <td>Rhône-style Red Blend</td>\n",
       "      <td>Château Pégau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47874</th>\n",
       "      <td>47874</td>\n",
       "      <td>France</td>\n",
       "      <td>This is round, while also having a mineral edg...</td>\n",
       "      <td>Les Narvaux</td>\n",
       "      <td>88</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Burgundy</td>\n",
       "      <td>Meursault</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Domaine Vincent Girardin 2010 Les Narvaux  (Me...</td>\n",
       "      <td>Chardonnay</td>\n",
       "      <td>Domaine Vincent Girardin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65807</th>\n",
       "      <td>65807</td>\n",
       "      <td>France</td>\n",
       "      <td>Made from organic grapes, this wine blends eve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Southwest France</td>\n",
       "      <td>Gaillac</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Château de Rhodes 2012 Red (Gaillac)</td>\n",
       "      <td>Red Blend</td>\n",
       "      <td>Château de Rhodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27091</th>\n",
       "      <td>27091</td>\n",
       "      <td>France</td>\n",
       "      <td>A light, fresh wine, with flavors of crushed s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Burgundy</td>\n",
       "      <td>Bourgogne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Michel Picard 2006  Bourgogne</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Michel Picard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123874</th>\n",
       "      <td>123874</td>\n",
       "      <td>France</td>\n",
       "      <td>The blend of delightfully crisp wine is based ...</td>\n",
       "      <td>Blanc de Blancs Brut</td>\n",
       "      <td>91</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Champagne</td>\n",
       "      <td>Champagne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Vollereaux NV Blanc de Blancs Brut Chardonnay ...</td>\n",
       "      <td>Chardonnay</td>\n",
       "      <td>Vollereaux</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0 country                                        description  \\\n",
       "52178        52178  France  This is a structured wine, with solid tannins ...   \n",
       "34287        34287  France  White peach and spice notes billow aromaticall...   \n",
       "95227        95227  France  This wine is fairly soft and muted, with delic...   \n",
       "84797        84797  France  Made by the same team as Château Pichon Longue...   \n",
       "78982        78982  France  Fresh and fruity, it has ripe blackberries, so...   \n",
       "...            ...     ...                                                ...   \n",
       "57100        57100  France  This is the rare Côtes du Rhône that needs cel...   \n",
       "47874        47874  France  This is round, while also having a mineral edg...   \n",
       "65807        65807  France  Made from organic grapes, this wine blends eve...   \n",
       "27091        27091  France  A light, fresh wine, with flavors of crushed s...   \n",
       "123874      123874  France  The blend of delightfully crisp wine is based ...   \n",
       "\n",
       "                 designation  points  price              province  \\\n",
       "52178                    NaN      90   20.0              Bordeaux   \n",
       "34287                   Brut      86   13.0                Alsace   \n",
       "95227                    NaN      84   10.0  Languedoc-Roussillon   \n",
       "84797                    NaN      89    NaN              Bordeaux   \n",
       "78982                    NaN      85   19.0              Bordeaux   \n",
       "...                      ...     ...    ...                   ...   \n",
       "57100          Cuvée Maclura      90   20.0          Rhône Valley   \n",
       "47874            Les Narvaux      88   56.0              Burgundy   \n",
       "65807                    NaN      92   17.0      Southwest France   \n",
       "27091                    NaN      84    NaN              Burgundy   \n",
       "123874  Blanc de Blancs Brut      91   37.0             Champagne   \n",
       "\n",
       "                  region_1 region_2     taster_name taster_twitter_handle  \\\n",
       "52178   Bordeaux Supérieur      NaN      Roger Voss            @vossroger   \n",
       "34287     Crémant d'Alsace      NaN      Roger Voss            @vossroger   \n",
       "95227            Pays d'Oc      NaN   Lauren Buzzeo             @laurbuzz   \n",
       "84797           Haut-Médoc      NaN      Roger Voss            @vossroger   \n",
       "78982       Côtes de Bourg      NaN      Roger Voss            @vossroger   \n",
       "...                    ...      ...             ...                   ...   \n",
       "57100       Côtes du Rhône      NaN  Joe Czerwinski                @JoeCz   \n",
       "47874            Meursault      NaN      Roger Voss            @vossroger   \n",
       "65807              Gaillac      NaN      Roger Voss            @vossroger   \n",
       "27091            Bourgogne      NaN      Roger Voss            @vossroger   \n",
       "123874           Champagne      NaN      Roger Voss            @vossroger   \n",
       "\n",
       "                                                    title  \\\n",
       "52178           Château Barreyre 2011  Bordeaux Supérieur   \n",
       "34287   Hubert Meyer NV Brut Sparkling (Crémant d'Alsace)   \n",
       "95227              Les Jamelles 2016 Viognier (Pays d'Oc)   \n",
       "84797                 Château Bernadotte 2011  Haut-Médoc   \n",
       "78982                Bailli de Bourg 2011  Côtes de Bourg   \n",
       "...                                                   ...   \n",
       "57100   Château Pégau 2013 Cuvée Maclura Red (Côtes du...   \n",
       "47874   Domaine Vincent Girardin 2010 Les Narvaux  (Me...   \n",
       "65807                Château de Rhodes 2012 Red (Gaillac)   \n",
       "27091                       Michel Picard 2006  Bourgogne   \n",
       "123874  Vollereaux NV Blanc de Blancs Brut Chardonnay ...   \n",
       "\n",
       "                         variety                    winery  \n",
       "52178   Bordeaux-style Red Blend          Château Barreyre  \n",
       "34287            Sparkling Blend              Hubert Meyer  \n",
       "95227                   Viognier              Les Jamelles  \n",
       "84797   Bordeaux-style Red Blend        Château Bernadotte  \n",
       "78982   Bordeaux-style Red Blend           Bailli de Bourg  \n",
       "...                          ...                       ...  \n",
       "57100      Rhône-style Red Blend             Château Pégau  \n",
       "47874                 Chardonnay  Domaine Vincent Girardin  \n",
       "65807                  Red Blend         Château de Rhodes  \n",
       "27091                 Pinot Noir             Michel Picard  \n",
       "123874                Chardonnay                Vollereaux  \n",
       "\n",
       "[500 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/winemag/winemag-data-130k-v2.csv')\n",
    "df_france = df[df['country'] == 'France']\n",
    "\n",
    "# Let's also filter out wines that have less than 5 references with their grape variety – even though we'd like to find those\n",
    "# they're outliers that we don't want to optimize for that would make our enum list be too long\n",
    "# and they could also add noise for the rest of the dataset on which we'd like to guess, eventually reducing our accuracy.\n",
    "\n",
    "varieties_less_than_five_list = df_france['variety'].value_counts()[df_france['variety'].value_counts() < 5].index.tolist()\n",
    "df_france = df_france[~df_france['variety'].isin(varieties_less_than_five_list)]\n",
    "\n",
    "df_france_subset = df_france.sample(n=500)\n",
    "df_france_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96cd12f-cbdf-46af-958f-3d553598be1d",
   "metadata": {},
   "source": [
    "Let's retrieve all grape varieties to include them in the prompt and in our structured outputs enum list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06f5dbea-549a-455d-9b6e-051de9d38723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Gewürztraminer', 'Pinot Gris', 'Gamay',\n",
       "       'Bordeaux-style White Blend', 'Champagne Blend', 'Chardonnay',\n",
       "       'Petit Manseng', 'Riesling', 'White Blend', 'Pinot Blanc',\n",
       "       'Alsace white blend', 'Bordeaux-style Red Blend', 'Malbec',\n",
       "       'Tannat-Cabernet', 'Rhône-style Red Blend', 'Ugni Blanc-Colombard',\n",
       "       'Savagnin', 'Pinot Noir', 'Rosé', 'Melon',\n",
       "       'Rhône-style White Blend', 'Pinot Noir-Gamay', 'Colombard',\n",
       "       'Chenin Blanc', 'Sylvaner', 'Sauvignon Blanc', 'Red Blend',\n",
       "       'Chenin Blanc-Chardonnay', 'Cabernet Sauvignon', 'Cabernet Franc',\n",
       "       'Syrah', 'Sparkling Blend', 'Duras', 'Provence red blend',\n",
       "       'Tannat', 'Merlot', 'Malbec-Merlot', 'Chardonnay-Viognier',\n",
       "       'Cabernet Franc-Cabernet Sauvignon', 'Muscat', 'Viognier',\n",
       "       'Picpoul', 'Altesse', 'Provence white blend', 'Mondeuse',\n",
       "       'Grenache-Syrah', 'G-S-M', 'Pinot Meunier', 'Cabernet-Syrah',\n",
       "       'Vermentino', 'Marsanne', 'Colombard-Sauvignon Blanc',\n",
       "       'Gros and Petit Manseng', 'Jacquère', 'Negrette', 'Mauzac',\n",
       "       'Pinot Auxerrois', 'Grenache', 'Roussanne', 'Gros Manseng',\n",
       "       'Tannat-Merlot', 'Aligoté', 'Chasselas', \"Loin de l'Oeil\",\n",
       "       'Malbec-Tannat', 'Carignan', 'Colombard-Ugni Blanc', 'Sémillon',\n",
       "       'Syrah-Grenache', 'Sciaccerellu', 'Auxerrois', 'Mourvèdre',\n",
       "       'Tannat-Cabernet Franc', 'Braucol', 'Trousseau',\n",
       "       'Merlot-Cabernet Sauvignon'], dtype='<U33')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varieties = np.array(df_france['variety'].unique()).astype('str')\n",
    "varieties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6612e612-698d-4f1a-8008-70fb5ff263a0",
   "metadata": {},
   "source": [
    "## Generating the prompt\n",
    "\n",
    "Let's build out a function to generate our prompt and try it for the first wine of our list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3ec2fba-9c99-4cb7-bf56-f13e3816e559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Based on this wine review, guess the grape variety:\\n    This wine is produced by Trimbach in the Alsace region of France.\\n    It was grown in Alsace. It is described as: \"This dry and restrained wine offers spice in profusion. Balanced with acidity and a firm texture, it\\'s very much for food.\".\\n    The wine has been reviewed by Roger Voss and received 87 points.\\n    The price is 24.0.\\n\\n    Here is a list of possible grape varieties to choose from: Gewürztraminer, Pinot Gris, Gamay, Bordeaux-style White Blend, Champagne Blend, Chardonnay, Petit Manseng, Riesling, White Blend, Pinot Blanc, Alsace white blend, Bordeaux-style Red Blend, Malbec, Tannat-Cabernet, Rhône-style Red Blend, Ugni Blanc-Colombard, Savagnin, Pinot Noir, Rosé, Melon, Rhône-style White Blend, Pinot Noir-Gamay, Colombard, Chenin Blanc, Sylvaner, Sauvignon Blanc, Red Blend, Chenin Blanc-Chardonnay, Cabernet Sauvignon, Cabernet Franc, Syrah, Sparkling Blend, Duras, Provence red blend, Tannat, Merlot, Malbec-Merlot, Chardonnay-Viognier, Cabernet Franc-Cabernet Sauvignon, Muscat, Viognier, Picpoul, Altesse, Provence white blend, Mondeuse, Grenache-Syrah, G-S-M, Pinot Meunier, Cabernet-Syrah, Vermentino, Marsanne, Colombard-Sauvignon Blanc, Gros and Petit Manseng, Jacquère, Negrette, Mauzac, Pinot Auxerrois, Grenache, Roussanne, Gros Manseng, Tannat-Merlot, Aligoté, Chasselas, Loin de l\\'Oeil, Malbec-Tannat, Carignan, Colombard-Ugni Blanc, Sémillon, Syrah-Grenache, Sciaccerellu, Auxerrois, Mourvèdre, Tannat-Cabernet Franc, Braucol, Trousseau, Merlot-Cabernet Sauvignon.\\n    \\n    What is the likely grape variety? Answer only with the grape variety name or blend from the list.\\n    '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_prompt(row, varieties):\n",
    "    # Format the varieties list as a comma-separated string\n",
    "    variety_list = ', '.join(varieties)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Based on this wine review, guess the grape variety:\n",
    "    This wine is produced by {row['winery']} in the {row['province']} region of {row['country']}.\n",
    "    It was grown in {row['region_1']}. It is described as: \"{row['description']}\".\n",
    "    The wine has been reviewed by {row['taster_name']} and received {row['points']} points.\n",
    "    The price is {row['price']}.\n",
    "\n",
    "    Here is a list of possible grape varieties to choose from: {variety_list}.\n",
    "    \n",
    "    What is the likely grape variety? Answer only with the grape variety name or blend from the list.\n",
    "    \"\"\"\n",
    "    # we could add the following if needed but it looks like it doesn't improve (on 20 rows):\n",
    "    return prompt\n",
    "\n",
    "# Example usage with a specific row\n",
    "prompt = generate_prompt(df_france.iloc[0], varieties)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf208f5-0a70-41cb-b2c0-c340ee55d6d1",
   "metadata": {},
   "source": [
    "To get a understanding of the cost before running the queries, you can leverage tiktoken to understand the number of tokens we'll send and the cost associated to run this. This will only give you an estimate for to run the completions, not the fine-tuning process (used later in this cookbook when running the distillation), which depends on other factors such as the number of epochs, training set etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf43b5f4-dbfb-4c89-a7f8-2bd7b03c49c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in the dataset: 244763\n",
      "Total number of prompts: 500\n"
     ]
    }
   ],
   "source": [
    "# Load encoding for the GPT-4 model\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "\n",
    "# Initialize a variable to store the total number of tokens\n",
    "total_tokens = 0\n",
    "\n",
    "for index, row in df_france_subset.iterrows():\n",
    "    prompt = generate_prompt(row, varieties)\n",
    "    \n",
    "    # Tokenize the input text and count tokens\n",
    "    tokens = enc.encode(prompt)\n",
    "    token_count = len(tokens)\n",
    "    \n",
    "    # Add the token count to the total\n",
    "    total_tokens += token_count\n",
    "\n",
    "print(f\"Total number of tokens in the dataset: {total_tokens}\")\n",
    "print(f\"Total number of prompts: {len(df_france_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "362e1ddd-2a87-433e-bcba-534ae946c2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6119075\n",
      "0.036714449999999996\n"
     ]
    }
   ],
   "source": [
    "# outputing cost in $ as of 2024/10/16\n",
    "\n",
    "gpt4o_token_price = 2.50 / 1_000_000  # $2.50 per 1M tokens\n",
    "gpt4o_mini_token_price = 0.150 / 1_000_000  # $0.15 per 1M tokens\n",
    "\n",
    "total_gpt4o_cost = gpt4o_token_price*total_tokens\n",
    "total_gpt4o_mini_cost = gpt4o_mini_token_price*total_tokens\n",
    "\n",
    "print(total_gpt4o_cost)\n",
    "print(total_gpt4o_mini_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff1181a-6b06-4ad3-8d68-7afb64518010",
   "metadata": {},
   "source": [
    "## Preparing functions to Store Completions\n",
    "\n",
    "As we're looking at a limited list of response (enumerate list of grape varieties), let's leverage structured outputs so we make sure the model will answer from this list. This also allows us to compare the model's answer directly with the grape variety and have a deterministic answer (compared to a model that could answer \"I think the grape is Pinot Noir\" instead of just \"Pinot noir\"), on top of improving the performance to avoid grape varieties not in our dataset.\n",
    "\n",
    "If you want to know more on Structured Outputs you can read this [cookbook](https://cookbook.openai.com/examples/structured_outputs_intro) and this [documentation guide](https://platform.openai.com/docs/guides/structured-outputs/introduction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4153ca1a-c195-4102-a6c3-f570dd6ae372",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_format = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"grape-variety\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"variety\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": varieties.tolist()\n",
    "                }\n",
    "            },\n",
    "            \"additionalProperties\": False,\n",
    "            \"required\": [\"variety\"],\n",
    "        },\n",
    "        \"strict\": True\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fedb40e-72e5-4aba-8bc2-b244111b4b43",
   "metadata": {},
   "source": [
    "To distill a model, you need to store all completions from a model, allowing you to give it as a reference to the smaller model to fine-tune it. We're therefore adding a `store=True` parameter to our `client.chat.completions.create` method so we can store those completions from gpt-4o.\n",
    "\n",
    "We're going to store all completions (even 4o-mini and our future fine-tuned model) so we are able to run [Evals](https://platform.openai.com/docs/guides/evals) from OpenAI platform directly.\n",
    "\n",
    "When storing those completions, it's useful to store them with a metadata tag, that will allow filtering from the OpenAI platform to run distillation & evals on the specific set of completions you'd like to run those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85cb4cc7-077a-4afe-aefc-85b768adfc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the progress index\n",
    "metadata_value = \"wine-distillation\" # that's a funny metadata tag :-)\n",
    "\n",
    "# Function to call the API and process the result for a single model (blocking call in this case)\n",
    "def call_model(model, prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        store=True,\n",
    "        metadata={\n",
    "            \"distillation\": metadata_value,\n",
    "        },\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You're a sommelier expert and you know everything about wine. You answer precisely with the name of the variety/blend.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "         response_format=response_format\n",
    "    )\n",
    "    return json.loads(response.choices[0].message.content.strip())['variety']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4ae8e1-20cb-43b4-a7b1-9998e09f4394",
   "metadata": {},
   "source": [
    "## Parallel processing\n",
    "\n",
    "As we'll run this on a large number of rows, let's make sure we run those completions in parallel and use concurrent futures for this. We'll iterate on our dataframe and output progress every 20 rows. We'll store the completion from the model we run the completion for in the same dataframe using the column name `{model}-variety`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81ddec71-c2a6-411a-aecd-6556cddc36c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_example(index, row, model, df):\n",
    "    global progress_index\n",
    "    \n",
    "    try:\n",
    "        # Generate the prompt using the row\n",
    "        prompt = generate_prompt(row, varieties)\n",
    "\n",
    "        df.at[index, model + \"-variety\"] = call_model(model, prompt)\n",
    "        \n",
    "        # Print progress only for every 20th row\n",
    "        if progress_index % 20 == 0:\n",
    "            print(f\"Question processed {progress_index}/{len(df)}\")\n",
    "        \n",
    "        progress_index += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing model {model}: {str(e)}\")\n",
    "\n",
    "\n",
    "def process_dataframe(df, model):\n",
    "    global progress_index\n",
    "    progress_index = 1  # Reset progress index\n",
    "\n",
    "    # Process each example concurrently using ThreadPoolExecutor\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(process_example, index, row, model, df): index for index, row in df.iterrows()}\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                future.result()  # Wait for each example to be processed\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing example: {str(e)}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680587d1-bcb8-45bd-bfe8-1f771ae1a5bd",
   "metadata": {},
   "source": [
    "Let's try out our call model function before processing the whole dataframe and check the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95915fd2-24f6-4908-a54f-9ce59073233d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bordeaux-style Red Blend'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = call_model('gpt-4o', generate_prompt(df_france_subset.iloc[0], varieties))\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941b9027-eb22-4eed-84de-8b962fe4fee2",
   "metadata": {},
   "source": [
    "Great! We confirmed we can get a grape variety as an output, let's now process the dataset with both `gpt-4o` and `gpt-4o-mini` and compare the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cedf978-e60b-4f56-9c8c-da6b0a722320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question processed 20/500\n",
      "Question processed 40/500\n",
      "Question processed 60/500\n",
      "Question processed 80/500\n",
      "Question processed 100/500\n",
      "Question processed 120/500\n",
      "Question processed 140/500\n",
      "Question processed 160/500\n",
      "Question processed 180/500\n",
      "Question processed 200/500\n",
      "Question processed 220/500\n",
      "Question processed 240/500\n",
      "Question processed 260/500\n",
      "Question processed 280/500\n",
      "Question processed 300/500\n",
      "Question processed 320/500\n",
      "Question processed 340/500\n",
      "Question processed 360/500\n",
      "Question processed 380/500\n",
      "Question processed 400/500\n",
      "Question processed 420/500\n",
      "Question processed 440/500\n",
      "Question processed 460/500\n",
      "Question processed 480/500\n",
      "Question processed 500/500\n"
     ]
    }
   ],
   "source": [
    "df_france_subset = process_dataframe(df_france_subset, \"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93a96539-e25d-4d15-adc0-ef8cbacd70e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question processed 20/500\n",
      "Question processed 40/500\n",
      "Question processed 60/500\n",
      "Question processed 80/500\n",
      "Question processed 100/500\n",
      "Question processed 120/500\n",
      "Question processed 140/500\n",
      "Question processed 160/500\n",
      "Question processed 180/500\n",
      "Question processed 200/500\n",
      "Question processed 220/500\n",
      "Question processed 240/500\n",
      "Question processed 260/500\n",
      "Question processed 280/500\n",
      "Question processed 300/500\n",
      "Question processed 320/500\n",
      "Question processed 340/500\n",
      "Question processed 360/500\n",
      "Question processed 380/500\n",
      "Question processed 400/500\n",
      "Question processed 420/500\n",
      "Question processed 440/500\n",
      "Question processed 460/500\n",
      "Question processed 480/500\n",
      "Question processed 500/500\n"
     ]
    }
   ],
   "source": [
    "df_france_subset = process_dataframe(df_france_subset, \"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74869ee-3361-4d08-bd46-126239d6008c",
   "metadata": {},
   "source": [
    "## Comparing gpt-4o and gpt-4o-mini\n",
    "\n",
    "Now that we've got all chat completions for those two models ; let's compare them against the expected grape variety and assess their accuracy at finding it. We'll do this directly in python here as we've got a simple string check to run, but if your task involves more complex evals you can leverage OpenAI Evals or our open-source eval framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cce147d2-32e4-4005-9f79-11394c76c2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o accuracy: 83.60%\n",
      "gpt-4o-mini accuracy: 69.80%\n"
     ]
    }
   ],
   "source": [
    "models = ['gpt-4o', 'gpt-4o-mini']\n",
    "\n",
    "def get_accuracy(model, df):\n",
    "    return np.mean(df['variety'] == df[model + '-variety'])\n",
    "\n",
    "for model in models:\n",
    "    print(f\"{model} accuracy: {get_accuracy(model, df_france_subset) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6ae1c1-22e5-4a61-a055-7b98360de523",
   "metadata": {},
   "source": [
    "We can see that gpt-4o is better a finding grape variety than 4o-mini (13.80% higher or almost 20% relatively to 4o-mini!). Now I'm wondering if we're making gpt-4o drink wine during training!\n",
    "\n",
    "## Distilling gpt-4o outputs to gpt-4o-mini\n",
    "\n",
    "Let's assume we'd like to run this prediction often, we want completions to be faster and cheaper, but keep that level of accuracy. That'd be great to be able to distill 4o accuracy to 4o-mini, wouldn't it? Let's do it!\n",
    "\n",
    "We'll now go to OpenAI Stored completions page: [https://platform.openai.com/chat-completions](https://platform.openai.com/chat-completions).\n",
    "\n",
    "Let's select the model gpt-4o (make sure to do this, you don't want to distill the outputs of 4o-mini that we ran). Let's also select the metadata `distillation: wine-distillation` to get only stored completions ran from this cookbook.\n",
    "\n",
    "![Filtering out completions](../images/filtering-out-completions.png)\n",
    "\n",
    "Once you've selected completions, you can click on \"Distill\" on the top right corner to fine-tune a model based on those completions. Once we've done that, a file to run the fine-tuning process will automatically be created. Let's then select `gpt-4o-mini` as the base model, keep the default parameters (but you're free to change them or iterate with it to improve performance).\n",
    "\n",
    "![Distilling modal](../images/distilling.png)\n",
    "\n",
    "Once the fine-tuning job is starting, you can retrieve the fine tuning job ID from the fine-tuning page, we'll use it to monitor status of the fine-tuned job as well as retrieving the fine-tuned model id once done.\n",
    "\n",
    "![Fine tuning job](../images/fine-tuning-job.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78a1b24e-3956-48f0-ae56-399f729a6c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuned model: ft:gpt-4o-mini-2024-07-18:distillation-test:wine-distillation:AIZntSyE\n"
     ]
    }
   ],
   "source": [
    "# copy paste your fine-tune job ID below\n",
    "finetune_job = client.fine_tuning.jobs.retrieve(\"ftjob-pRyNWzUItmHpxmJ1TX7FOaWe\")\n",
    "\n",
    "if finetune_job.status == 'succeeded':\n",
    "    fine_tuned_model = finetune_job.fine_tuned_model\n",
    "    print('finetuned model: ' + fine_tuned_model)\n",
    "else:\n",
    "    print('finetuned job status: ' + finetune_job.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eda7a4-3817-40df-84bc-db4555366078",
   "metadata": {},
   "source": [
    "## Running completions for the distilled model\n",
    "\n",
    "Now that we've got our model fine-tuned, we can use this model to run completions and compare accuracy with both gpt4o and gpt4o-mini.\n",
    "Let's grab a different subset of french wines (as we restricted the outputs to french grape varieties, without outliers, we'll need to focus our validation dataset to this too). Let's run this on 300 entries for each models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "603dc1e9-58dc-4b01-b25a-4433ebd88546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question processed 20/300\n",
      "Question processed 40/300\n",
      "Question processed 60/300\n",
      "Question processed 80/300\n",
      "Question processed 100/300\n",
      "Question processed 120/300\n",
      "Question processed 140/300\n",
      "Question processed 160/300\n",
      "Question processed 180/300\n",
      "Question processed 200/300\n",
      "Question processed 220/300\n",
      "Question processed 240/300\n",
      "Question processed 260/300\n",
      "Question processed 280/300\n",
      "Question processed 300/300\n",
      "Question processed 20/300\n",
      "Question processed 40/300\n",
      "Question processed 60/300\n",
      "Question processed 80/300\n",
      "Question processed 100/300\n",
      "Question processed 120/300\n",
      "Question processed 140/300\n",
      "Question processed 160/300\n",
      "Question processed 180/300\n",
      "Question processed 200/300\n",
      "Question processed 220/300\n",
      "Question processed 240/300\n",
      "Question processed 260/300\n",
      "Question processed 280/300Question processed 280/300\n",
      "\n",
      "Question processed 300/300\n",
      "Question processed 20/300\n",
      "Question processed 40/300\n",
      "Question processed 60/300\n",
      "Question processed 80/300\n",
      "Question processed 100/300\n",
      "Question processed 120/300\n",
      "Question processed 140/300\n",
      "Question processed 160/300\n",
      "Question processed 180/300\n",
      "Question processed 200/300\n",
      "Question processed 220/300\n",
      "Question processed 240/300\n",
      "Question processed 260/300\n",
      "Question processed 280/300\n",
      "Question processed 300/300\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = df_france.sample(n=300)\n",
    "\n",
    "models.append(fine_tuned_model)\n",
    "\n",
    "for model in models:\n",
    "    another_subset = process_dataframe(validation_dataset, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eba9c5d-d805-4610-86fe-e18cc20b8cd9",
   "metadata": {},
   "source": [
    "Let's compare accuracy of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cad42199-a4cb-4589-859b-32b39ad02eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o accuracy: 77.00%\n",
      "gpt-4o-mini accuracy: 65.67%\n",
      "ft:gpt-4o-mini-2024-07-18:distillation-test:wine-distillation:AIZntSyE accuracy: 78.33%\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f\"{model} accuracy: {get_accuracy(model, another_subset) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5bdb3c-c7ee-493a-9343-5950d7c36638",
   "metadata": {},
   "source": [
    "That's almost a **20% improvement over the non-distilled gpt-4o-mini! 🎉**\n",
    "\n",
    "Our fine-tuned model performs way better than gpt-4o-mini, while having the same base model. We'll be able to use this model to run inferences at a lower cost and lower latency for future grape variety prediction. It even performs better than gpt-4o, which might be an overfitting problem as we were supposed to train on its outputs but we'll keep that analysis for another cookbook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
